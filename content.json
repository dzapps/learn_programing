[{"title":"git-command","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Git/git-command/","text":"Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。 Git使用GitHub，给出的地址我们一般用ssh。使用ssh需要https，如果不支持只能使用http，但是每次都要输口令。 分支Git鼓励大量使用分支： 查看分支：git branch 创建分支：git branch \\ 切换分支：git checkout \\ 创建+切换分支：git checkout -b \\ 合并某分支到当前分支：git merge \\ 删除分支：git branch -d \\ 主要理解分支，克隆远程仓库，将本地和远程仓库关联，搭建git服务器 git pull 命令作用：取回远程主机某个分支的更新，再与本地的指定分支合并 格式：git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 如果与当前分支合并，则可省略本地分支名git pull &lt;远程主机名&gt; &lt;远程分支名&gt; 相当于：git fetch &lt;远程主机名&gt; &lt;远分支名&gt; git merge &lt;远程主机名&gt;/&lt;远程分支名&gt; 如果当前分支与远程分支存在追踪关系 git pull &lt;远程主机名&gt; 如果当前分支只有一个追踪关系 git pull 手动建立追踪关系 git branch –set-upstream master origin/next 清理远程已删除本地还存在的分支 git fetch –prune origin 或者 git fetch -p 或者 git pull -p 如何上传GitHub 在用户目录下 .ssh ssh-keygen -t rsa -C “1441765847@qq.com“ 把 id_rsa.pub 添加到GitHub的ssh上 git init 把当前目录变为仓库 git add 把文件添加进仓库 git commit 把文件提交到仓库 git add –all 当我们在一个不是空目录下init需要把所有文件添加到仓库的时候使用 文件的标记解释：123456789101112131415A: 你本地新增的文件（服务器上没有）.C: 文件的一个新拷贝.D: 你本地删除的文件（服务器上还在）.M: 文件的内容或者mode被修改了.R: 文件名被修改了。T: 文件的类型被修改了。U: 文件没有被合并(你需要完成合并才能进行提交)。X: 未知状态(很可能是遇到git的bug了，你可以向git提交bug report)。 123456git pullgit pull origin mastergit pull origin master --allow-unrelated-histories git的hook(钩子)为了防止一些不规范的代码 commit 并 push 到远端，我们可以在 git 命令执行前用一些钩子来检测并阻止。在node中，安装需要的模块：husky, pre-commit 配置package.json在提交代码前执行自定义的脚本。 12cd .git/hooksls -l 该目录提供了git的各个钩子的脚步案例。","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"ECMAScript6","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/ECMAScript/","text":"ECMAScript6 是 JavaScript 的第六版本，是一个标准，主要增加了面向对象的支持等 扩展运算符（ spread ）是三个点（…）。它好比 rest 参数的逆运算，将一个数组转为用逗号分隔的参数序列。 12345console.log(...[1, 2, 3])// 1 2 3console.log(1, ...[2, 3, 4], 5)// 1 2 3 4 5[...document.querySelectorAll('div')] 箭头函数12345678910const Person = &#123; 'name': 'little bear', 'age': 18, 'sayHello': function () &#123; setInterval(function () &#123; console.log('我叫' + this.Person + '我今年' + this.age + '岁!') &#125;, 1000) &#125;&#125;Person.sayHello() 基础语法 (参数1, 参数2, …, 参数N) =&gt; {函数声明} (参数1, 参数2, …, 参数N) =&gt; 表达式（单一） 相当于：(参数1, 参数2, …, 参数N) =&gt;{ return表达式} 当只有一个参数时，圆括号是可选的： (单一参数) =&gt; {函数声明} 单一参数 =&gt; {函数声明} 没有参数的函数应该写成一对圆括号。 () =&gt; {函数声明} 在上面的代码里面，谁调用，this指向谁，所以this指向的是setInterval, 就是window（因为setInterval）是window就注入的函数。 所以在setInterval 上一行，我们可以var self = this此时的this是sayHello 由Person来调用，这样才能得到我们想要的结果。 箭头函数最大特点： 不绑定this 不绑定arguments es6箭头函数，这个是原来定义函数的缩写。let 和原来的 var 类似，var是声明变量，它所处的位置决定了变量的作用域，比如在函数里面就是函数的作用于，在外部就是全局作用域。let也是这样，但是它的位置决定的是最接近的块的作用域，作用域比var更细，除了函数全局外，如果你用在for，if里面，那么在整个函数里面是不可见的。所以可以用let声明作用域更细的变量。 继承理解继承的机制 123function DOG(name)&#123;this.name = name&#125; 这个函数我们称为构造函数，js通过对构造函数使用new 关键字创建实例（构造函数相当于Class），这样我们就从原型对象生产了一个实例对象。 共有属性： 这样创建的实例没有共有属性，于是通过为构造函数设置prototype属性，来让从这个构造函数创建的实例都有共有属性。 这个属性包含一个对象（以下简称”prototype对象”），所有实例对象需要共享的属性和方法，都放在这个对象里面；那些不需要共享的属性和方法，就放在构造函数里面。 实例对象一旦创建，将自动引用prototype对象的属性和方法。也就是说，实例对象的属性和方法，分成两种，一种是本地的，另一种是引用的。 这个prototype是大家共同引用的，修改它会影响实例。 constructor： 通过构造函数创建的实例，访问这个属性就可以知道实例的构造函数是谁。 cat1 instanceof Cat 判断实例cat1是否是通过构造函数Cat来的，类似python的isinstance。 1234567891011121314156.1 isPrototypeOf()这个方法用来判断，某个proptotype对象和某个实例之间的关系。 alert(Cat.prototype.isPrototypeOf(cat1)); //true alert(Cat.prototype.isPrototypeOf(cat2)); //true6.2 hasOwnProperty()每个实例对象都有一个hasOwnProperty()方法，用来判断某一个属性到底是本地属性，还是继承自prototype对象的属性。 alert(cat1.hasOwnProperty(&quot;name&quot;)); // true alert(cat1.hasOwnProperty(&quot;type&quot;)); // false 12prototype constructor__proto__ 普通对象 最普通的对象：有proto属性（指向其原型链），没有prototype属性。 原型对象(person.prototype 原型对象还有constructor属性（指向构造函数对象）)。 函数对象： 凡是通过new Function()创建的都是函数对象。 拥有proto、prototype属性（指向原型对象）。 Function、Object、Array、Date、String、自定义函数。 特例： Function.prototype(是原型对象，却是函数对象，下面会有解释) 如何判断是什么对象 typeof 对象 其实原型对象就是构造函数的一个实例对象。person.prototype就是person的一个实例对象。相当于在person创建的时候，自动创建了一个它的实例，并且把这个实例赋值给了prototype。 早绑定和晚绑定所谓绑定（binding），即把对象的接口与对象实例结合在一起的方法。 早绑定（early binding）是指在实例化对象之前定义它的属性和方法，这样编译器或解释程序就能够提前转换机器代码。在 Java 和 Visual Basic 这样的语言中，有了早绑定，就可以在开发环境中使用 IntelliSense（即给开发者提供对象中属性和方法列表的功能）。ECMAScript 不是强类型语言，所以不支持早绑定。 另一方面，晚绑定（late binding）指的是编译器或解释程序在运行前，不知道对象的类型。使用晚绑定，无需检查对象的类型，只需检查对象是否支持属性和方法即可。ECMAScript 中的所有变量都采用晚绑定方法。这样就允许执行大量的对象操作，而无任何惩罚。 文件导入export default 和 export 区别： export与export default均可用于导出常量、函数、文件、模块等 你可以在其它文件或模块中通过import+(常量 | 函数 | 文件 | 模块)名的方式，将其导入，以便能够对其进行使用 在一个文件或模块中，export、import可以有多个，export default仅有一个 通过export方式导出，在导入时要加{ }，export default则不需要 export 12345//a.jsexport const str = \"blablabla~\";export function log(sth) &#123; return sth;&#125; 对应的导入方式： 12//b.jsimport &#123; str, log &#125; from 'a'; //也可以分开写两次，导入的时候带花括号 export default 123//a.jsconst str = \"blablabla~\";export default str; 对应的导入方式： 12//b.jsimport str from 'a'; //导入的时候没有花括号 Object.assignObject.assign({}, row) 拷贝对象 import和require的区别node编程中最重要的思想就是模块化，import和require都是被模块化所使用。 遵循规范 require 是 AMD规范引入方式 import是es6的一个语法标准，如果要兼容浏览器的话必须转化成es5的语法 调用时间 require是运行时调用，所以require理论上可以运用在代码的任何地方 import是编译时调用，所以必须放在文件开头 本质 require是赋值过程，其实require的结果就是对象、数字、字符串、函数等，再把require的结果赋值给某个变量 import是解构过程，但是目前所有的引擎都还没有实现import，我们在node中使用babel支持ES6，也仅仅是将ES6转码为ES5再执行，import语法会被转码为require 引用同级文件 a.js，b.js 都在一起，应该 import ./b 不要直接 import b 1，给vue组件绑定事件时候，必须加上native ，不然不会生效（监听根元素的原生事件，使用 .native 修饰符）2，等同于在自组件中： 子组件内部处理click事件然后向外发送click事件：$emit(“click”.fn)","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"}]},{"title":"element-UI","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/element-UI/","text":"饿了么前端团队出品的Vue UI框架 from rulesfrom rules 是表单组件中用于在表单验证规则的属性，把rules绑定给一个对象，对象的属性即为需要做验证的字段，属性值为验证规则 12345rules: &#123;type: [&#123; required: true, message: 'type is required', trigger: 'change' &#125;],timestamp: [&#123; type: 'date', required: true, message: 'timestamp is required', trigger: 'change' &#125;]&#125; 对表单的type字段做规则验证，该字段是必须的。 Loading关于 Loading 拥有指令调用，服务调用（在需要的地方手动触发），指令的话就是 v-loading=’true’即可。可以通过修饰符把效果的遮蔽罩覆盖到DOM的body上。","tags":[{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"},{"name":"farmework","slug":"farmework","permalink":"http://www.liuzhidream.com/tags/farmework/"},{"name":"Vue","slug":"Vue","permalink":"http://www.liuzhidream.com/tags/Vue/"}]},{"title":"jQuery","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/jQuery/","text":"javascript封装，快速编写前端代码，不过在MVVM框架的势头下，jQuery慢慢的不再需要了 jQuery 方法javascript封装，快速编写前端代码，不过在MVVM框架的势头下，jQuery慢慢的不再需要了 each( )如果是去迭代数组 类似 Inpute标签组成的 a:1,b:2： 使用 $.each(对象，function（index,value）{ }); 这样可以拿到数组的键和值 如果是迭代元素 类似p标签的集合： 使用 $(&quot;p&quot;).eache(function(index){ }); 在函数中，使用this得到当前迭代的元素 is()is() 根据选择器、元素或 jQuery 对象来检测匹配元素集合，如果这些元素中至少有一个元素匹配给定的参数，则返回 true。 parseFloat()解析一个字符串，并返回一个浮点数，参数必须且是一个字符 该函数先去判断第一个字符串是否是数字，不是，函数返回 NaN，是，继续执行。如果在解析过程中遇到了正负号（+ 或 -）、数字 (0-9)、小数点，或者科学记数法中的指数（e 或 E）以外的字符，则它会忽略该字符以及之后的所有字符，返回当前已经解析到的浮点数。同时参数字符串首位的空白符会被忽略。 NaN 属性是JS的Number对象，代表非数字值的特殊值。该属性用于指示某个值不是数字。可以把 Number 对象设置为该值，来指示其不是数字值。比如月份用数字5代表5月份，var number=5; number.NaN,number现在就不是数字了。 isNaN() 该一个要检测的参数（必须）看是不是NaN，是就返回True 其它值返回False。 parseInt() 函数可解析一个字符串，并返回一个整数。 indexOf() 方法可返回某个指定的字符串值在字符串中首次出现的位置。即索引值。 match() 方法可在字符串内检索指定的值，或找到一个或多个正则表达式的匹配。 othertext（）用来设置或返回值，val()返回value的值 attr() 方法设置或返回被选元素的属性值。该方法不同的参数会有不同的效果 attr(“id”,123) 选择器得到的JQuery对象的attr方法，将对象的id 改变为 “123”（没有id直接添加一个id） appendto() append() append() 方法在被选元素的结尾（仍然在内部）插入指定内容。提示：append() 和 appendTo() 方法执行的任务相同。不同之处在于：内容的位置和选择器。例子： 123456p标签原来的内容 &lt;p&gt;This is a paragraph.&lt;/p&gt;$(&quot;p&quot;).append(&quot; &lt;b&gt;Hello world!&lt;/b&gt;&quot;); 执行方法后 This is a paragraph. Hello world!$(&quot;&lt;b&gt; Hello World!&lt;/b&gt;&quot;).appendTo(&quot;p&quot;);p标签原内容和执行结果同上。 find（）方法 由给定表达式去匹配满足条件的后代元素，返回jquery对象。 1var b=$(\"#id\").find('[name=id]'); window.location.href=”url” 当前页面打开URL 当点击元素时，会发生 click 事件。 当鼠标指针停留在元素上方，然后按下并松开鼠标左键时，就会发生一次 click。 click() 方法触发 click 事件，或规定当发生 click 事件时运行的函数。 on 为元素绑定事件，比如click事件，然后加个函数，这个元素点击后就会去执行这个函数。 html()jquery渲染页面方法，$.html() 对dom执行html方法，会将dom的内容给替换了，比如 &lt;div class=123&gt;&lt;/div&gt; 对这个dom执行方法html(&lt;p&gt;123&lt;/p&gt;) 结果是&lt;div class=123&gt;&lt;p&gt;123&lt;/p&gt;&lt;/div&gt; 元素切换sildeup sildedown，show hide 元素切换隐藏 jQuery遍历 siblings：dom.siblings(.class).addClass() 对选择对象执行遍历，找到所有class类，并给他们添加样式。 scroll()dom调用，可以在滚动条滚动的时候触发，只要有滚动就触发。这里注意如果逻辑涉及到滚动的数值判断，使用比较不要使用相等，因为滚动很快，相关的判断不一定每次执行到。 样式直接写在dom上，相当于 style : dom.css(&#39;color&#39;, &#39;red&#39;) hasClass() addClass() removClass() 对dom类的控制","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"}]},{"title":"node","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/node/","text":"服务端的javascript，Nodejs是一个Javascript运行环境(runtime environment)，让js可以运行在服务端 webpackwebpack把多种静态资源转换成一个静态文件 @ 的含义在webpack的配置中 1234567resolve: &#123; extensions: ['.js', '.vue', '.json'], alias: &#123; '@': resolve('src'), &#125;&#125; 这样在需要导入组件的时候使用 import A from &#39;@/components/a.vue&#39; 就是给复杂了引用路径做个别名。 修改编译路径编译路径修改（由于存在编译出来的文件相互依赖的，而你只导入其中几个，依赖就出问题了，为了不修改后端代码，修改通用编译路径是不错的解决方案） 12345assetsRoot: path.resolve(__dirname, '../static/dist'),assetsSubDirectory: '',assetsPublicPath: '/static/dist/',productionSourceMap: false, Babel一个转码器，将es6转es5，这个东西何用？node.js直接执行es6代码还存在问题，听说最新版本可以了。所以用es6来写js，这样可以利用它的新特性，然后转码，这样node.js就可以运行了。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"},{"name":"node.js","slug":"node-js","permalink":"http://www.liuzhidream.com/tags/node-js/"}]},{"title":"npm","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/npm/","text":"npm是node的包管理工具，不建议使用任何第三方的工具，也不建议换源，这些操作解决一时问题也带来其它问题。关于网络问题，是在不行用手机热点，如果你们公司的网络都下不了，那公司不用待了。第三方工具也是，开始npm确实比不上第三方工具，不过现在渐渐好多了，官方也意识到这些问题了。 npmnpm是node的包管理工具，不建议使用任何第三方的工具，也不建议换源，这些操作解决一时问题也带来其它问题。关于网络问题，实在不行用手机热点，如果你们公司的网络都下不了，那公司不用待了。第三方工具也是，开始npm确实比不上第三方工具，不过现在渐渐好多了，官方也意识到这些问题了。 全局和局部一般在全局安装的是工具，比如webpack，这样这些工具在构建项目或者执行项目的命令的时候由于是全局任何地方都能使用，而局部就是装模块的，这些模块可能因为依赖关系，你最好不要在全局装模块，如果你的项目引用全局模块，多个项目的时候，可能依赖不一样，这样你去更新全局模块的时候就可能由于依赖的问题影响其它项目了。 命令 Command Description npm list -g –depth 0 查看全局安装包 npm install packagename -g 全局安装 npm uninstall package -g 全局卸载 npm install pg –save 项目依赖安装 npm install pg –save-dev 项目非依赖安装 npm view jquery versions 查看模块版本号，这里举例的是jQuery","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"node.js","slug":"node-js","permalink":"http://www.liuzhidream.com/tags/node-js/"}]},{"title":"nvm","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/nvm/","text":"nvm 是 node的环境管理工具，可以同时安装多个node版本，具体实现是通过修改环境变量切换到对应的node上，不同的node版本拥有独立的包文件。 nvmnvm 是 node的环境管理工具，可以同时安装多个node版本，具体实现是通过修改环境变量切换到对应的node上，不同的node版本拥有独立的包文件。 安装Mac 下安装使用github提供的脚本安装，安装完成添加对应shell的配置 nvm 使用brew安装会有一些小问题 正确的安装和使用nvm(mac) 1234export NVM_DIR=\"$HOME/.nvm\"[ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" # This loads nvm[ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\"# This loads nvm bash_completion github 地址 https://github.com/creationix/nvm/blob/master/README.md 命令 Command Description nvm install stable 安装最新稳定版 nvm install \\ 安装指定版本，可模糊安。如：安装v4.4.0，既可nvm install v4.4.0，又可nvm install 4.4 nvm uninstall \\ 删除已安装的指定版本，语法与install类似 nvm ls 列出所有安装的版本 nvm ls-remote 列出所有远程服务器的版本（官方node version list） nvm current 显示当前的版本 nvm alias \\ \\ 给不同的版本号添加别名 nvm unalias \\ 删除已定义的别名 nvm reinstall-packages \\ 在当前版本 node 环境下，重新全局安装指定版本号的 npm 包","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"node.js","slug":"node-js","permalink":"http://www.liuzhidream.com/tags/node-js/"}]},{"title":"JavaScriptUtil","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScriptUtil/JavaScriptUtil/","text":"常见的JavaScript 相关设计 自定义遮蔽罩使用了jQuery-WeUI，需要根据情况做调整 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!--自定义遮罩层--&gt;&lt;div id=\"bg\" class=\"weui-mask weui-mask--visible\" style=\"display: none;opacity: 1;visibility: visible;z-index: 100\"&gt;&lt;/div&gt;&lt;!-- 简单示例 --&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/&gt; &lt;title&gt;html 最简遮罩层&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; function showDiv() &#123; document.getElementById('popDiv').style.display = 'block'; document.getElementById('bg').style.display = 'block'; &#125; function closeDiv() &#123; document.getElementById('popDiv').style.display = 'none'; document.getElementById('bg').style.display = 'none'; &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"popDiv\" style=\"z-index:99;display:none;position:absolute;margin-top: 20%;margin-left: 40%;background-color: #FFF;\"&gt;html 最简遮罩层&lt;br/&gt;html 最简遮罩层&lt;br/&gt; &lt;a href=\"javascript:closeDiv()\"&gt;关闭遮罩层&lt;/a&gt;&lt;/div&gt;&lt;div id=\"bg\" style=\"display:none;background-color: #ccc;width: 100%;position:absolute;height: 100%;opacity: 0.5;z-index: 1;\"&gt;&lt;/div&gt;&lt;div style=\"padding-top: 10%;padding-left:40%;z-index:1;\"&gt; &lt;input type=\"Submit\" name=\"\" value=\"打开遮罩层\" onclick=\"javascript:showDiv()\"/&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;","tags":[{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"},{"name":"util","slug":"util","permalink":"http://www.liuzhidream.com/tags/util/"}]},{"title":"linux-command","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Linux/linux-command/","text":"Linux 命令与工具 chsh 修改用户使用的shell查看 cat /etc/shells 文件，显示当前系统支持的shell，使用 chsh -s /bin/zsh 修改。该命令最终的效果会修改 /etc/passwd 文件。 env printenv 查看环境变量理解全局环境变量和局部环境变量，全局变量包括系统设置的和用户自己添加的，系统变量一般是全大写字母，通过printenv命令可以查看变量值 printenv HOME。 scp 拷贝命令scp命令 （主机和服务器相互拷贝数据，该命令要求开启scp服务。 从服务器到本地 scp root@ip:拷贝路径 本地路径 从本地到服务器 scp 本地路径 root@ip:拷贝路径 grep内容查找命令，配合其它命令一起使用 find 查找命令查找命令，列出符合条件的文件路径。 find / -name * uptime查看系统运行情况，启动时间，登陆时间等。最后的三个数字代表系统最近1分钟，5分钟，15分钟负载情况。 liuzhi@localhost  ~  uptime 23:03 up 13:47, 3 users, load averages: 1.04 1.25 1.37 lsoflsof 是 linux 下的一个非常实用的系统级的监控、诊断工具。它的意思是 List Open Files，很容易你就记住了它是 “ls + of” 的组合。它可以用来列出被各种进程打开的文件信息，记住：linux 下 “一切皆文件”，包括但不限于 pipes, sockets, directories, devices, 等等。因此，使用 lsof，你可以获取任何被打开文件的各种信息。 监控进程：lsof -p 2854 查看指定进程打开的文件。 监控网络：lsof -i:8080 查看端口被哪些进程使用。 wgetwget url 下载文件 tar 解压关于解压，如果是网络的包，文件后缀tar.gz 解压命令 tar zxf filename zip类型，需要安装解压工具 unzip unzip filename 先创建好目标目录，在里面解压，或者指定目录 screen 工具需要下载 screen -r name screen -S name 最好用大写的S screen C d 关闭当前会话并结束进程 screen -ls 会话会有状态，dead 状态利用screen -wipe 清除 Detached 为没有人登陆，Attached为有人，有时候没有人也会是这个状态，一般是出问题了screen -D -r ＜session-id&gt; 先踢掉前一用户，再登陆。 screen -X -S session_id quit 查看发行版本信息cat /etc/issue 或 cat /etc/redhat-release（Linux查看版本当前操作系统发行版信息） 查看内核信息uname -a（Linux查看版本当前操作系统内核信息） 查看操作系统版本信息cat /proc/version（Linux查看当前操作系统版本信息） mkdir -pmkdir 用于创建文件夹，如果包含子目录，需要使用 -p ，这样就可以创建多层级的目录 例子：mkdir -p ~/web-develop/projects/data mv 移动、重命名mv [options] 源文件或目录 目标文件或目录 Debian 删除软件基于Debian的Linux发行版使用apt-get管理软件包 apt-get remove 会删除软件包而保留软件的配置文件 apt-get purge 会同时清除软件包和软件的配置文件 查看端口netstat -an | grep 3306","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"linux-shell","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Linux/linux-shell/","text":"linux shell学习笔记 定位系统环境变量登录shell的时候，默认情况下bash会在几个文件中查找命令，这些文件称为启动文件或环境文件。这就是我们经常设置的把某个程序的目录加到环境变量，如果你跟风，用了什么 item2 这样的第三方shell，并对系统做了一些修改，那么原来安装的软件默认设置的环境变量就没有了，需要把他们迁移到新的shell中。 bash检查的启动文件，取决于你启动shell的方式： - 登录时作为默认登陆shell - 作为非登录shell的交互式shell - 作为运行脚本的非交互shell 虽然都是进入了shell，但是它们的环境变量有区别。 登录shell这种shell就是你登陆后启动的shell。 常见启动文件： /etc/profile $HOME/.bash_profile&nbsp;&nbsp; $HOME/.bashrc $HOME/.bash_login&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $HOME/.profile 上述是 bash shell 的启动文件。如果你使用了一些第三方安装了 zsh 应该可以在~目录找到 .zshrc。/etc/profile 是系统环境变量，剩余的是用户的，每个用户都可以编辑这些文件添加自己的环境变量。这些环境变量在启动 bash shell 的时候生效。 shell会按照按照下列顺序，运行第一个被找到的文件，余下的则被忽略: $HOME/.bash_profile $HOME/.bash_login $HOME/.profile 注意，这个列表中并没有 $HOME/.bashrc文件。这是因为该文件通常通过其他文件运行的，比如在有些Linux系统中 ./bash_profile 文件会去找有没有 .bashrc，有的话先执行它。 交互式shell就是通过命令行启动shell，比如 /bin/sh 如果安装zsh /bin/zsh 这种情况不会访问系统变量。 非交互式shell最后一种shell是非交互式shell。系统执行shell脚本时用的就是这种shell。不同的地方在于它没有命令行提示符。但是当你在系统上运行脚本时，也许希望能够运行一些特定启动的命令。非交互，理解继承，如果你要编写脚本要知道这是什么情况 为了处理这种情况，bash shell 提供了 BASH_ENV 环境变量。当shell启动一个非交互式shell进程时，它会检查这个环境变量来查看要执行的启动文件。如果有指定的文件，shell会执行该文件里的命令，这通常包括shell脚本变量设置。 在CentOS Linux发行版中，这个环境变量在默认情况下并未设置。如果变量未设置，printenv命令只会返回CLI提示符:$ printenv BASH_ENV $ Ubuntu发行版中，变量BASH_ENV也没有被设置。记住，如果变量未设置，echo 命令会显示一个空行，然后返回CLI提示符:$ echo $BASH_ENV 那如果BASH_ENV变量没有设置，shell脚本到哪里去获得它们的环境变量呢?别忘了有些shell脚本是通过启动一个子shell来执行的。子shell可以继承父shell导出过的变量。举例来说，如果父shell是登录shell，在/etc/profile、/etc/profile.d/*.sh和$HOME/.bashrc文件中设置并导出了变量，用于执行脚本的子shell就能够继承这些变量。 要记住，由父shell设置但并未导出的变量都是局部变量。子shell无法继承局部变量。 对于那些不启动子shell的脚本，变量已经存在于当前shell中了。 所以就算没有设置BASH_ENV，也可以使用当前shell的局部变量和全局变量。 环境变量持久化现在你已经了解了各种shell进程以及对应的环境文件，找出永久性环境变量就容易多了。也可以利用这些文件创建自己的永久性全局变量或局部变量。对全局环境变量来说(Linux系统中所有用户都需要使用的变量)，可能更倾向于将新的或修改过的变量设置放在 /etc/profile 文件中，但这可不是什么好主意。如果你升级了所用的发行版，这个文件也会跟着更新，那你所有定制过的变量设置可就都没有了。 最好是在 /etc/profile.d 目录中创建一个以.sh结尾的文件。把所有新的或修改过的全局环境变 量设置放在这个文件中。在大多数发行版中，存储个人用户永久性 bash shell 变量的地方是 $HOME/.bashrc 文件。这一点适用于所有类型的shell进程。但如果设置了BASH_ENV变量，那么记住，除非它指向的是 $HOME/.bashrc，否则你应该将非交互式shell的用户变量放在别的地方。图形化界面组成部分(如GUI客户端)的环境变量可能需要在另外一些配置文件中设置，这和设置 bash shell 环境变量的地方不一样。你可以把自己的alias设置放在 $HOME/.bashrc 启动文件中，使其效果永久化。 :sunny:总结：全局环境变量可以在对其作出定义的父进程所创建的子进程中使用。局部环境变量只能在定义它们的进程中使用。Linux系统使用全局环境变量和局部环境变量存储系统环境信息。可以通过shell的命令行界面或者在shell脚本中访问这些信息。bash shell 沿用了最初 Unix Bourne shell 定义的那些系统环境变量，也支持很多新的环境变量。PATH环境变量定义了 bash shell 在查找可执行命令时的搜索目录。可以修改PATH环境变量来添加自己的搜索目录(甚至是当前目录符号)，以方便程序的运行。也可以创建自用的全局和局部环境变量。一旦创建了环境变量，它在整个shell会话过程中就都是可用的。 bash shell 会在启动时执行几个启动文件。这些启动文件包含了环境变量的定义，可用于为每个bash会话设置标准环境变量。每次登录Linux系统，bash shell 都会访问/etc/profile启动文件以及3个针对每个用户的本地启动文件 :$HOME/.bash_profile、$HOME/.bash_login和$HOME/.profile。 用户可以在这些文件中定制自己想要的环境变量和启动脚本。最后，我们还讨论了环境变量数组。这些环境变量可在单个变量中包含多个值。你可以通过指定索引值来访问其中的单个值，或是通过环境变量数组名来引用所有的值。 重点：永久环境变量，用户环境变量，配置顺序也很重要，直接使用符号链接和配置环境变量","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"linux-question","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Linux/question/","text":"Linux遇到的问题 遇到的问题export LC_CTYPE=en_US.UTF-8 在 user目录下面，.bashrc 文件加入这一行，执行 source .bashrc 解决svn 编码错误问题。或者直接执行 LC_CTYPE=en_US.UTF-8（对本次登陆有效） lsb_release -a 查看版本信息 本地仓库关联远程仓库：通过GitHub创建的仓库，通常会有一个README.md，在本地初始化一个目录为git 当我们想把这个目录和远程GitHub仓库关联起来的时候，实际上是合并两个分支，所以如果两个仓库有同名文件就会发生冲突，最好不要有同名文件，以确保合并分支成功。","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"vim","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Linux/vim/","text":"vim使用 Vim命令","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"HomeBrew","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Mac/HomeBrew/","text":"用mac电脑，你需要学会HomeBrew HomeBrewmac 平台的包管理工具，官网地址https://brew.sh/ 12安装命令/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 记得先安装Xcode，保证安装脚步需要的环境都是可行的。 常用命令 Command Description brew info [name] 查看已安装包都信息 brew search [name] 搜索包 brew install remove rm [name] 安装包 brew uninstall [name] 卸载包 brew list 查看已安装的包列表 brew cleanup 删除文件残留 brew cleanup [name] brew deps [name] 查看包的依赖 brew outdated 查看需要更新的包 brew update 更新包 brew home [name] 用浏览器打开，查看包的网页信息 brew options [name] 查看包的安装选项 brew services list 查看homebrew安装的服务情况 brew services start 启动服务，后面跟服务名称 brew services stop 停止服务，后面跟服务名称","tags":[{"name":"util","slug":"util","permalink":"http://www.liuzhidream.com/tags/util/"},{"name":"mac","slug":"mac","permalink":"http://www.liuzhidream.com/tags/mac/"}]},{"title":"Locust测试工具","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Locust/README/","text":"locust 是一个简单易用的测试工具。 官方文档：https://docs.locust.io/en/stable/what-is-locust.html 文件描述符限制如果做高并发测试，操作系统会限制一个进程能够创建的文件描述符上限制，因为每个tcp连接都需要用到一个socket句柄。 ulimit -n 可以查看系统允许当前用户打开的文件数限制 ulimit -n 65535 可以修改限制，本次有效果 根据官方文档描述来看，模拟用户数超过能打开的文件数，会出现错误。 如何使用安装locust后，通过编写脚本，然后启动服务，此时通过浏览器端，就可以进行测试了。12345678910111213141516171819202122232425#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time : 2018/10/7 下午10:46# @Author : liuzhi# @File : locustfile.pyfrom locust import HttpLocust, TaskSet, taskclass UserBehavior(TaskSet): @task def sleep(self): self.client.get(\"/sleep\") @task def woek(self): self.client.get(\"/work\")class WebsiteUser(HttpLocust): task_set = UserBehavior min_wait = 0 # 单位 ms 请求等待的最小时间 max_wait = 1# 测试server# locust --host=http://localhost:8888 上述代码主要有两个类，UserBehavior类两个任务就是模拟当前用户的行为，sleep和work代表本次请求的用户将执行sleep和work操作，可以设置随机或同顺序，或者执行的比重。locust --host=http://localhost:8888命令启动locust，8888代表测试服务的端口。 UI界面描述 Type：请求类型； Name：请求路径； requests：当前请求的数量； fails：当前请求失败的数量； Median：中间值，单位毫秒，一般服务器响应时间低于该值，而另一半高于该值； Average：所有请求的平均响应时间，毫秒； Min：请求的最小的服务器响应时间，毫秒； Max：请求的最大服务器响应时间，毫秒； Content Size：单个请求的大小，单位字节；10.reqs/sec：每秒钟请求的个数。 RPS: 服务器每秒能处理的请求数","tags":[{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"},{"name":"web","slug":"web","permalink":"http://www.liuzhidream.com/tags/web/"}]},{"title":"Iterm2","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Mac/Iterm2/","text":"不错的终端软件 移动一个单词在Profile – keys下，找到如同的原配置信息。 image 其实这是已有的功能，不过Mac默认的快捷键被占用了，修改成我们习惯的。分别修改option+←和option+→的映射，选择Action为“Send Escape Sequence”，然后输入“b”和“f”即可。 配置远程ssh登陆使用脚本传参数的方式登陆，先准备脚本，内容如下： 1234567891011#!/usr/bin/expectset timeout 30spawn ssh -p [lindex $argv 0] [lindex $argv 1]@[lindex $argv 2]expect &#123; \"(yes/no)?\" &#123;send \"yes\\n\";exp_continue&#125; \"password:\" &#123;send \"[lindex $argv 3]\\n\"&#125;&#125;interact 在本地创建这么一个文件 *.sh然后去配置iterm2，如下图，用绝对路径指向这个文件，后面加上参数。 端口，用户，IP，password。举例：/Users/liuzhi/Documents/LinuxServer/liuzhiTX.sh 22 root 123.207.***.202 12345 image 命令 Command Description 垂直分屏 command + d 水平分屏 command + shift + d 切换屏幕 command + option + 方向键 command + [ 或 command + ] 查看历史命令 command + ; 查看剪贴板历史 command + shift + h 新建标签 command + t 关闭标签 command + w 切换标签 command + 数字 command + 左右方向键 切换全屏 command + enter 查找 command + f 清除当前行 ctrl + u 到行首 ctrl + a 到行尾 ctrl + e 前进后退 ctrl + f/b (相当于左右方向键) 上一条命令 ctrl + p 搜索命令历史 ctrl + r 删除当前光标的字符 ctrl + d 删除光标之前的字符 ctrl + h 删除光标之前的单词 ctrl + w 删除到文本末尾 ctrl + k 交换光标处文本 ctrl + t 清屏1 command + r 清屏2 ctrl + l ⌘ + f 所查找的内容会被自动复制 ⌘ + r clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏 ctrl + u 清空当前行，无论光标在什么位置 输入开头命令后 按 ⌘ + 会自动列出输入过的命令 ⌘ + shift + h 会列出剪切板历史 复制： 选中即复制：iterm2有2种好用的选中即复制模式。 一种是用鼠标，在iterm2中，选中某个路径或者某个词汇，那么，iterm2就自动复制了。 另一种是无鼠标模式，command+f，弹出iterm2的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之后，输入tab，查找窗口将自动变化内容，并将其复制。如果输入的是shift+tab（实测好像没用），则自动将查找内容的左边选中并复制。 输入command+shift+h，iterm2将自动列出剪切板的历史记录，这个历史要使用过无鼠标模式才行","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"util","slug":"util","permalink":"http://www.liuzhidream.com/tags/util/"},{"name":"mac","slug":"mac","permalink":"http://www.liuzhidream.com/tags/mac/"}]},{"title":"MongoDB","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/MongoDB/MongoDB/","text":"MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。 MongoDB image ObjectID字段ObjectId构成我们使用MySQL等关系型数据库时，主键都是设置成自增的。但在分布式环境下，这种方法就不可行了，会产生冲突。为此，MongoDB采用了一个称之为ObjectId的类型来做主键。ObjectId是一个12字节的BSON类型字符串。按照字节顺序，依次代表： 4字节：UNIX时间戳 3字节：表示运行MongoDB的机器 2字节：表示生成此_id的进程 3字节：由一个随机数开始的计数器生成的值 MongoDB对ObjectId对象提供了getTimestamp()方法来获取ObjectId的时间。 这里不使用自增长id主要是因为MongoDB是分布式数据库，在并发插入的时候需要维护全局的唯一ID，传统的像MySQL是单机版的，使用自增长ID可以了，处理多条数据插入加锁就行了，虽然MySQL也可以部署集群，但是这种情况ID就没用了，需要自定义全局唯一字段。 ObjectID是字段类型，通常来说它是按照默认规则来生产的，文档中的其它字段也可以使用这种字段类型。 查询 查询全部：db.document.find({}) 查询字段是对象的：db.document.find({&#39;id_card.idcard_type&#39;: &#39;身份证&#39;}) projection该参数指明要显示的字段或者要隐藏的字段 db.document.find({}, {&#39;name&#39;:1}) 返回结果只显示name字段 db.document.find({}, {&#39;name&#39;:0}) 返回结果把name字段隐藏了，其它展示出来 内嵌文档见文档 数据库引用分为手动引用和DBRefs，手动引用就是自己建立关系，然后查多次或关联查询。 使用方法： $ref：集合名称 $id：引用的id $db:数据库名称，可选参数 产品document中引用attr_data，attr_data是产品属性document 12345from collections import namedtuplePoint = namedtuple('Point', ['x', 'y'])p = Point(11, 22)x, y = pprint(x, y) 123456789&#123; \"_id\":ObjectId(\"53402597d852426020000002\"), \"product_name\": \"卫龙辣条\", \"attr_data\": &#123; \"$ref\": \"product_attr\", \"$id\": ObjectId(\"534009e4d852427820000002\"), \"$db\": \"testdata\" &#125;&#125; product_attr document 12345&#123; \"_id\" : ObjectId(\"534009e4d852427820000002\"), \"size\": \"大\", \"weight\": \"100g\"&#125; 查询123456789var product = db.products.findOne(&#123;\"product_name\":\"卫龙辣条\"&#125;)var dbRef = product.attr_datadb[dbRef.$ref].findOne(&#123;\"_id\":(dbRef.$id)&#125;)结果：&#123; \"_id\" : ObjectId(\"534009e4d852427820000002\"), \"size\": \"大\", \"weight\": \"100g\"&#125; 原子操作mongodb不支持事务，所以，在你的项目中应用时，要注意这点。无论什么设计，都不要要求mongodb保证数据的完整性。 但是mongodb提供了许多原子操作，比如文档的保存，修改，删除等，都是原子操作。 所谓原子操作就是要么这个文档保存到Mongodb，要么没有保存到Mongodb，不会出现查询到的文档没有保存完整的情况。 findAndModify方法该方法将查询一些结果，如果查询到，执行更新。这些语句都是写在一个查询中的，并且使用对应的原子操作方法，让整个findAndModify实现原子性操作。如果分开操作，就是先查询，再修改，在这两个操作之间，如果有人购买了产品，导致库存不足，那么修改操作就会导致数据库数据一致性问题。1234567891011book = &#123; _id: 123456789, title: &quot;MongoDB: The Definitive Guide&quot;, author: [ &quot;Kristina Chodorow&quot;, &quot;Mike Dirolf&quot; ], published_date: ISODate(&quot;2010-09-24&quot;), pages: 216, language: &quot;English&quot;, publisher_id: &quot;oreilly&quot;, available: 3, checkout: [ &#123; by: &quot;joe&quot;, date: ISODate(&quot;2012-10-15&quot;) &#125; ] &#125; 对于上述的book模型，available是我们的判别标志，当它大于0的时候，说明是可以操作的(比如借书)，这部分就是查询，查询成功了，就可以去执行要更新的操作。db.document.findAndModify({ query: {}, update: {}})更新操作应该使用原子操作命令 $set:用来指定一个键并更新键值，若键不存在并创建。 { $set : { field : value } } $unset:用来删除一个键 { $unset : { field : 1} } $inc:可以对文档的某个值为数字型的键进行增减操作 { $inc : { field : value } } $push：把value追加到field里面去，field一定要是数组类型才行，如果field不存在，会新增一个数据类型加进去。 { $push : { field : value } } $pushAll:同$push,只是一次可以追加到多个值到一个数组字段内。 { $pushAll : { field : value_array } } $pull:从数组field内删除一个等于value值 { $pull : { field : _value } } $addToSet：增加一个值到数组内，而且只有当这个值不在数组内才增加。 $pop：删除数组的第一个或最后一个元素{ $pop : { field : 1 } } $rename：修改字段名称{ $rename : { old_field_name : new_field_name } } $bit：位操作，integer类型{$bit : { field : {and : 5}}} 偏移操作符 t.find() { “_id” : ObjectId(“4b97e62bf1d8c7152c9ccb74”), “title” : “ABC”, “comments” : [ { “by” : “joe”, “votes” : 3 }, { “by” : “jane”, “votes” : 7 } ] } t.update( {‘comments.by’:’joe’}, {$inc:{‘comments.$.votes’:1}}, false, true ) t.find() { “_id” : ObjectId(“4b97e62bf1d8c7152c9ccb74”), “title” : “ABC”, “comments” : [ { “by” : “joe”, “votes” : 4 }, { “by” : “jane”, “votes” : 7 } ] } 索引MongoDB通过索引加快查询速度，索引运行在内存中，数据库的操作也需要对索引进行操作，索引超过内存的情况，将会删除一些索引。最好只对大数据文档创建索引。 索引不能被以下的查询使用： 正则表达式及非操作符，如 $nin, $not, 等 算术运算符，如 $mod, 等 $where 子句 所以，检测你的语句是否使用索引是一个好的习惯，可以用explain来查看。 最大范围 集合中索引不能超过64个 索引名的长度不能超过128个字符 一个复合索引最多可以有31个字段","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"database","slug":"database","permalink":"http://www.liuzhidream.com/tags/database/"}]},{"title":"MongoEngine","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/MongoDB/MongoEngine/","text":"文档http://docs.mongoengine.org/index.htmlMongoEngine是Python操作MongoDB的ORM封装，可以看到很多ORM框架的影子，比如Django的ORM。底层调用了pymongo。 基本用法都是创建Document的class，得到class的instance，然后去操作instance。 MongoDB数据库是文档型的，在一个集合中，每一个文档都可以是不同的结构，不过使用了ORM，查询写入都会受到ORM的限制，当然你应该规范文档的结构。 ORM提供的功能比较有限，基础操作满足不了的，查pymongo，框架底层是基于pymongo。 Document instancesclean实例方法，用来做save前操作。 Cascading SavesIf your document contains ReferenceField or GenericReferenceField objects, then by default the save() method will not save any changes to those objects.如果文档包含ReferenceField或者GenericReferenceField字段，save方法不会保存他们的修改，需要在save(cascade=True)设置，save方法描述： :param cascade: Sets the flag for cascading saves. You can set a default by setting “cascade” in the document meta暂时没有做过测试。 delete执行delete，需要有id字段。 Document IDs文档要保存了才能访问id，通过情况不需要声明id字段12345&gt;&gt;&gt; page = Page(title=&quot;Test Page&quot;)&gt;&gt;&gt; page.id&gt;&gt;&gt; page.save()&gt;&gt;&gt; page.idObjectId(&apos;123456789abcdef000000000&apos;) 通过设置字段的关键字来创建id，这里把email作为id，事实上id是主键的别名，pk == id 是等价的? 修改了默认主键，是不是就不存在唯一表示了，既没有了ObjectId(‘123456789abcdef000000000’)12345678&gt;&gt;&gt; class User(Document):... email = StringField(primary_key=True)... name = StringField()...&gt;&gt;&gt; bob = User(email=&apos;bob@example.com&apos;, name=&apos;Bob&apos;)&gt;&gt;&gt; bob.save()&gt;&gt;&gt; bob.id == bob.email == &apos;bob@example.com&apos;True Querying the databaseQuerySetManager QuerySet 的概念在MongoEngine中也是适用的。查询集使用本地缓存，如果想返回新的结果，使用no_cache方法。 Filtering queriesuser = User.objects(name=’liu zhi’) Query operators123456789101112ne – not equal to 不等于lt – less than 小于lte – less than or equal to 小于等于gt – greater than 大于gte – greater than or equal to 大于等于not – negate a standard check, may be used before other operators (e.g. Q(age__not__mod=5)) 否定其它条件，比如查询所有age不在[20, 30]中的 age__not__in=[20, 30]in – value is in list (a list of values should be provided)nin – value is not in list (a list of values should be provided)mod – value % x == y, where x and y are two provided valuesall – every item in list of values provided is in arraysize – the size of the array isexists – value for field exists String queriesThe following operators are available as shortcuts to querying with regular expressions: 123456789exact – string field exactly matches valueiexact – string field exactly matches value (case insensitive)contains – string field contains valueicontains – string field contains value (case insensitive)startswith – string field starts with valueistartswith – string field starts with value (case insensitive)endswith – string field ends with valueiendswith – string field ends with value (case insensitive)match – performs an $elemMatch so you can match an entire document within an array Geo queries(特定字段扩展的查询)PointField, LineStringField and PolygonField字段增加了特殊的查询方法，详情看文档。 Querying lists(查询list字段的扩展)Raw queries(pymongo查询)使用pyMongo的原生查询，document.objects(raw={‘name’: ‘liuzhi’}) Limiting and skipping results使用切片实现原生db.document.find().limit().skip()，get，first方法，get是检索唯一结果，如果有多个结果匹配，会触发MultipleObjectsReturned异常。get_or_create()已经弃用，最好不要使用，由于没有事务的原因，它不是安全的。 Default Document queries(扩展模型管理器)相当于对objects重写，使用特定的装饰器，方法名字可以自定义，这样可以做到使用原始的查询原始数据，使用自定义，查询自定义数据，比如自定义的只查询状态是正常的。123456789class BlogPost(Document): title = StringField() date = DateTimeField() @queryset_manager def objects(doc_cls, queryset): # This may actually also be done by defining a default ordering for # the document, but this illustrates the use of manager methods return queryset.order_by(&apos;-date&apos;) Custom QuerySets(封装查询集方法)把某些特定查询条件组合，通过新的方法获取查询集，可以给多个文档模型使用。12345678910class AwesomerQuerySet(QuerySet): def get_awesome(self): return self.filter(awesome=True)class Page(Document): meta = &#123;&apos;queryset_class&apos;: AwesomerQuerySet&#125;# To call:Page.objects.get_awesome() AggregationMongoDB的聚合方法objects 方法 count() 返回\bQuerySet() 数目 sun(‘quantitu’) 求和 average() 求平均","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"},{"name":"database","slug":"database","permalink":"http://www.liuzhidream.com/tags/database/"}]},{"title":"MySQL install-problem","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/MySql/install-problem/","text":"安装MySQL遇到的问题 安装遇到的问题安装软件总会遇到很多问题，很多问题仅在当时情况下出现，其实解决的思路都是大致的，多看报错和官方文档。 mysql.sock 无法被创建mysql 的链接需要借助这个套接字，如果不小心删除了，会导致服务无法运行 mac mysql 8.0.12安装教程 本次中Mac上使用非root账户来安装mysql，终于装好了。主要原因在于8.0版本配置（说是没有配置，但还说有，通过brew安装的可以在 /usr/local/etc 目录下找到配置文件，linux包管理软件安装的东西一般都在这个目录）没有配置东西，用的是默认的，这导致要创建链接的socket的时候没有指定目录使用了默认的 /tmp，没有执行/tmp的权限或者是用户所属等问题导致创建失败（并不是很建议去操作这个文件，有些人直接运行成功了，可能和个人的系统有很大关系）。无法创建mysql服务 大概解决思路mysql安装会在data目录下生成很多东西，如果没有或生成的不对，可以把目录删除了，通过启动服务来生成（我就说这么干的），然后配置了socket的客户端和服务端的路径，路径指向data即可（以为mysql的data是有执行权限的），这样服务就启动成功了，然后安装brew指导，创建root用户。配置1234[client]socket=/usr/local/lnmp/mysql/data/mysql.sock[mysqld]socket=/usr/local/lnmp/mysql/data/mysql.sock 两个都要指定 mysql.sock 无法创建，问题可能是多方面的，在data目录下，会生成 .err后缀的文件，可以在里面查看错误信息，然后结合经验来解决问题。 还有就是data目录下数据不对，这个目录应该有很多文件的，但是我一直没有，我通过删除，再执行服务成功生成了，感觉并不是很正确的解决思路。 mysqld –help –verbose | less这个目录可以列出mysql的一些信息，包括配置文件可能的路径，一些已经配置的参数。 最后，使用编译源代码的方式，估计是最后的活路。 报错：MySQL Illegal mix of collations for operation ‘like’MySQL Illegal mix of collations for operation ‘like’ 在 MySQL 5.5 以上, 若字段类型 Type 是 time,date,datetime 在 select时如果使用 like ‘%中文%’ 会出现 Illegal mix of collations for operation ‘like’ 在编程时要对每个字段进行查找，在执行时可能就会出现时间字段 like ‘%中文%’ 这种语法，在旧版的 MySQL 是不会出现错误的。 升到 MySQL 5.5 以上, 必需改成 like binary ‘%中文%’ 即可避免出现错误。 在python代码中，解决方案为使用cast(fields, CHAR)转换类型后再做like.(高mysql版本中使用like的使用，非字符类型和字符类型混合在filter条件中做like，就会导致这个问题)","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"database","slug":"database","permalink":"http://www.liuzhidream.com/tags/database/"}]},{"title":"sqlAlchemy-query","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/MySql/sqlAlchemy-query/","text":"MySQL 的 Python 版 ORM sqlAlchemy 查询操作notin_in_or_ 批量插入（非orm方式）123456# MemberCouponRecord 为要操作的表名db.session.execute( MemberCouponRecord.__table__.insert(), [&#123;'coupon_id': 'NO0001', 'member_id': 0002, 'update_time': get_current_time(), 'create_by': get_op_user_name()&#125; for item in item_data])db.session.commit()","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"},{"name":"database","slug":"database","permalink":"http://www.liuzhidream.com/tags/database/"}]},{"title":"计算机知识补充","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Other/README/","text":"计算机知识补充 为什么不要用记事本来写代码？可能有人会怪windows怎么那么傻，一个\\n不就可以了，为什么要用\\r\\n呢，给我们造成了多大的麻烦。其实这也不能怪windows。使用\\r\\n的历史可以追溯到遥远的19世纪。 那时候发明的打字机主要结构是一个实心圆筒+排列成菊花状的字模。纸张被牢牢地固定在圆筒的表面上。当我们按下一个字母的时候，机械装置引动字模”飞”向纸张，同时圆筒前的色带升起，用力地印下去，于是纸张上面就出现一个字了。印完之后，机械装置自动地让圆筒向左移动一个字母格子，方便打印下一个字符。打完一行之后，左手边上有一个摇杆，摇一下，圆筒就可以滚动一个行距，这是换行。不过，因为打字的时候圆筒总会不断地向左移动，所以打字员还需要用力地把圆筒推回右边，这就是传说中的回车了。在计算机里常见的换行操作在打字机里需要换行+回车两个操作。自然，计算机里不用这么麻烦，不过windows喜欢看起来更兼容一点。于是换行就成了\\r\\n了。 猴子补丁“猴子补丁”就是指，在函数或对象已经定义之后，再去改变它们的行为。 ScaleScale Out（也就是Scale horizontally）横向扩展，向外扩展 Scale Up（也就是Scale vertically）纵向扩展，向上扩展 无论是Scale Out，Scale Up，Scale In，实际上就是一种架构的概念，这些概念用在存储上可以，用在数据库上，网络上一样可以。 简单比喻下Scale out和Scale up，帮助我们理解： Scale Out，比如：我们向原有的web、邮件系统添加一个新机器。 Scale UP，比如：我们向原有的机器添加CPU、内存。 斜杠与反斜杠“\\”与“/”斜杠与反斜杠，只要知道，在windows路径里面用反斜杠，其它一般都是斜杠 \\ 转义，Python中加 r 不转义 r ‘\\t’ 结果是 \\t 秒的定义国际单位制词头经常与秒结合以做更细微的划分，例如ms（毫秒，千分之一秒）、μs（微秒，百万分之一秒）和ns（纳秒，十亿分之一秒）。虽然国际单位制词头虽然也可以用于扩增时间，例如Ks（千秒）、Ms（百万秒）和Gs（十亿秒），但实际上很少这样子使用，大家都还是习惯用60进制的分、时和24进制的日做为秒的扩充。 csv文件csv文件，使用逗号分隔，这种格式的文本可以导到excel 名词缩写进程间通信（Inter Process Communication，IPC） POSIX表示可移植操作系统接口（Portable Operating System Interface of UNIX，缩写为 POSIX ）这个标准制定了一些通用的东西，方便大家在实现的时候做到通用性，那么移植就不会有太大的问题了 SMP：对称多处理结构，一个计算机上使用多个CPU，而内存，总线是共享的 conditional requests : 条件请求，可以改变请求的资源 Cross Origin Resource Sharing（CORS）跨域资源共享 fd(file descriptor) 文件描述符 oom (out of memory) 内存溢出 oom killer 这个东西会在系统内存耗尽的情况下跳出来，选择性的干掉一些进程以求释放一些内存。具体的记录日志是在/var/log/messages中，如果出现了Out of memory字样，说明系统曾经出现过OOM！ utf-8 和 unicode必须知道的是，utf-8是unicode的一种实现方式，比如utf-16也是。互联网多采用utf-8，之所以出现unicode的多种实现，是因为为了表数多字符的二进制，需要使用多个字节，这带来的存储的不便利（比如在Unicode中英文用一个字节就行了，汉字会占用2个或3个等，如果大家都统一成4字节，倒是存储解析都可以了，但是大大浪费了空间，utf-8这种实现就是一种灵活的可变字节数的编码，如果符号只用一个字节，那么存储就是一个，需要多个就多个。如何解析呢？利用第一个字节的前几位表示这个符合占用几个字节，这样解析的时候就知道这次是拿几个字节出来解码成对应的符号，大大利用了空间。）编码过程：2条。1）单字节首位是0，其它7位是Unicode码。2）多字节，对于n字节的符号（n &gt; 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。 123字符 严 Unicode 100 111000 100101utf-8 111 0 (0100) 10 (111000) 10 (100101) 通过括号和空格分割，可以看道字符是如何从Unicode到utf-8的。 关于字节序：Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1。 如果一个文本文件的头两个字节是FE FF，就表示该文件采用大头方式；如果头两个字节是FF FE，就表示该文件采用小头方式。 事件句柄事件句柄又称为事件处理函数。它需要被赋值，比如将一个函数赋值给事件句柄。当特定事件发生的时候，就去检查事件句柄有没有被赋值，如果有，则执行事件句柄（执行该函数） 函数签名函数的名称及其参数类型组合在一起，就定义了一个唯一的特性，称为函数签名。（不包括返回类型） 在编写包含函数调用的语句时，编译器就会使用该调用创建一个函数签名。再把它与函数原型/或定义中可用的函数签名集比较。如果找到匹配的函数名，就建立所调用的函数。(c++的解释) 函数签名对象，表示调用函数的方式，即定义了函数的输入和输出。在Python中，可以使用标准库inspect的一些方法或类，来操作或创建函数签名。 重载多个相同函数名，不同的参数个数或者类型的形式叫做函数的重载。 arp -a这个Windows命令中有一个类型的概念 类型：动态的是说过一定时间如果这个mac地址没有用到过，就会被删掉；静态的会被永久保留 可重入函数可重入函数主要用于多任务环境中，一个可重入的函数简单来说就是可以被中断的函数，也就是说，可以在这个函数执行的任何时刻中断它，转入OS调度下去执行另外一段代码，而返回控制时不会出现什么错误；而不可重入的函数由于使用了一些系统资源，比如全局变量区，中断向量表等，所以它如果被中断的话，可能会出现问题，这类函数是不能运行在多任务环境下的。","tags":[{"name":"learn","slug":"learn","permalink":"http://www.liuzhidream.com/tags/learn/"},{"name":"other","slug":"other","permalink":"http://www.liuzhidream.com/tags/other/"}]},{"title":"collections模块","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/collections/","text":"python collections模块collections模块是python的内建模块，提供类很多实用的集合类。 nametuple(命名元组)从名字可以看出，这是一个对tuple定义name的类，通过nametuple创建的tuple有了名字，最重要的是可以通过属性来访问new tuple 的元素。 collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)Returns a new tuple subclass named typename. The new subclass is used to create tuple-like objects that have fields accessible by attribute lookup as well as being indexable and iterable. Instances of the subclass also have a helpful docstring (with typename and field_names) and a helpful repr() method which lists the tuple contents in a name=value format. 示例：12345from collections import namedtuplePoint = namedtuple('Point', ['x', 'y'])p = Point(11, 22)x, y = pprint(x, y) 输出 11 22 注意：field_name参数不能是关键字，也不能有重复。rename参数用于当field_name重名的时候，自动进行重命名。 12345from collections import namedtuplePoint = namedtuple('Point', ['x', 'y', 'x'], rename=True)p = Point(11, 22, 33)print(p)print(p._fields) 输出 Point(x=11, y=22, _2=33)(‘x’, ‘y’, ‘_2’)重命名的时候使用了下划线 _ 加元素所在索引数的方式进行重命名 classmethod somenamedtuple._make(iterable)该方法用来给实例赋值，这通常配合一些有序数据处理，如csv12345from collections import namedtuplePoint = namedtuple('Point', ['x', 'y'], rename=True)t = [11, 22]p = Point._make(t)print(Point, p) 输出 Point(x=11, y=22) deque(双向列表)使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，因为list是线性存储，数据量大的时候，插入和删除效率很低，deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈。 示例1234567from collections import dequeraw_list = ['1', '2', '3', 'a', 'b', 'c']new_list = deque(raw_list)new_list_2 = deque(['11', '22'])b = new_list_2 + new_listprint(b)print(new_list, type(new_list), isinstance(new_list, list)) OutPutdeque([‘11’, ‘22’, ‘1’, ‘2’, ‘3’, ‘a’, ‘b’, ‘c’])deque([‘1’, ‘2’, ‘3’, ‘a’, ‘b’, ‘c’]) False 可以看到，deque创建到列表不是list的实例，只有deque的实例能相互进行运算。deque支持的方法和list类似，多了像appendleft, popleft等方法，remove，reverse等通用方法，详情参考文档。 defaultdict在对字典操作的时候，如果没有值会key错误，通过defaultdict创建的字典，第一个参数传递一个callable对象或者None(None创建的字典和原字典没有区别)，如果key不存在则返回callable调用的值。12345from collections import defaultdicta = [('a', 2), ('b', 3)]_dict = defaultdict(int, a)print(_dict, isinstance(_dict, dict))print(_dict['aa']) OutPutdefaultdict(, {‘a’: 2, ‘b’: 3}) True0 使用int返回0，list返回[]，或者使用:lambda: ‘The key doesn’t exist’。对于需要对字典key不存在的时候，返回统一值，就可以使用defaultdict。使用get访问字典也是不错的编程习惯，在不想触发异常。 OrderedDict(有序字典)使用OrderedDict创建一个有序字典，在迭代的时候就按照创建的顺序来。1234from collections import OrderedDicta = [('a', 1), ('b', 2), ('c', 3)]_dict = OrderedDict(a)print(_dict, isinstance(_dict, dict)) Counter用来统计字符出现的个数，结果返回一个dict12345678from collections import Countera = [('a', 1), ('b', 2), ('c', 3)]c = Counter('aasjaslajl')c2 = Counter(['aasjaslajl', 'aa', 'bb', 'aa'])c3 = Counter(a)print(c, c2, c3)print(sorted(c3.elements()))print(isinstance(c, dict)) OutPutCounter({‘a’: 4, ‘s’: 2, ‘j’: 2, ‘l’: 2}) Counter({‘aa’: 2, ‘aasjaslajl’: 1, ‘bb’: 1}) Counter({(‘a’, 1): 1, (‘b’, 2): 1, (‘c’, 3): 1})[(‘a’, 1), (‘b’, 2), (‘c’, 3)]True","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"yaml","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Other/yaml/","text":"yaml 语言 基本语法 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 注释YAML 支持的数据结构有三种 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值 python 操作load 和 dump 方法load 加载 yaml 文件 dump将数据写入yaml文件 先创建一个文件对象 ，并加载 stream = file(&#39;example.yaml&#39;,&#39;r&#39;) dicts = yaml.load(stream) 这个时候，我们就可以去取值了 举例：yaml文件为 1234url:- www.baidu.com- www.taobao.com- vlcoa.inruan.com 这个属于数组，取值时用索引就可以了 print dicts[&#39;url&#39;][1] 结果是 www.taobao.com yaml文件为 12345language: top1: python top2: java 属于对象，language是一个字典 print dicts[&#39;language&#39;][&#39;top1&#39;] 结果 python 比较简单的配置文件： settime: 5 load后，dicts[settime]，就可以取到5了，冒号后面一点要有空格，使用数组就可以使用索引去取值，而且dicts到的是列表，可以去迭代参数，必须要用 ‘-‘ 加空格的形式，不能使用Tab键来缩进，一定要用空格。","tags":[{"name":"other","slug":"other","permalink":"http://www.liuzhidream.com/tags/other/"},{"name":"yaml","slug":"yaml","permalink":"http://www.liuzhidream.com/tags/yaml/"}]},{"title":"python-patter相关设计模式","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/patter/","text":"Python常见设计模式 Borg 模式这个模式创建的实例，属性都是共享的 12345678910111213141516171819202122def borg(cls): cls._state = &#123;&#125; orig_init = cls.__init__ def new_init(self, *args, **kwargs): self.__dict__ = cls._state orig_init(self, *args, **kwargs) cls.__init__ = new_init return cls@borgclass A: ...a = A()a.b = '2'b = A()print(a.b, b.b) Pool 对象池模式以下代码实现了维护一定线程池 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import timeimport threadingfrom contextlib import contextmanagerclass ObjectPool: def __init__(self, klass, *args, max_size=None, timeout=0.5, **kwargs): self._klass = klass self._max_size = max_size self._size = 0 self._args = args self._kwargs = kwargs self._tiemout = timeout self._items = [] self._mutex = threading.Lock() self._item_available = threading.Condition(self._mutex) def get(self): with self._mutex: if not self._items and (self._max_size is None or self._size &lt; self._max_size): item = self._klass(*self._args, **self._kwargs) self._size += 1 else: while not self._items: self._item_available.wait(self._tiemout) item = self._items.pop() return item def put(self, item): with self._mutex: self._items.append(item) self._item_available.notify() @contextmanager def item(self): item = self.get() try: yield item finally: self.put(item)class Test: def __init__(self, a, b=1): self.a = a self.b = bpool = ObjectPool(Test, 1, b=2, max_size=3)class MyThread(threading.Thread): def run(self): with pool.item() as item: print(f'&lt;&#123;item.__class__.__name__&#125; at &#123;id(item)&#125;&gt;') time.sleep(0.1)def main(): threads = [] for i in range(10): t = MyThread() t.start() threads.append(t) for t in threads: t.join(True)if __name__ == '__main__': main()","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"gunicorn","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/gunicorn/","text":"Gunicorn ‘Green Unicorn’ is a Python WSGI HTTP Server for UNIX. It’s a pre-fork worker model. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy. 运行gunicorn -w 2 --threads=4 application:app -b localhost:8080 -w 指启动的进程数量如2 ps -ef|grep python 可以看到python共有3个进程，其中一个主进程和两个work进程（两个work进程是master的子进程） gunicorn 工作模式 sync eventlet - Requires eventlet &gt;= 0.9.7 gevent - Requires gevent &gt;= 0.13 tornado - Requires tornado &gt;= 0.2 gthread - Python 2 requires the futures package to be installed gaiohttp - Requires Python 3.4 and aiohttp &gt;= 0.21.5 Linux进程有父进程和子进程之分,windows的进程是平等关系 gunicorn的同步模式，一次只处理一个请求（此时使用一个进程，4个线程来处理任务，任意时刻只能有一个请求被执行吗？） 虽然python有GIL，但不是所有操作都是线程安全的 问题遇到的问题汇总 启动django项目，找不到静态资源gunicorn 来直接启动django项目，找不到静态资源，在url配置文件中加入 123from django.contrib.staticfiles.urls import staticfiles_urlpatternsurlpatterns += staticfiles_urlpatterns() 问题解决来自 Stack Overflow","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"python-virtualenv","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/virtualenv/","text":"python 虚拟环境 使用虚拟环境是很有必要的，在windows和Linux上还是有区别的。 Linux python virtualenv大致和windows上是一样的，安装virtualenv virtualenv -p 解释器目录 virtual目录 ls /usr/bin/python* 一般现在的linux都有python3，在这里指定解释器就可以了，没有就装一个 source py34env/bin/activate 激活 deactivate 退出 windows上的虚拟环境还是不能直接在linux上用，虽然可以跑，但是创建这个虚拟环境的时候是指定了解释器的，直接跑解释器不对，包的内容和版本也不对，所以还是在linux上创建虚拟环境吧。 virtualenvwrappervirtualenvwrapper 是对virtualenv的扩展，利用它管理虚拟环境，最好的特征就是直接用命令就可以进入虚拟环境，不用像原来一样需要切换到目录下进入。简书 基本命令 workon 查看虚拟环境 workon 环境名称 进入对应虚拟环境 deactivate 退出环境 export WORKON_HOME=/ 环境安装路径 export VIRTUALENVWRAPPER_PATHON= / python解释器路径 source / virtualenvwrapper.sh 路径 我的流程： pip 安装 virtualenvwrapper virtualenv 配置 ~/.bash_profile 为上面内容 把virtualenv添加符号链接 source ~/.bash_profile(激活环境变量，让workon命令可以被执行到，仅本次登陆有效) Anaconda该软件有新的包管理工具 conda 这个不仅是python，是一个其它语言也可以用的包管理工具。用conda命令安装的python包，会去寻找相关依赖，提示你需要安装依赖，并一起安装。而pip虽然也会连同依赖一起装（听说没有conda好），但是有些包不会（猜测依赖的机制是包自身的，有些第三方包没有做这个处理，导致你安装了后，运行报错还要去装其它的，个人猜测）。 conda env export &gt; environment.yaml 命令导出当前虚拟环境，可以用这个文件恢复虚拟环境。这个文件中有一个pip相关的信息，记录了该环境用pip安装的包。 虽然用了conda，但是还是有一些包没法安装，还得用pip安装（猜测是一些个人写的包，不出名，没在conda上记录，或者就是单纯的没有记录）conda 和 pip ，conda可以管理pip和自己安装的包（用conda list查看），pip好像不行，只能管理自己的。 关于安装的时候是否选择添加到path，如果你电脑已经有了python，就不要选了。选了这个直接在命令行输入python，就会使用Anaconda的虚拟环境。 在新的虚拟环境中执行 pip install -r requirements.txt 导入pip安装的包 activate 环境名称：进入对应环境 conda env list：列出当前环境 mac下进入环境，前面加 source 心得：Anaconda也用了一段时间，感觉并没有网上说的那么强大，对于一些科学计算，或者说是由其它语言编写，Python来调用的那种包，对，就是那种很高端的，是可以用conda安装管理的，但是像一些小包，尤其是纯Python写的，只有pip才能安装，这样你还是摆脱不了pip，重点软件非常大，太大了，比较适合做开发用，数据分析方向用。 pipenv又是一个新的虚拟环境工具，相比virtualenv功能上更加强大，由于是较新的工具，设计上考虑就比较全面。通过pip install来安装，在项目对应目录执行 pipenv install --dev 使用系统Python版本来为此项目创建虚拟环境，生成Pipfile，Pipfile.lock文件。使用 pipenv python 3.6 的形式指定版本。通过帮助可以查看更多命令。 Pipfile &amp; Pipfile.lock： Pipfile是用来代替原来的requirements.txt的，source部分用来设置仓库地址，packages部分用来指定项目依赖的包，dev-packages部分用来指定开发环境需要的包，这样分开便于管理。而Pipfile.lock中记录了当前环境中安装的依赖的版本号以及哈希，以保证每次装出来的依赖都是一致的。 pipenv install --dev 用来安装当前项目中dev-packages中的包，没有环境的会创建虚拟环境。 在 Dockerfile 中安装依赖，加–system参数表示使用 pip 直接安装相应依赖，不创建虚拟环境。 RUN pipenv install --deploy --system pipenv install --dev django，pipenv install django 安装django包，第一种安装在dev-packages里面，这样在部署的时候通过 pipenv install 安装，只会安装packages里面的，把开发环境的包过滤了，这很有用，要全部安装，应该 pipenv insyall --dev 在项目目录中编写 .env，可以在进入虚拟环境后，把env文件中的环境变量加载，这个就很有用了 关于IDE支持：pycharm中，最新版本已经支持了，然而我用的mac版试了还是不行，而且我看源码的执行文件，明确说明不能直接执行此文件，这就很尴尬了，从使用virtualenv的经验来看，配置操作是没问题的，而且我查了官方文档，发现官方的情况和我的不符合。我推测是Windows环境的版本才支持，可能mac版还不行（但是软件中是有配置项，这就很尴尬了，暂时使用常规虚拟环境配置吧）。 无敌的环境还是有bug，在安装amqp的时候，生成Pipfile文件是叫pyamqp，而且我看有些书上也是叫pyamqp的，不过官方的包库中，找不到pyamqp，这导致了锁定版本的时候出了问题，估计是改了名字pipenv没有反应过来。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"pytest","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/pytest/","text":"pytest，Python的单元测试工具 命令1234py.testpy.test --versionpy.test name.pypy.test --resultlog=report 保存测试报告 测试文件以test_开头（以_test结尾也可以） 测试类以Test开头，并且不能带有 init 方法 测试函数以test_开头 断言使用基本的assert即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263一些命令py.test # run all tests below current dir py.test test_mod.py # run tests in module py.test somepath # run all tests below somepath py.test -k stringexpr # only run tests with names that match the # the &quot;string expression&quot;, e.g. &quot;MyClass and not method&quot; # will select TestMyClass.test_something # but not TestMyClass.test_method_simple py.test test_mod.py::test_func # only run tests that match the &quot;node ID&quot;, # e.g &quot;test_mod.py::test_func&quot; will select # only test_func in test_mod.py ``` ## 相关装饰器讲解 @pytest.fixture(scope=&quot;module&quot;)这个装饰器会让被装饰的函数只执行一次，通常用来装饰需要在多个测试直接使用到的同一个变量，例如：```python@pytest.fixture(scope=&apos;module&apos;)def get_result(): return 1``` 把上面的代码放入conftest.py 文件中（经测试这个文件名字不能改，不知道为什么）这样在其它测试文件中，我们可以把get_result做为参数传入，例如：文件 test_func.py```pythonclass TestApi: def test_func(self, get_result): a = get_result assert a != 1``` pytest.mark.usefixtures 装饰器的使用，就是显式的调用，先用@pytest.fixture()把需要公用的函数做装饰，使用的时候通过pytest.mark.usefixtures装饰，就可以得到公用函数了，下面展示了使用三种方法：```pythonimport pytest@pytest.fixture()def before(): print(&apos;\\nbefore each test&apos;)@pytest.mark.usefixtures(&quot;before&quot;)def test_1(): print(&apos;test_1()&apos;)@pytest.mark.usefixtures(&quot;before&quot;)def test_2(): print(&apos;test_2()&apos;)class Test1: @pytest.mark.usefixtures(&quot;before&quot;) def test_3(self): print(&apos;test_1()&apos;) @pytest.mark.usefixtures(&quot;before&quot;) def test_4(self): print(&apos;test_2()&apos;)@pytest.mark.usefixtures(&quot;before&quot;)class Test2: def test_5(self): print(&apos;test_1()&apos;) def test_6(self): print(&apos;test_2()&apos;) 关于 fixture 的scope参数 function：每个test都运行，默认是function的scope class：每个class的所有test只运行一次 module：每个module的所有test只运行一次 session：每个session只运行一次 比如你的所有test都需要连接同一个数据库，那可以设置为module，只需要连接一次数据库，对于module内的所有test，这样可以极大的提高运行效率。 autouse 参数 这个参数默认是Fals, 设置为True的时候，一个session的所有test都会自动调用autouse设置为True的fixture。就是自动调用了，你都不需要把fixture作为参数传入，比如你的fixture写成打印一些友好提示，这样在每个测试执行的时候，这些提示都会打印出来。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Python-socket","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python-socket/README/","text":"python网络编程笔记 EAGAIN当客户通过Socket提供的send函数发送大的数据包时，就可能返回一个EAGAIN的错误。该错误产生的原因是由于 send 函数中的size变量大小超过了tcp_sendspace的值。tcp_sendspace定义了应用在调用send之前能够在kernel中缓存的数据量。当应用程序在socket中设置了O_NDELAY或者O_NONBLOCK属性后，如果发送缓存被占满，send就会返回EAGAIN的错误。 acceptaccept()是在一个套接口接受的一个连接。accept（）是c语言中网络编程的重要的函数，本函数从s的等待连接队列中抽取第一个连接，创建一个与s同类的新的套接口并返回句柄 socket.listen(backlog)开始监听传入连接。backlog指定在拒绝连接之前，可以挂起的最大连接数量。 backlog等于5，表示内核已经接到了连接请求，但服务器还没有调用accept进行处理的连接个数最大为5这个值不能无限大，因为要在内核中维护连接队列。 closeclose方法可以释放一个连接的资源，但是不是立即释放，如果想立即释放，那么在close之前使用shutdown方法shut_rd() ——-关闭接受消息通道shut_wr()——–关闭发送消息通道shut_rdwr()——-连个通道都关闭使用：在close()之前加上shutdown(num)即可 [shut_rd(), shut_wr(), shut_rdwr()分别代表num 为0 1 2 ]（但是测试过close()关闭，发现如果关闭后，那么accept()得到的connection就马上不能用了[提示不能在非套接字上]）","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"PythonUtil","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/PythonUtil/README/","text":"python 偷懒小工具，通过编写脚本实现日常功能 markdown table 语法生成1234567891011121314151617181920212223242526272829303132333435363738\"\"\"markdown 的table语法格式 自动生成代码，错误的地方需要手动处理一下，中文因为字符占位问题，无法做到统一格式化\"\"\"op_str = '''v-bind ：动态绑定数据。简写为“:” 。=&gt; 以后的:class=\"&#123;red:boolean&#125;\"v-on ：绑定时间监听器。简写为“@”，例：@click=\"xxx\"；v-text ：更新数据，会覆盖已有结构。类似&#123;&#123; msg &#125;&#125; ；v-show ：根据值的真假，切换元素的display属性；v-if ：根据值的真假，切换元素会被销毁、重建； =&gt; 在dom中已消失v-else-if ：多条件判断，为真则渲染；v-else ：条件都不符合时渲染；v-for ：基于源数据多次渲染元素或模块；v-model ：在表单控件元素（input等）上创建双向数据绑定（数据源）；v-pre ：跳过元素和子元素的编译过程；v-once ：只渲染一次，随后数据更新也不重新渲染；v-cloak ：隐藏未编译的Mustache语法，在css中设置[v-cloak]&#123;display:none;&#125;'''_op_str = op_str.split('\\n')_op_str.pop()out_str = ''max_str_len = len('v-else-if') # pop(key[, default])space = ' 'for item in _op_str: tmp = item.split(' ') if tmp[0] == '': tmp_str = \"| Command&#123;space&#125; | Description \\n\".format(space=space * (max_str_len - len('Command'))) tmp_str += \"| &#123;a&#125; | :&#123;b&#125;: \\n\".format(a='-' * max_str_len, b='-' * (max_str_len - 2)) else: tmp_str = \"| &#123;a&#125;&#123;space&#125; | &#123;b&#125; \\n\".format(a=tmp[0], b=''.join(tmp[1:]), space=space * (max_str_len - len(tmp[0]))) out_str += tmp_strprint(out_str)# print(len('Inheritor'))","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"python常用方法","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/PythonUtil/common_tool/","text":"记录python常用方法 获取文件所在目录12345import ospath = os.path.dirname(os.path.abspath(__file__))print(path) dict扩展12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class AttrDict(object): \"\"\" 不继承dict，实现一个dict，实例化使用关键字参数的形式：AttrDict(a=1, b=2) __getitem__，__setitem__，__delitem__称为容器方法，就是_dict['a']这种操作的 拦截，而__getattribute__（访问属性先执行这个，然后执行__getattr__）， __setattr__这种才是属性拦截，通过把关键字参数赋值给__dict__，实现了可以通过 _dict.a 或 _dict['a'] 的形式访问字典键值 \"\"\" def __init__(self, **kwargs): self.__dict__.update(**kwargs) def __getitem__(self, item): return self.__getattribute__(item) def __setitem__(self, key, value): return self.__setattr__(key, value) def __delitem__(self, key): return self.__delattr__(key) def __len__(self): return len(self.__dict__)attr_dict = AttrDict(a=2, b=3)print(attr_dict['a'])print(attr_dict.a)# print(attr_dict.get('a')) 报错的，这是字典的方法，这个类没有继承字典class AttrDict2(dict): \"\"\" 继承dict，扩展链式操作 \"\"\" def __init__(self, *args, **kwargs): print('init a dict') # dict.__init__(self, *args, **kwargs) # 同下super的效果 super().__init__(*args, **kwargs) # 继承dict的对象，对象的实例就是一个字典，print(_dict)可以看到，既然如此，把这个 # 字典给到__dict__，那么对象的属性就有了 self.__dict__ = self_dict = AttrDict2()_dict['a'] = 33print(_dict)print(_dict.__dict__)# 如果再次执行_dict['b'] = 44，已经不执行__init__方法了，但是self.__dict__ = self已经关联了，# dict做为可变变量类型，同样更新了__dict___dict['b'] = 44print(_dict)print(_dict.__dict__)print(_dict.a, _dict.b)","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Core-python-programming 读书笔记","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/ReadBook/Core-python-programming/","text":"Python 核心编程 读书笔记，节选部分内容 CGICGI： 对于静态资源（文件图片等，或者静态的HTML页面），利用web服务器就可以处理了（比如nginx），而动态资源（计算出来的数据）就要用CGI应用程序来处理。python可以用命令就在本地创建一个服务器，接着导入CGI模块，编写如何渲染页面的应用程序，就实现了CGI了。但是这种方式已经被淘汰了，一个弊端例如： 这种方式无法扩展，CGI 进程（类似 Python 解释器）针对每个请求进行创建，用完就抛弃。 如果应用程序接收数千个请求，创建大量的语言解释器进程很快就会导致服务器停机。有两种方法可以解决这个问题，一是服务器集成，二是外部进程。因此CGI被框架或新的东西代替了。 web服务器一般用C写，而应用程序用各种语言都可以。 CGI是web服务器与应用程序（CGI程序）接口标准，两个直接信息传递的规程。这个规范运行web服务器执行外部程序，就是CGI程序，这样就实现了获取动态资源。这种方式每次来一个请求就要创建一个子进程，处理完成再结束这个子进程，就是fork-and-execute模式。后来又设计出了wsgi，成为web网关服务接口，也是在web服务器和应用程序之间提供一个通用的API标准。 好了，我们来做一个总结，CGI是标准，WSGI也是标准，我们用CGI标准实现一个应用程序，用于处理动态数据并返回渲染后的HTML页面（其中一种情况），可以用python来实现这个程序。一个请求来的时候，用CGI方式的话，就会创建一个CGI子进程（我们不要管是谁来创建这个子进程的），然后子进程调用CGI程序得到返回数据传给客户端。 WSGI也是一个标准，我们会实现一个服务，这个服务负责处理请求，并将请求分配到对应的应用程序上。看起来有点类似，这个处理请求和分配到应用程序上的基于WSGI标准的程序不用像CGI那样每次都要创建子进程。在django的默认处理里面，就有wsgi程序。 WSGI,实现这一标准的服务器，比如uWSGI, Gunicorn 。称为wsgi服务器，也就是server，这个服务器需要和一个实现WSGI规范的接口相配合，一般定义一个函application(environ,start_response)。 RE核心提示：搜索和匹配的比较 本章通篇会使用搜索和匹配两个术语。当严格讨论与字符串中模式相关的正则表达式时，我们会用术语“匹配”（matching），指的是术语“模式匹配”（pattern-matching）。在Python 术语中，主要有两种方法完成模式匹配：“搜索”（searching），即在字符串任意部分中搜索匹配的模式；而“匹配”（matching）是指判断一个字符串能否从起始处全部或者部分地匹配某个模式。搜索通过 search()函数或方法来实现，而匹配通过调用 match()函数或方法实现。总之，当涉及模式时，全部使用术语“匹配”；我们按照 Python 如何完成模式匹配的方式来区分“搜索”和“匹配”。 如何写出灵活的re是关键，比如 .+ 就可以匹配任意长度的字符串，再和其它元字符等配合，可以实现高效的组合 理解re表达式，结合模块的方法即可使用RE（可以概况为RE表达式和python语言） 理解返回的结果 预编译：re.compile() 匹配 ： 一般指模式匹配。如何完成模式匹配？主要使用“搜索”和“匹配”两种方法实现 re的组成：通用文本，如hello。特殊符号和字符，称为元字符 元字符表： image image 择一匹配 “|” re=’hello|world’ 匹配任意单个字符串 “.” re = ‘fa.b’ 可以匹配a和b之间可以是任意字符（换行除外，修改编译标记可以解除这个限制）。可以使用多个点 .. 则匹配任意两个 .灵活用在文本的前面后面，中间。 数量词的贪婪模式与非贪婪模式 贪婪 总是尝试匹配尽可能多的字符 非贪婪 总是尝试匹配尽可能少的字符 正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab“如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab?”，将找到”a”。 compile 标记参数： re.I(re.IGNORECASE): 忽略大小写（括号内是完整写法，下同） M(MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图） S(DOTALL): 点任意匹配模式，改变’.’的行为 L(LOCALE): 使预定字符类 \\w \\W \\b \\B \\s \\S 取决于当前区域设定 U(UNICODE): 使预定字符类 \\w \\W \\b \\B \\s \\S \\d \\D 取决于unicode定义的字符属性 X(VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。 字符集 [abc] 限定范围和否定 [a-b] 常用符号 * o次或者多次 + 1次或者多次 ？ 0次或者一次 o次就是允许没有，比如z? 分析它是一个通用文本 “？” 号将前面的通用文本进行一次或0次匹配。 比如zz, zx都是可以匹配到的，如此 * + 也就理解了。 {0，1} 前一个正则匹配的次数0次或1次，使用符号为{} 注意：这些符号是对通用文本的扩充，比如原来的re=aa, 如果你想匹配8个a,好的做法是a{8}, 而不是写8个a. 表示字符集的特殊字符：\\d 数字 \\w字母（大小写） 他们的大写如 \\D 表示不匹配，即非十进制数字。 分组：提取任何已经成功匹配的特定字符串或者子字符串 使用（）包裹re表达式，可以进行分组或匹配子组，注意这两个的区别： 分组：被包裹的re表达式会是一个整体，一般在后面接上量词。每一个括号得到分组为组1，后面的分组累加 (a(b)) 组1 ab 组2 b 子组：上面得到的组1就是子组了，可以称为子组1 扩展表示法：通常形式（?…） 尽管圆括号使用这些符号，但是只有（?P\\）表述一个分组匹配。所有其他的都没有创建一个分组。 边界匹配 ： 符号 \\b \\B \\b是一个单词的边界匹配， r’\\ber’ 能匹配 ‘a er’ 不能匹配 ‘aer’要匹配 ’aer‘ re=r’er\\b’ 闭合操作符是非贪婪的 语言 re可以先进行预编译，用得到的编译对象再去操作函数或方法，也可以用模块（re）直接调用方法，这个时候需要传入pattern参数，即一个re表达式。 理解搜索和匹配，匹配是从头开始，如果第一个字符串就不匹配，则匹配模式失败，如果用搜索模式，则会把被匹配对象从头到尾都匹配一编，中间有符合条件的就可以得到匹配结果。 findall() 该函数返回正则表达式模式全部的非重复情况，结果是一个列表，没有匹配就是空列表。 这个函数的结果就是一个列表了，它没有group等属性了。 finditer()和上面的类似，结果是一个迭代器。 sub()和 subn()搜索与替换 功能就是将字符串能匹配到的都替换成其它字符串，subn会返回替换计数。 split()分隔字符串：匹配成功的时候进行，号分割，返回的是分割后结果的列表。即一个字符串，左到右，满足条件就进行分割。 扩展表示： 在分组的时候重新起一个名字‘z’ re = r’ns(?P\\\\d+)’ re.match(ns7).group(‘z’) out: 7 数量词组合：+， * 这两个是贪婪的，可以在后面加上？ 变成非贪婪。 re = ‘.+c’ str=’abcabc’ out=’abcabc’ 如果re=’.+?’ out=’abc’","tags":[{"name":"readbook","slug":"readbook","permalink":"http://www.liuzhidream.com/tags/readbook/"}]},{"title":"javascript-definitive-guide 读书笔记","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/ReadBook/javascript-definitive-guide/","text":"JavaScript 权威指南 读书笔记，节选部分内容 关于分号关于分号，分号可以不要，如果你不要分号，语句会被解释器连起来。 比如： 12var x = y + z(a+b).result() 实际是 var x = y + z(a+b).result() 分号是语句的结束，你不加分号解释器会自己来处理，它处理不了的语句会自己加分号，等等一些规则，所以养成加分号是好习惯，避免前面的语句改了，没有分号语句被解释器组合了。","tags":[{"name":"readbook","slug":"readbook","permalink":"http://www.liuzhidream.com/tags/readbook/"}]},{"title":"博客迁移","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Water/UseHexo/","text":"关于博客迁移，最开始是在有道上做笔记，学习记录，后来萌生了写类似博客网站的想法，于是用element-UI框架写了一个，整体的效果还不错，还有一个后台管理，使用Django作为web服务，每篇文章存储在数据库，但是想要的功能太多了，设计的功能也显得格格不入（完全按照自己的想法来），后来放弃了，转用了VuePress，后来又看到Hexo，还是迁移到Hexo吧。开始使用VuePress，也是因为作者说会在后续添加博客的功能，结果没有后续了，Hexo作为博客提供了很全面的功能 博客迁移关于博客迁移，最开始是在有道上做笔记，学习记录，后来萌生了写类似博客网站的想法，于是用element-UI框架写了一个，整体的效果还不错，还有一个后台管理，使用Django作为web服务，每篇文章存储在数据库，但是想要的功能太多了，设计的功能也显得格格不入（完全按照自己的想法来），后来放弃了，转用了VuePress，后来又看到Hexo，还是迁移到Hexo吧。开始使用VuePress，也是因为作者说会在后续添加博客的功能，结果没有后续了，Hexo作为博客提供了很全面的功能 迁移脚本大概扫描了一下Hexo的官方，马上起了一个项目，发现这个文件结构和VuePress差的有点多啊，不怕，写个迁移脚本就行了，这样就把原来文件结构都取出来放到通用目录下，顺便生成一下Hexo的yaml-Front-matter，对README的文件做一下重命名。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#!/usr/bin/env python# -*- coding: utf-8 -*-\"\"\"@author: LiuZhi@file: hexo_change.py@time: 2019-10-22 23:48@contact: vanliuzhi@qq.com@software: PyCharm\"\"\"import ospath = '/Users/liuzhi/PycharmProjects/test_code/zh/'op_list = os.listdir(path)write_data2 = '''---title: %sdate: 2018-10-22 00:00:00updated: 2018-10-22 00:00:00tags:categories:---'''def write_data(title): a = write_data2 % title return adef get_absolute_path(dir_name): return path + dir_namedef get_dir_file(_dir, result): if _dir != '/Users/liuzhi/PycharmProjects/test_code/zh/.DS_Store': for item in os.listdir(_dir): res = _dir + '/' + item result.append(res)def loop_file_path(): result = [] dir_list = map(get_absolute_path, op_list) for i in list(dir_list): get_dir_file(i, result) print(result) return resultdef save_name(_dir, data): _list = _dir.split('/') name = _list[-1] if name == 'README.md': name = _list[-2] + '.md' with open('/Users/liuzhi/PycharmProjects/test_code/result/' + name, 'w') as f: f.write(data)def get_name(_dir): _list = _dir.split('/') name = _list[-1] if name == 'README.md': name = _list[-2] + '.md' return name[:-3]def hexo_change(): \"\"\" 实现在文件头写入，不能使用a+模式，需要截断成0字节 总体来说，要实现任意位置写入，只能是通过读取整个文件，然后将 需要写入的插入，然后把整个结果写入 :param file_name: :return: \"\"\" for file_name in loop_file_path(): with open(file_name, 'r+') as _file: old = _file.read() _file.seek(0) _file.write(write_data(get_name(file_name))) _file.write(old) for file_name in loop_file_path(): with open(file_name, 'r+') as _file: old = _file.read() save_name(file_name, old)def insert_content_to_file(): file = open(\"a.txt\", \"r\") file_add = open(\"a.txt\", \"r\") content = file.read() content_add = file_add.read() pos = content.find(\"buildTypes\") if pos != -1: content = content[:pos] + content_add + content[pos:] file = open(\"a.txt\", \"w\") file.write(content) file.close() file_add.close()def init(): cp_cmd = 'cp -rf ~/JavaScriptProjects/my-notebook/docs/zh/ ~/PycharmProjects/test_code/zh' rm_zh = 'rm -rf ~/PycharmProjects/test_code/zh/' mark_dir = 'mkdir ~/PycharmProjects/test_code/zh' cmd_list = [rm_zh, mark_dir, cp_cmd] for i in cmd_list: os.system(i) # map(lambda x: os.system(x), cmd_list)def cp_new_file(): cp_cmd = 'cp -rf ~/PycharmProjects/test_code/result/ /Users/liuzhi/JavaScriptProjects/hexo_blog/source/_posts' os.system(cp_cmd)if __name__ == '__main__': # init() # hexo_change() cp_new_file() 采坑浏览过一遍文档，如果不着急搞分享，评论什么的，上手会很快，开始我的图片资源也是没有问题了，直到我看了官方的资源文件夹功能，它提出了一个顾虑（我真的没感觉到会有这个问题，分类和主页的资源，怎么会有路径问题呢？难道是历史原因），推荐使用此功能，需要进行对应的配置，使用{% asset_img example.jpg This is an example image %}，坑就坑在这么用完全没效果，然后我Google，发现别人都是装插件的，查了我的package.json，没插件啊，官方这文档不负责啊。 然而坑还没结束，装了插件仍然没用，于是我去看了GitHub对插件的用法，需要使用Markdown语法，我真是哔了狗了，Hexo的文档英文也是明确说明不要使用Markdown语法，用插件语法，这完全没用啊，看了别人的用法也是用Markdown语法。 最后，经过我的测试，使用Markdown语法，配合插件可以使用相对路径，如果这样用，你的每篇博客不能创建独立的文件夹，只能放在_posts下，不知道是BUG还是什么问题，总之一点官方文档给的用法没有效果，插件的作者都没这么用，个人猜测框架扩展了插件后，使用插件语法应该是没问题的，Hexo支持这么多插件，然而在这个插件上出了问题估计是BUG了。 解决方案：使用Markdown语法，图片放在_posts/images下，由于这是绝对路径，部署和本地都是正常的，另外不一定要把文章放在_posts下，可以再创建一个父级目录，虽然编译后文章被分类了，但是原始项目这么搞就太混乱了，这让我觉得使用命令创建文章有点鸡肋了。","tags":[{"name":"water","slug":"water","permalink":"http://www.liuzhidream.com/tags/water/"}]},{"title":"Nginx","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/Nginx/","text":"Nginx (engine x) 是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务。 配置nginx的配置, 一般就是配server模块，该模块的全局定义，location 定义了正则的解析（向服务器请求各种资源，nginx应该如何处理）","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"RESTFulAPI","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/RESTFulAPI/","text":"一种接口风格，使用一种通用的风格，在团队开发中，也便于沟通。 概念REST风格5个约束：客户端-服务端，无状态，缓存，统一接口，分层系统 使用名词表示资源，动词通过HTTP方法来实现，比如删除资源使用DELETE方法。 关注请求头，比如请求头Accept要求返回application/xml，如果服务器只能放回json格式的，应该返回406错误。 使用正确的请求方法和状态码 不能一味的使用POST和GET方法，HTTP方法表 Name Description OPTIONS 用于获取资源支持的所以HTTP方法 HRAD 用于只获取请求某个资源返回的头信息 GET 用于从服务器获取某个资源的信息：1.完成请求后，返回状态码200 OK 2.完成请求后，需要返回被请求的资源详细信息 POST 用于创建新资源：1.创建完成后，返回状态码201 Created 2.完成请求后，需要返回被创建的资源详细信息 PUT 用于完整的替换资源或者创建指定身份的资源：1.如果是创建了资源，则返回201 Created 2.如果是替换了资源，则返回200 OK PATCH 用于局部更新资源：1.完成请求后，返回状态码200 OK 2.完成请求后，需要返回被修改的资源详细信息 3.完成请求后，需返回被修改的资源详细信息 DELETE 用于删除某个资源，完成请求后返回状态码204 No Content 对输出结果不在封装：通过状态码来判断请求，不应该把信息写在响应体中","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"RabbitMQ","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/RabbitMQ/","text":"MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。 概念需要了解一个协议：AMQP协议，协议的流程由消息发布者，交换机，队列，到消息订阅者。交换机做路由分发，将收到的消息根据路由规则分发给绑定的队列。 消息：消息实际包含两部分内容，1是有效载荷，就是要传输的数据，数据类型可以是纯文本或JSON。2是标签，它包含交换机的名字和可选的主题(topic)标记等，AMQP仅仅描述了标签，而RabbitMQ决定了把这个消息发给哪个消费者。 发布者：也就是生产者，创建消息并设置标签 消费者：消费者连接到代理服务器上，接受有效载荷，消费者不需要消息中的标签 消息投递失败会重发，保证消息正确取出和执行，AMQP模块包含了消息确认的概念，在收到消费者的确认回执前，消息代理不会将消息从队列中删除。 交换机交换机拿到消息后，将路由给队列，使用哪种路由算法是由交换机类型和被称作“绑定（queue_bind）”的规则决定的。 可配置的队列如下： 直连交换机（direct exchange） 根据消息携带的路由键(routing key)将消息投递给对应的队列。将一个队列绑定到某个交换机的同时赋予该绑定一个路由键，当一个携带者路由键为XXX的消息被发送给直连交换机时，交换机会把它路由给绑定值同样为XXX的队列。直连交换机用来处理消息的单播路由。 主题交换机（topic exchange） 通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。主题交换机通常用来实现消息的多播路由。发送到主题交换机的消息的路由键，必须是一个由 “.” 分隔的词语列表，这些词语应该和对应的业务关联，词语的个数可以随意，但是不要超过255字节。绑定键支持通配符：“*” 用来表示一个单词；“#” 用来表示任意数量(零个或多个)单词。 扇形交换机（fanout exchange） 将消息路由给绑定到它身上的所有队列，且不理会绑定的路由键。用来做消息的广播路由。它允许你对单条消息做不同的处理，在开发中一个操作可能要多个连带工作，比如用户创建一篇新的日记，需要更新用户的创建日记数，清除相关缓存，给关注这个用户的其他用户推消息，日记进审核后台，日记进最新日记池等等。可以使用扇形交换机把一个消息分发给多个任务队列，执行不一样的工作。尤其是业务改变时，使用扇形交换机直接为新的消费者添加声明，并绑定进来就可以了，否则需要修改发送方的代码来添加接收方。所以，使用扇形交换机可以有效地解耦发送者和消费者。 头交换机（headers exchange） 允许匹配AMQP的头而非路由键，其实使用起来和直接交换机差不多，但是性能却差很多，一般用不到这种类型。 虚拟主机通过创建新的虚拟主机，实现隔离，不同的虚拟主机直接完全隔离，拥有自己的队列，绑定和交换机。就像创建了一个新用户，服务A做订单的，链接对应的虚拟主机，服务B做消息推送的，链接对应的虚拟主机。默认是虚拟主机是 /，使用guest做默认用户和密码，通过命令创建新的虚拟主机： 123sudo rabbitmqctl add_user dongwm 123456sudo rabbitmqctl add_vhost web_developsudo rabbitmqctl set_permissions -p web_develop dongwm \".*\" \".*\" \".*\" rabbitmqctl set_permissions 是配置权限，三个对应的权限是：配置（队列和交换的创建和删除）、写（发布消息）、读（消费消息）的权限。 常用命令 sudo rabbitmqctl list_vhosts sudo rabbitmqctl list_queue -p web_develop sudo rabbitmqctl list_users","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"Redis","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/Redis/","text":"REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 Database NumberRedis 使用 DB number 实现类似关系型数据库中 schema 的功能。不同 DB number 表示的数据库是隔离的，但是目前只能使用数字来表示一个数据库，Ubuntu 默认的配置文件配置了16个数据库，DB number 是从0开始的，并且默认连接0号数据库。 redis-cli -n &lt;dbnumber&gt; 连接指定数据库 在docker中使用Redis","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"},{"name":"database","slug":"database","permalink":"http://www.liuzhidream.com/tags/database/"}]},{"title":"http-protocol","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/http-protocol/","text":"超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。 http actionHTTP协议中GET、POST和HEAD的介绍 2008-05-10 14:15 Name Description GET 请求指定的页面信息，并返回实体主体。 HEAD 只请求页面的首部。 POST 请求服务器接受所指定的文档作为对所标识的URI的新的从属实体。 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 DELETE 请求服务器删除指定的页面。 OPTIONS 允许客户端查看服务器的性能。 TRACE 请求服务器在响应中的实体主体部分返回所得到的内容。 PATCH 实体中包含一个表，表中说明与该URI所表示的原内容的区别。 MOVE 请求服务器将指定的页面移至另一个网络地址。 COPY 请求服务器将指定的页面拷贝至另一个网络地址。 LINK 请求服务器建立链接关系。 UNLINK 断开链接关系。 WRAPPED 允许客户端发送经过封装的请求。 Extension-mothed 在不改动协议的前提下，可增加另外的方法。 三次握手，四次挥手三次握手：A向B发起连接，B收到，回一个给A，A也收到，连接确定 第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。 完成三次握手，客户端与服务器开始传送数据。 建立连接是三次握手，释放连接是四次挥手（关闭连接） 第一步，当主机A的应用程序通知TCP数据已经发送完毕时，TCP向主机B发送一个带有FIN附加标记的报文段（FIN表示英文finish）。 第二步，主机B收到这个FIN报文段之后，并不立即用FIN报文段回复主机A，而是先向主机A发送一个确认序号ACK，同时通知自己相应的应用程序：对方要求关闭连接（先发送ACK的目的是为了防止在这段时间内，对方重传FIN报文段）。 第三步，主机B的应用程序告诉TCP：我要彻底的关闭连接，TCP向主机A送一个FIN报文段。 第四步，主机A收到这个FIN报文段后，向主机B发送一个ACK表示连接彻底释放。 状态码 Name Description 2xx 成功 3xx 重定向 4xx 客户端问题 5xx 服务端问题 get 和 post get是从服务器上获取数据，post是向服务器传送数据。 get是把参数数据队列加到提交表单的ACTION属性所指的URL中，值和表单内各个字段一一对应，在URL中可以看到。post是通过HTTP post机制，将表单内各个字段与其内容放置在HTML HEADER内一起传送到ACTION属性所指的URL地址。用户看不到这个过程。 对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据。 get传送的数据量较小，不能大于2KB。post传送的数据量较大，一般被默认为不受限制。但理论上，IIS4中最大量为80KB，IIS5中为100KB。 get安全性非常低，post安全性较高。但是执行效率却比Post方法好。 建议：1、get方式的安全性较Post方式要差些，包含机密信息的话，建议用Post数据提交方式；2、在做数据查询时，建议用Get方式；而在做数据添加、修改或删除时，建议用Post方式；","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"http","slug":"http","permalink":"http://www.liuzhidream.com/tags/http/"}]},{"title":"web相关","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/other/","text":"web相关学习笔记 网络网关和路由器最大的区别是是否连接相似的网络。如果连接相似的网络，则称为路由器。而连接不相似的网络，称为网关。（个人认为这个关字可以从海关上来理解，出关，海关） 相似的网络和不相似的网络有两种不同的含义。 逻辑层面： 相似的网络：如果都是互联网上的两个网络，我们称为相似的网络。不相似的网络：如果一个是私网，一个是公网。我们称为不相似的网络。 物理层面： 相似的网络：都是以太网或者同一种介质的网络。不相似的网络：一边是以太，一边是SDH或者ATM等 子网（Sub-net）出口路由器就叫网关了，后面还有很多中继路由器。所以网关一定是路由器，但路由器不一定用来做网关 TTL Time to live 域名解析在DNS服务器中存留时间 实际指转发的最大跳数，主机发送ip包的时候，在网络中转发，转发一次该值减1，为了防止无限转发和循环而设置这个值。如果变成1还没到目标地址，即为超时。 内网映射","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"ORID 焦点呈现法（Focused Conversation Method）","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/blog/ORID/","text":"ORID，即焦点呈现法（Focused Conversation Method），是一种通过催化师（主持人、引导讲师）引导来开展的结构化汇谈（会议、交谈）形式。该方法常被用作对事实进行分析和感觉某一工具和方法（O实践-客观事实、R感受-客观反射、I意义-事实分析，D行动-基于事实的下一步行动）。 ORIDObjective 你对今天学的记得什么？ Reflective 一句话形容今天的情绪（今天的高峰、低峰）。 Interpretive 今天你学到了啥？重要的领悟是什么？ Decisional 一句话形容今天的工作，明天要继续哪些工作。 Objective：The Objective Level of Thinking：这个方法就是通过引导的方法，对团队成员都着眼于客观事实，引导师让大家先说看到了什么、听到了什么，一方面是比较容易让大家回答，参与，同时让大家从事实入手看问题。 Reflective：The Reflective Level of Thinking：引导师会问大家对此事情的感受是怎么的？比较适合让人们打开感性的一面？多用来描述心情，如“喜、怒、哀、乐”等。 Interpretive：The Interpretive Level of Thinking ：思考这件事带给我们的思考、意义、启发是什么？ Decisional：The Decisional Level of Thinking：给我们带来的行动是什么？未来我要怎么做？ 焦点表述法（ORID）可以用于很多的场合，例如课堂提问学员引导，职场上级与下级的沟通，以及日常的写作都可以应用。 举例：在某件事中，你看到印象最深刻的一幕是什么？（O）你的第一感觉是什么？(R)对这件事，你是怎么想的？(I)能不能把这个经验用在未来的工作中？(D) 如：我今天上班途中突然遇到一条狗（O），我很害怕（R），为什么这里会有一条狗？因为这条路太偏僻(I)，明天我要选择其它人多的路(D)","tags":[{"name":"causerie","slug":"causerie","permalink":"http://www.liuzhidream.com/tags/causerie/"}]},{"title":"利用Docker快速构建开发环境","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/blog/docker-dev/","text":"Docker是很不错的容器技术，利用Docker可用快速构建一个开发环境，这样的好处在于一台新的电脑，只要安装了Docker软件，搭建环境就是几个命令的事，这样整个开发团队都会在同样的环境下进行，而且部署的时候，运维的同学只需要针对安全性做一些调整即可上线。 序言以Python语言为例，一个小团队的技术栈差不多会用到以下的东西： Python环境，包括各种需要的包 数据库，包括MySQL、MongoDB等 缓存服务，使用Redis等 任务队列，使用celery，RabbitMQ Http服务器，Nginx WSGI服务器，gunicorn，uwsgi Dockerfile1234567891011121314151617181920212223242526FROM python:3.7LABEL author=\"liuzhi&lt;1441765847.com&gt;\"# 换源，Python镜像基于Debian，使用阿里的Debian源RUN rm /etc/apt/sources.listCOPY sources.list /etc/apt/sources.list# 运行命令，安装常用软件RUN apt-get update \\ # 修改时区 &amp;&amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ # &amp;&amp; apt-get install -y apt-utils \\ # &amp;&amp; apt-get install -y wget \\ &amp;&amp; apt-get install -y zsh \\ &amp;&amp; chsh -s /bin/zsh root \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; apt-get install -y git \\ &amp;&amp; apt-get install -y vim # 安装zsh的扩展RUN sh -c \"$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" || trueENV FLASK_ENV devENV APP_DIR /codeWORKDIR /code/EXPOSE 5000 注意事项： 记得在同级目录下装备源文件 sources.list 有时候会提示需要安装 apt-utils，不过我这里是基于Debian的，这东西还装不上，没有apt-utils，安装不了第三方包，wget安装失败了，可用进入容器自行安装wget RUN命令中通过 &amp;&amp; 连接命令，因为在Docker中，每一个指令都会构建一层，因此尽量将命令都放在一个RUN指令中，用 &amp;&amp; 来串联。还有命令后面的 \\ 符最后就不需要写了，不然和下面的命令连起来了，如果你使用Dockerfile静态语法检查工具，有错误提示的（xcode安装插件即可编写Dockerfile，错误的地方会有提示） 这里还安装了zsh的扩展，使用了 || ，不用直接安装镜像创建会失败，我猜测可能是这个命令后面没接上，不用 || 可以看到安装信息是成功了的，但是容器创建会失败，太具体的情况不知道了，安装了zsh，启动容器的时候记得通过 /bin/zsh 进入 这里使用了官方的Python镜像，体积有点大，好处是装软件一般不会出问题了，作为开发用就不在精简体积上花时间了。","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"docker","slug":"docker","permalink":"http://www.liuzhidream.com/tags/docker/"},{"name":"technology","slug":"technology","permalink":"http://www.liuzhidream.com/tags/technology/"}]},{"title":"Algorithm","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Algorithm/README/","text":"算法相关 算法 有穷性(Finiteness)算法的有穷性是指算法必须能在执行有限个步骤之后终止； 确切性(Definiteness)算法的每一步骤必须有确切的定义； 输入项(Input)一个算法有0个或多个输入，以刻画运算对象的初始情况，所谓0个输入是指算法本身定出了初始条件； 输出项(Output)一个算法有一个或多个输出，以反映对输入数据加工后的结果。没有输出的算法是毫无意义的； 可行性(Effectiveness)算法中执行的任何计算步骤都是可以被分解为基本的可执行的操作步，即每个计算步都可以在有限时间内完成（也称之为有效性）。 聚合 先准备一个dict 循环数据 准备唯一键 如果唯一键没在dict中，生成新的dict2 并且 dict[key] = dict2 如果在，dict2 = dict[key] 然后修改dict2 利用字典在原引用修改的特性，把数据进行聚合分组，每次循环都会根据唯一键从临时数据字典dict处取出要聚合到这个key对应的字典中，然后对其进行操作。 找出数组中，只出现一次的两个数字list = [2, 4, 3, 6, 3, 2, 5, 5] 核心思路： 1、数组中全部数据异或操作后，依次对数组中的每个元素进行异或（相同位为0，不同为1）操作，得到0000 0010。 2、倒数第二位是1，说明我们要找的那两个只出现一次的数字，倒数第二位是不同的。(会出现不同，是因为这两个数不同，所以至少有一位是不同的) 3、下面根据每个数二进制倒数第二位是不是1来分成两组，倒数第二位为1的是{2, 3, 6, 3, 2}，倒数第二位为0的是{4, 5, 5}。 4、接下来对这两个数组分别进行异或操作，剩下的数字就是只出现一次的数字。 为什么分组可以实现：因为4，6是不同的两个数，它们二进制的至少某一位是不同的（记为N位），所以把这位是1的分在一起，试想所有的数在N位不同的是4或6中的一个，加上其它的数，其它的数都是成对的，所有其它的数也只会分成两组（其它的数N位同样只会是1或0），一组包含4和多个重复的数，一组包含6和多个重复的数，重复的数是可以消去的。 A + B 问题给出两个整数 aa 和 bb , 求他们的和。 样例如果 a=1 并且 b=2，返回3。 挑战显然你可以直接 return a + b，但是你是否可以挑战一下不这样做？（不使用++等算数运算符） 说明a和b都是 32位 整数么？ 是的 我可以使用位运算符么？ 当然可以 思路：运用位运算模拟加法 12345678910111213141516class Solution: \"\"\" @param a: An integer @param b: An integer @return: The sum of a and b \"\"\" def aplusb(self, a, b): # write your code here if a == -b: return 0 else: while b != 0: a, b = a ^ b, (a &amp; b) &lt;&lt; 1 # 每次去算进位的地方，进位的和a一直相加 return a 主要利用异或运算来完成 异或运算有一个别名叫做：不进位加法 那么a ^ b就是a和b相加之后，该进位的地方不进位的结果 然后下面考虑哪些地方要进位，自然是a和b里都是1的地方 a &amp; b就是a和b里都是1的那些位置，a &amp; b &lt;&lt; 1 就是进位 之后的结果。所以：a + b = (a ^ b) + (a &amp; b &lt;&lt; 1) 令a’ = a ^ b, b’ = (a &amp; b) &lt;&lt; 1 可以知道，这个过程是在模拟加法的运算过程，进位不可能 一直持续，所以b最终会变为0。因此重复做上述操作就可以 求得a + b的值。 冒泡排序1234567891011121314151617181920212223def bubbleSort(relist): len_ = len(relist) for i in range(len_): for j in range(0, len_ - i - 1): if relist[j] &gt; relist[j + 1]: relist[j + 1], relist[j] = relist[j], relist[j + 1] return relist# print(bubbleSort([1, 5, 2, 6, 9, 3]))def bubbleSort2(inlist): len_ = len(inlist) for i in range(len_): for j in range(len_ - i - 1): if inlist[j] &gt; inlist[j + 1]: inlist[j + 1], inlist[j] = inlist[j], inlist[j + 1] return inlist# print(bubbleSort2([1, 5, 2, 6, 9, 3])) 快速排序123456789101112131415161718192021222324def quickSort(array): if len(array) &lt; 2: return array else: pivot = array[0] less = [i for i in array[1:] if i &lt; pivot] greater = [j for j in array[1:] if j &gt; pivot] return quickSort(less) + [pivot] + quickSort(greater)print(quickSort([1, 5, 2, 6, 9, 3]))# 快排 分片的思想+递归的思想，这是取了第一个为基准值，栈高为O(log(n)),栈长O(n),所以运行时间为栈高x栈长，也就是算法平均运算时间为O(nlog(n))def quickSort2(array): if len(array) &lt; 2: return array else: piovt = array[0] less = [i for i in array[1:] if i&lt; piovt] greater = [j for j in array[1:] if j&gt;piovt] return quickSort2(less) + [piovt] + quickSort2(greater)print(quickSort2([1, 5, 2, 6, 9, 3])) 范围内的质数12345678910111213141516171819202122def func(): res = [] for i in range(1, 101): if compute(i): pass else: res.append(i) return resdef compute(value): flag = False if value &lt;= 2: return False for i in range(2, value - 1): r = value % i if not r: flag = True return flagprint(func()) 二叉数遍历1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586class BinaryTreeNode(object): def __init__(self, data=None, left=None, right=None): self.data = data self.left = left self.right = rightclass BinaryTree(object): \"\"\"docstring for BinaryTree\"\"\" def __init__(self, root=None): self.root = root def is_empty(self): return self.root == None def preOrder(self, this_Node): if this_Node == None: return print(this_Node.data) self.preOrder(this_Node.left) self.preOrder(this_Node.right) def inOrder(self, this_Node): if this_Node == None: return self.inOrder(this_Node.left) print(this_Node.data) self.inOrder(this_Node.right) def postOrder(self, this_Node): if this_Node == None: return self.postOrder(this_Node.left) self.postOrder(this_Node.right) print(this_Node.data) def levelOrder(self, this_Node): if this_Node == None: return _queue = [] _queue.append(this_Node) while _queue: node = _queue.pop(0) print(node.data) if node.left != None: _queue.append(node.left) if node.right != None: _queue.append(node.right) def deep(self, root): if not root: return print(root.data) self.deep(root.left) self.deep(root.right) def deepTree(self, root): if root == None: return 0 ld = self.deepTree(root.left) rd = self.deepTree(root.right) return max(ld, rd) + 1n1 = BinaryTreeNode(data=\"D\")n2 = BinaryTreeNode(data=\"E\")n3 = BinaryTreeNode(data=\"F\")n4 = BinaryTreeNode(data=\"B\", left=n1, right=n2)n5 = BinaryTreeNode(data=\"C\", left=n3, right=None)root = BinaryTreeNode(data=\"A\", left=n4, right=n5)bt = BinaryTree(root)bt = BinaryTree(root)# print('先序遍历')# bt.preOrder(bt.root)# print('中序遍历')# bt.inOrder(bt.root)# print('后序遍历')# bt.postOrder(bt.root)bt.levelOrder(root)# print bt.deepTree(bt.root) 斐波那契数列1234567891011121314def flb(num): result = None n, a, b = 0, 0, 1 while n &lt; num: print(b) result = b a, b = b, a + b n += 1 return resulta = flb(6)print(a) 跳台阶1234567891011121314151617181920212223242526272829303132333435# def jump_floor(number):# if number &lt;= 2:# return number# prev, curr = 1, 2# for _ in range(3, number + 1):# prev, curr = curr, prev + curr# print(curr)# return curr# print(jump_floor(5))def jump(time): if time &lt;= 2: return time a, b = 1, 2 for i in range(3, time + 1): a, b = b, a + b return b# print(jump(6))# def jumpm(time):# if time == 0:# return 0# return 2 ** (time - 1)### fff = lambda a: a if a &lt;= 2 else (fff(a - 1) + fff(a - 2))## print(fff(6))","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"algorithm","slug":"algorithm","permalink":"http://www.liuzhidream.com/tags/algorithm/"}]},{"title":"css","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/HTML/css/","text":"css总结 自动换行style=’word-wrap:break-word; word-break:break-all;display:block;width:100%;’ 不换行white-space:nowrap inputstyle=”-webkit-appearance:checkbox” 复选相关样式 空格 使用 \\&nbsp; 使用样式，输出1 &nbsp; 2 &nbsp; 3 &nbsp; 1&lt;span style=\"white-space:pre\"&gt;1 2 3&lt;/span&gt; table123&lt;tr&gt; - 定义表行&lt;th&gt; - 定义表头&lt;td&gt; - 定义表元(表格的具体数据) widthwidth 100% auto 某div不显示设置宽度，那么width为auto 某div的width在默认情况设置的是盒子模型中content的值 某div的width为100%表示的是此div盒子内容部分的宽度为其父元素的宽度 某个div的width不设置，或者设置为auto，那么表示的这个div的所有部分（内容、边框、内边距等的距离加起来）为父元素宽度 overflow关于滚动条：overflow 决定了溢出的操作，设置溢出用滚动条，那么这个容器必须有固定高度，才有溢出的概念。 scopedscoped 属性是一个布尔属性。如果使用该属性，则样式仅仅应用到 style 元素的父元素及其子元素。（在style type=”text/css” scoped 这里使用） css3 选择器 :nth-child(n) —-&gt;选中某个元素，该元素必须是某个父元素下的第n个子元素 p:nth-child(n) —-&gt;选中p元素，且该p元素必须是某个父元素下的第n个子元素 如果n是数字，比如2，那么第2个作用样式，如果是n+2 那么从第2个开始，后面的都作用样式 默认行为body 默认会有 margin 8px 这是浏览器决定的，不同浏览器不一样，所以初始创建一个项目，我们可以修改body 的css就可以0px 了 内联和块级元素块级元素特点： 1、每个块级元素都从新的一行开始，并且其后的元素也另起一行。（真霸道，一个块级元素独占一行） 2、元素的高度、宽度、行高以及顶和底边距都可设置。 3、元素宽度在不设置的情况下，是它本身父容器的100%（和父元素的宽度一致），除非设定一个宽度。 内联元素(行内元素 inline)特点： 1、和其他元素都在一行上； 2、元素的高度、宽度及顶部和底部边距不可设置； 3、元素的宽度就是它包含的文字或图片的宽度，不可改变。 内联块级inline-block 元素特点： 1、和其他元素都在一行上； 2、元素的高度、宽度、行高以及顶和底边距都可设置。 盒子模型CSS 盒子模型(Box Model) 所有HTML元素可以看作盒子，在CSS中，”box model”这一术语是用来设计和布局时使用。 CSS盒模型本质上是一个盒子，封装周围的HTML元素，它包括：边距，边框，填充，和实际内容。 盒模型允许我们在其它元素和周围元素边框之间的空间放置元素。 盒子模型居中显示，设置内联元素时 text-align:center; 这句话就可以让内联元素居中设置块状元素时定宽： 12345678&lt;style&gt;div&#123; border:1px solid red;/*为了显示居中效果明显为 div 设置了边框*/ width:200px;/*定宽*/ margin:20px auto;/* margin-left 与 margin-right 设置为 auto */&#125;&lt;/style&gt; 定宽就是width值固定，此时设置margin左或右为自动即可，注意两个设置缺一不可。 不定宽： 加table，或者将其改为内联 在实际工作中我们会遇到需要为“不定宽度的块状元素”设置居中，比如网页上的分页导航，因为分页的数量是不确定的，所以我们不能通过设置宽度来限制它的弹性。(不定宽块状元素：块状元素的宽度width不固定。)不定宽度的块状元素有三种方法居中（这三种方法目前使用的都很多）： 加入 table 标签 设置 display: inline 方法：与第一种类似，显示类型设为 行内元素，进行不定宽元素的属性设置 设置 position:relative 和 left:50%：利用 相对定位 的方式，将元素向左偏移 50% ，即达到居中的目的第一种方法：为什么选择方法一加入table标签? 是利用table标签的长度自适应性—即不定义其长度也不默认父元素body的长度（table其长度根据其内文本长度决定），因此可以看做一个定宽度块元素，然后再利用定宽度块状居中的margin的方法，使其水平居中。 第一步：为需要设置的居中的元素外面加入一个 table 标签 ( 包括 \\、\\、\\ )。 第二步：为这个 table 设置“左右 margin 居中”（这个和定宽块状元素的方法一样）。 举例如下： html代码：1234567891011121314151617181920&lt;div&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt; &lt;ul&gt; &lt;li&gt;我是第一行文本&lt;/li&gt; &lt;li&gt;我是第二行文本&lt;/li&gt; &lt;li&gt;我是第三行文本&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;&lt;/div&gt;css代码：&lt;style&gt;table&#123; border:1px solid; margin:0 auto;&#125;&lt;/style&gt; 隐形改变display类型 position : absolute float : left 或 float:right 加入这两句话中任意一句，就可以将元素变化inline-block 12345.container a&#123; position:absolute; width:200px; background:#ccc;&#125; a原来是内联的，不能改变width，加入绝对定位后变为内联块就可以了。 width height是改变盒子的背景background, font-size才是改变文字大小 权值12345p&#123;color:red;&#125; /*权值为1*/p span&#123;color:green;&#125; /*权值为1+1=2*/.warning&#123;color:white;&#125; /*权值为10*/p span.warning&#123;color:purple;&#125; /*权值为1+1+10=12*/#footer .note p&#123;color:yellow;&#125; /*权值为100+10+1=111*/ 浏览器默认的样式 &lt; 网页制作者样式 &lt; 用户自己设置的样式 定位层模型有三种形式： 1、绝对定位(position: absolute) 2、相对定位(position: relative) 3、固定定位(position: fixed) Relative与Absolute组合使用 在三种形式中，1是相对于浏览器，2是移动后原来位置有保留，3是固定盒子 利用2，1可以实现相对与某一个的移动（不用相对于浏览器） 1234567891011#box1&#123; width:200px; height:200px; position:relative; &#125;#box2&#123; position:absolute; top:20px; left:30px; &#125; 这样一来，box2就是相对于box1来移动的 注意这样做的前提 参照定位的元素box1必须是相对定位元素box2的前辈元素 即： 123&lt;div id=\"box1\"&gt; &lt;div id=\"box2\"&gt;相对参照元素进行定位&lt;/div&gt;&lt;/div&gt; 关于代码编写时移动的问题 绝对定位中，比如实现div元素相对于浏览器右移100px 此时代码写为 left:100px； 注意理解绝对定位，先把我的盒子定位好，来移动浏览器，这样为了让我在浏览器的右边，浏览器应该左移，绝对定位。 另一个理解方法 有四个参数来设置 left right top bottom 比如设置left=50px 可以理解为此时盒子与浏览器左边相距50px，也就是盒子右移动50px 补充： static（静态定位）：默认值。没有定位，元素出现在正常的流中（忽略 top, bottom, left, right 或者 z-index 声明）。 relative（相对定位）：生成相对定位的元素，通过top,bottom,left,right的设置相对于其正常（原先本身）位置进行定位。可通过z-index进行层次分级。 absolute（绝对定位）：生成绝对定位的元素，相对于 static 定位以外的第一个父元素进行定位。元素的位置通过 “left”, “top”, “right” 以及 “bottom” 属性进行规定。可通过z-index进行层次分级。 fixed（固定定位）：生成绝对定位的元素，相对于浏览器窗口进行定位。元素的位置通过 “left”, “top”, “right” 以及 “bottom” 属性进行规定。可通过z-index进行层次分级。 css 相对固定位置 处理方案： 需要固定位置的时候，常使用 position：fixed 这种方式往往达不到理想的效果，我们经常需要的是容器在某个位置固定，这样你需要花时间去调整左右上下参数。可以让fixed定位的容器处在一个父容器内，父容器是relative定位的，这样我们固定定位的容器就不用调整位置了，以父容器为基准 举例： 12345 &lt;div style=\"position: relative;\"&gt; &lt;div class=\"rich_text_class\" style=\"position:fixed;\" v-html=\"menu\"&gt; &lt;/div&gt;&lt;/div&gt; index-zz序决定了dom的层级关系，数值越大的在最上层。关于宽度，父容器的宽度受到子dom的影响，可以调整让子dom的宽度不超过父容器，在设置width属性的时候，是块的宽加上内边距，可以改属性，让这个width只有块的宽决定。理解外边距和内边距和元素自己。块级元素才是占一行。 :hover:hover { } css选择器中对被选中对象做操作，效果为鼠标指向时代码作用。例子鼠标指向时修改文字颜色（注意不能直接在便签中加style=color 先设置颜色，class设置的颜色就会失效，应该是遵循了就近原则） 超出显示文字省略css3 超出显示文字省略 text-overflow: ellipsis; white-space: nowrap; overflow: hidden; 设置行数，超出行数省略 overflow: hidden; text-overflow: ellipsis; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; 把该样式作用于p标签上 控制锚点 js控制锚点跳转 1234567891011&lt;a name=&quot;anchor&quot;&gt;&lt;/a&gt;location.hash=&quot;anchor&quot;;不只有a其他元素也可以，比如在报表中：&lt;tr id=&quot;tr1&quot;&gt;...&lt;/tr&gt;location.hash=&quot;tr1&quot;或者用jQuery的动画滚动效果：var id=&quot;tr1&quot;;$(&apos;html,body&apos;).animate(&#123;scrollTop: $(&quot;tr#&quot;+id).offset().top&#125;, 500); html控制锚点跳转 12&lt;a href=&quot;#btn&quot;&gt;跳转到点击位置&lt;/a&gt;&lt;a name=&quot;btn&quot; id=&quot;btn&quot;&gt;点击&lt;/a&gt; 跨页面锚点跳转 123代码如下:&lt;a href=&quot;123.html#btn&quot;&gt;跳到btn&lt;/a&gt;&lt;a name=&quot;btn&quot; id=&quot;btn&quot;&gt;&lt;/a&gt; js控制锚点跳转在HTML中实现方式 12345678&lt;!-- 假设一个需要跳转到的节点 --&gt;&lt;div id=&quot;divNode&quot;&gt;&lt;!-- contents --&gt;&lt;/div&gt;&lt;a href=&quot;#&quot; onclick=&quot; document.getElemetnById(&apos;divNode&apos;).scrollIntoView(true); return false;&quot;&gt; 通过scrollIntoView实现锚点效果&lt;/a&gt; box-sizingbox-sizing属性用于更改用于计算元素宽度和高度的默认的 CSS 盒子模型。可以使用此属性来模拟不正确支持CSS盒子模型规范的浏览器的行为。 简单来说就是改变盒子模型的计算方式，默认盒子模型，容器的width等于容器设置的width。如果box-sizing 设置为border-box 容器的宽度等于除外边距外的其它属性和。 cursor: pointercursor: pointer 运用了该属性，鼠标指上元素时变成“小手” 其它给元素添加背景，做一个图标按钮，需要设置padding 扩充元素大小，不然图片没法显示","tags":[{"name":"css","slug":"css","permalink":"http://www.liuzhidream.com/tags/css/"},{"name":"html","slug":"html","permalink":"http://www.liuzhidream.com/tags/html/"}]},{"title":"Vue","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/Vue/","text":"Vue是MVVM框架，一个构建数据驱动的 web 界面的渐进式框架。Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。它不仅易于上手，还便于与第三方库或既有项目整合。 Vue一个不错的“简书”入门 image 基本 在通过ajax获取到数据需要赋值到data里面的时候，如果是不可变变量，可以直接赋值，但是如果是arrey，需要迭代每个值，加到data中。Ajax.data.forEach(function(val, index){ vue.data.push(val) })。 vue:在html中传递 this ，在vue中this都是指向vue的组件，如果我们想使用原本的this指向这个dom,需要这样使用dofunc($event)。在函数里面 dofunc(v){ v.target }。如果转换为 jQuery 对象 $(v.target) vue:由于dom是由js去渲染的，所以你在渲染的时候去操作dom，是选不到的。这里涉及到了vue的生命周期的问题，实例创建完毕(挂载)，再去渲染dom。 vue:template不会渲染成元素，用div的话会被渲染成元素。把if,show,for等语句抽取出来放在template上面，把绑定的事件放在temlpate里面的元，可以使html结构更加清晰，还可以改善一个标签过长的情况。 注册指令：全局注册，在new vue同块写Vue.directive局部注册，当前组件使用，作为vue实例的一个属性 directives 多了个 S注册组件也是如此，和指令类似 在vue实例中的选择基本都是可以在组件里面使用的（vue实例怎么写组件就怎么写），但是data必须是函数，如果是一般的对象，你在组件里面使用这个对象会报错 单页面的VUE实例只有一个，组件化开了，要想从实例拿到data，只能是组件props向下传递，记得绑定想要的数据在你的模板上。向上使用events props data 是驼峰命名，绑定数据的写法 &lt;child :msg-a=&quot;msgA&quot;&gt;&lt;/child&gt; v-bind=&quot; a &quot; 使用绑定，外部的引号不是想表达这个是个字符串，它应该当成一个变量，这也是在绑定url的时候，我们可以使用变量加上字符串，其中的字符串就用单引号。 props: 单项流数据，从父组件流向子组件，子组件试图修改它会报错，如果你要用它，应该把这个值给data，定义局部变量的方法。如果data是可变类型的，在子组件中修改了是会影响到父组件的。 props:验证，可以验证流进来的数据。验证在这个组件实例创建之前，所以你不能把这个组件里面的 option 诸如 data methods用在验证里面。 插槽：组件嵌套的时候使用，定义了如何进行内容分发 组件实例的作用域是孤立的 vue:自定义组件命名不要命名常见的（怕和框架冲突） 给vue组件绑定事件时候，必须加上native ，不然不会生效（监听根元素的原生事件，使用 .native 修饰符）。等同于在自组件中：子组件内部处理click事件然后向外发送click事件：$emit(&quot;click&quot;.fn) 字符串模板和非字符串模板123&lt;script id=\"component1\" type=\"x-template\"&gt;&lt;/script&gt; 在实例中option使用 template 会把挂载元素的内容替换掉，在组件中 option 使用 template是HTML元素扩展被替换的内容，很像，都是替换。 实例的模板字符串，执行元素的时候，此时元素应该是template标签或者 script type=x-template 都是把这两个的内容替换到实例挂载的元素上。 指令vue指令类似 v-model 可以自定义指令，在创建实例的时候声明即可 目前的vue架构，对于一个vue文件来说，在里面使用其它组件（就是引用的各种组件），那么这些组件对于当前vue文件来说就是子组件，当前vue文件是父组件。这在理解一些概念的时候会有用，比如子组件 双向绑定值 使用 sync 来修饰，把子组件的某个属性绑定到父组件上，做到双向绑定。 Command Description v-bind 动态绑定数据。简写为“:” =&gt; 以后的:class=”{red:boolean}” v-on 绑定时间监听器。简写为“@”，例：@click=”xxx” v-text 更新数据，会覆盖已有结构。类似 { {msg} } v-show 根据值的真假，切换元素的display属性 v-if 根据值的真假，切换元素会被销毁、重建；=&gt; 在dom中已消失 v-else-if 多条件判断，为真则渲染 v-else 条件都不符合时渲染 v-for 基于源数据多次渲染元素或模块 v-model 在表单控件元素（input等）上创建双向数据绑定（数据源） v-pre 跳过元素和子元素的编译过程 v-once 只渲染一次，随后数据更新也不重新渲染 v-cloak 隐藏未编译的Mustache语法，在css中设置[v-cloak]{display:none;} 交互命令 Command Description vue cli 主要功能就是创建vue工程 vue init webpack myproject 构建vue项目 ref 和 $refsref 这个通常在元素上使用（组件自定义的元素也可以），比如现在有个组件 &lt;my-component&gt;&lt;/my-component&gt; 使用ref &lt;my-component ref=&#39;new-name&#39; attr-a=&#39;hello&#39;&gt;&lt;/my-component&gt; 在 js 中 this.$refs[&#39;new-name&#39;].attr // res hello 就可以通过别名获取到元素，并且拿到元素对应的属性。 补充： 利用ref属性可以获取到dom元素或者是子组件，从而可以调用子组件的方法（注意2.0版本用ref取代了el） 当ref直接定义在dom元素上时，则通过this.$refs.name可以获取到dom对dom进行原生的操作 &lt;div class=&quot;foods-wrapper&quot; ref=&quot;foods-wrapper&quot;&gt; 通过 this.$refs 获取到dom进行操作（注意ref属性的命名不能用驼峰，同时获取的时候也是） let menuList=this.$refs[&#39;menu-wrapper&#39;].getElementsByClassName(&#39;menu-list-hook&#39;); 此处如果用 this.$refs[&quot;menuWrapper&quot;] 将获取不到元素 通过在引用的子组件上使用ref属性实现父组件调用子组件的方法以及属性 在父组件中引用子组件并定义ref &lt;v-food ref=&quot;selectfood&quot;&gt;&lt;/v-food&gt; 调用定义在子组件中的方法show this.$refs.selectfood.show(); 同时也可以调用子组件中的属性 声明下上面说的是vue 2.0的 templatetemplate是html5的一个新元素，主要用于保存客户端中的内容，表现为浏览器解析该内容但不渲染出来，可以将一个模板视为正在被存储以供随后在文档中使用的一个内容片段。 slot 插槽模板和非插槽模板非插槽模板指的是html模板，比如 div、span、ul、table 这些，非插槽模板的显示与隐藏以及怎样显示由组件自身控制。 插槽模板是slot，它是一个空壳子，因为它的显示与隐藏以及最后用什么样的html模板显示由父组件控制。但是插槽显示的位置确由子组件自身决定，slot写在组件template的什么位置，父组件传过来的模板将来就显示在什么位置。 一般的用法就是在子组件里面： 12345678910111213141516&lt;!-- 子组件名称：&lt;children&gt; --&gt;&lt;template&gt; &lt;div&gt; &lt;solt&gt;&lt;/solt&gt; &lt;/div&gt;&lt;/template&gt;&lt;!-- 父组件是这样的 --&gt;&lt;template&gt; &lt;children&gt; &lt;span&gt;被插入的内容，这整个span便签都会替换子组件中的solt&lt;/span&gt; &lt;children/&gt;&lt;/template&gt; 这就是匿名插槽或叫做具名插槽，就是 &lt;span solt=&#39;name&#39;&gt; &lt;/span&gt; 在父组件上为要插入的内容取个名字，子组件&lt;solt name=&#39;name&#39;&gt;&lt;/solt&gt; 这样来和父组件对应起来。 作用域插槽：这个概念比较难理解，先看怎么用: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;!-- 父组件： --&gt;&lt;template&gt;&lt;div class=\"father\"&gt; &lt;h3&gt;这里是父组件&lt;/h3&gt; &lt;!--第一次使用：用flex展示数据--&gt; &lt;child&gt; &lt;template slot-scope=\"user\"&gt; &lt;div class=\"tmpl\"&gt; &lt;span v-for=\"item in user.data\"&gt;&#123; &#123;item&#125; &#125;&lt;/span&gt; &lt;/div&gt; &lt;/template&gt; &lt;/child&gt; &lt;!--第二次使用：用列表展示数据--&gt; &lt;child&gt; &lt;template slot-scope=\"user\"&gt; &lt;ul&gt; &lt;li v-for=\"item in user.data\"&gt;&#123; &#123;item&#125; &#125;&lt;/li&gt; &lt;/ul&gt; &lt;/template&gt; &lt;/child&gt; &lt;!--第三次使用：直接显示数据--&gt; &lt;child&gt; &lt;template slot-scope=\"user\"&gt; &#123; &#123;user.data&#125; &#125; &lt;/template&gt; &lt;/child&gt; &lt;!--第四次使用：不使用其提供的数据, 作用域插槽退变成匿名插槽--&gt; &lt;child&gt; 我就是模板 &lt;/child&gt;&lt;/div&gt;&lt;/template&gt;&lt;!-- 子组件： --&gt;&lt;template&gt; &lt;div class=\"child\"&gt; &lt;h3&gt;这里是子组件&lt;/h3&gt; // 作用域插槽 &lt;slot :data=\"data\"&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;export default &#123; data: function()&#123; return &#123; data: ['zhangsan','lisi','wanwu','zhaoliu','tianqi','xiaoba'] &#125; &#125;&#125; 可以看到，子组件写法是 &lt;slot :data=&quot;data&quot;&gt;&lt;/slot&gt; 把数据绑定给data属性，而且数据的来源是子组件，这点就很重要了。 在父组件会这么写： 1234&lt;template slot-scope=\"scope\"&gt; &lt;span&gt;&#123; &#123;scope.row.id&#125; &#125;&lt;/span&gt;&lt;/template&gt; 此时通过scope就可以拿到子组件绑定的data了，这个scope可以随便写。 在什么时候会用到呢？由于做研发比较少，但是用框架的时候你就要知道这种写法，通常会对子组件绑定父组件的数据，子组件拿到父组件的时候后，做了处理，得到自己的 data 就是上面插槽绑定的 data 这个时候你就可以去这个里面拿一些你像要的数据了。 像element UI 的table组件，通过给组件list数据，在 el-table-column 组件里面用作用域插槽就可以拿到赋值给list也就是表格的数据。 this.$nextTick在vue中，当页面加载完成以后，dom还没有加载，是无法获取进行操作的，但是在vue2.0中提供了一个方法 this.$nextTick，在这个回调函数里面写dom操作即可，如下代码： 12345created() &#123; this.$nextTick(() =&gt; &#123; //do somthing&#125;); 其实这里还有一个小技巧，就是用settimeout(fn,20),来取代this.$nextTick,（20 ms 是一个经验值，每一个 Tick 约为 17 ms），对用户体验而言都是无感知的。 现在vue都快要到3.o了，不要使用settimeout了，在使用 this.$nextTick 如果失败了，很可能是生命周期相关问题没处理好。 路由跳转当我们需要跳转一个页面的时候，既然是单页面应用，可以使用路由会很方便，比如带很多的参数过去。如果是普通的url跳转只能在url里面带参数，限制较大 比如我们的跳转由方法来处理 @click=&quot;getDescribe(article.id)&quot; 方法内容(三种情况)： 123456789101112131415161718192021222324252627282930&lt;!-- 情况1.基本使用 --&gt;this.$router.push(&#123; path: `/describe/$&#123;id&#125;`,&#125;)&lt;!-- 路由配置 --&gt;&#123; path: '/describe/:id', name: 'Describe', component: Describe&#125;&lt;!-- 情况2.通过路由配置的name来匹配 --&gt;this.$router.push(&#123; name: 'Describe', params: &#123; id: id &#125;&#125;)&lt;!-- 情况3.通过path来匹配 --&gt;this.$router.push(&#123; path: '/describe', query: &#123; id: id &#125;&#125;) 方案2要优雅的多，可以在params中传递参数，这里的id用来做路由传参了。 在子组件中通过 $route.params 获取到参数。方案3为 $route.query 就是获取 $route 对象的属性了。 运用：通过方法查询接口，返回数据由路由来响应，把参数都传给子组件，子组件通过在created生命周期中 this.$route 获取传递给子组件的参数。 v-html 与 深度作用选择器vue 使用v-html指令渲染的页面样式处理问题 由于是动态加载的页面，在style中写的class不会作用于v-html渲染的内容，作者给出的解决方案是给外层容器加个类名, 然后用后代选择器，css的选择器可以是类选到类 .classA .classB， 选择元素的 .classA a (选择a标签) .classA &gt; a 只对一代a标签作用。直接这样写还不行，需要深度作用选择器 .classA &gt;&gt;&gt; a。 有些像 Sass 之类的预处理器无法正确解析 &gt;&gt;&gt;。这种情况下你可以使用 /deep/ 操作符取而代之——这是一个 &gt;&gt;&gt; 的别名，同样可以正常工作。 总结：在使用指令的便签上加个类，用这个类选择后代（注意要用深度作用选择器）这样就可以解决问题了。 1234567&lt;div class='myclass' v-html='content'&gt;&lt;/div&gt;&lt;style&gt; .myclass /deep/ a&#123; font-size: 10px &#125;&lt;/style&gt; 或者在被渲染的Html里面加style（没有测试过，感觉是可行的） 子组件向父组件传递事件子组件向父组件传递事件，通常用来实现子组件向父组件传递值，然后调用父组件的方法 在子组件中对某个标签绑定点击事件 v-on:click=&quot;$emit(&#39;click_event&#39;, data.guid)&quot; 这样在父组件中我们可以监听这个事件，&lt;article-classify v-on:click_event=&quot;classifyHandler&quot;&gt;&lt;/article-classify&gt; 方法 classifyHandler 会接受传递的参数，也就是 data.guid，这样我们就拿到子组件传递来的参数了，然后后面的逻辑也就可以去跟着执行方法","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"},{"name":"Vue","slug":"Vue","permalink":"http://www.liuzhidream.com/tags/Vue/"},{"name":"framework","slug":"framework","permalink":"http://www.liuzhidream.com/tags/framework/"}]},{"title":"JavaScript","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/JavaScript/javascript/","text":"javascript学习笔记 DOM对象DOM对象，即是我们用传统的方法(javascript)获得的对象，jQuery对象即是用jQuery类库的选择器获得的对象;复制代码 代码如下: 12var domObj = document.getElementById(\"id\"); //DOM对象var $obj = $(\"#id\"); //jQuery对象; jQuery对象就是通过jQuery包装DOM对象后产生的对象，它是jQuery独有的。如果一个对象是jQuery对象，那么就可以使用jQuery里的方法，例: $(“#foo”).html(); //获取id为foo的元素内的html代码，html()是jQuery特有的方法; 上面的那段代码等同于: document.getElementById(“foo”).innerHTML;$(“#foo”).innerHTML 是错误的 可以将jquery 和 dom 对象互相转换，这样dom对象就可以使用jquery的方法了，jquery对象亦如此。 Json 方法JSON.stringify(a) stringify()用于从一个对象解析出字符串 JSON.parse(str) parse用于从一个字符串中解析出json对象 取得url中get请求的参数12345function getUrlParam(name)&#123; var reg = new RegExp(\"(^|&amp;)\" + name + \"=([^&amp;]*)(&amp;|$)\"); var r = window.location.search.substr(1).match(reg); if (r != null) return decodeURI(r[2]); return null;&#125; ready 和 onload事件页面加载完成有两种事件，一是ready，表示文档结构已经加载完成（不包含图片等非文字媒体文件），二是onload，指示页 面包含图片等文件在内的所有元素都加载完成。(可以说：ready 在onload 前加载！！！) 一般样式控制的，比如图片大小控制放在onload 里面加载。 关键字JavaScript 关键字必须以字母、下划线（_）或美元符（$）开始。 后续的字符可以是字母、数字、下划线或美元符（数字是不允许作为首字符出现的，以便 JavaScript 可以轻易区分开关键字和数字）。 image BOM &amp; DOM BOM是浏览器对象模型，用来获取或设置浏览器的属性、行为，例如：新建窗口、获取屏幕分辨率、浏览器版本号等。 DOM是文档对象模型，用来获取或设置文档中标签的属性，例如获取或者设置input表单的value值。 BOM的内容不多，主要还是DOM。 字面量，变量有时候会遇到字面量的概念，它和变量对应，字面量就是固定值的表示法。 异常js也有异常，不过很少见人使用。 123456789101112131415161718192021222324252627282930&lt;html&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;script&gt; function myFunction() &#123; try &#123; //错误判断 var x = document.getElementById(\"demo\").value; if (x == \"\") throw \"值为空\"; if (isNaN(x)) throw \"不是数字\"; if (x &gt; 10) throw \"太大\"; if (x &lt; 5) throw \"太小\"; &#125; catch (err) &#123; //发生错误时在此执行，err为自定义错误 throw 对应的值， var y = document.getElementById(\"mess\"); y.innerHTML = \"错误：\" + err + \"。\"; &#125; &#125;&lt;/script&gt;&lt;body&gt; &lt;h1&gt;我的第一个 JavaScript&lt;/h1&gt; &lt;p&gt;请输出一个 5 到 10 之间的数字:&lt;/p&gt; &lt;input id=\"demo\" type=\"text\"&gt; &lt;button type=\"button\" onclick=\"myFunction()\"&gt;测试输入&lt;/button&gt; &lt;p id=\"mess\"&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 函数函数的定义方式大体有以下两种，浏览器对于不同的方式有不同的解析顺序。 12345678//“定义式”函数定义function Fn1()&#123;alert(\"Hello World!\");&#125;//“赋值式”函数定义var Fn2 = function()&#123;alert(\"Hello wild!\");&#125; 快速测试一段代码的执行时间123console.time('test')/* 这里运行待测代码 */console.timeEnd('test') 对象总结对象 javascript 对象 123JS Array JS Boolean JS Date JS Number JS String JS RegExp JS Functions JS Events JS Math 其它对象 12Browser Window Navigator Screen History Location Window 对象表示一个浏览器窗口或一个框架。在客户端 JavaScript 中，Window 对象是全局对象，所有的表达式都在当前的环境中计算。也就是说，要引用当前窗口根本不需要特殊的语法，可以把那个窗口的属性作为全局变量来使用。 HTML DOM 对象 每个载入浏览器的 HTML 文档都会成为 Document 对象。 Document 对象使我们可以从脚本中对 HTML 页面中的所有元素进行访问。 Element 节点，文本节点，元素节点等。 Attribute 属性； Event 事件； HTML 对象； 标签即是HTML对象，标签和元素的区别，属性的定义： 比如&lt;p&gt;这就是一个标签； &lt;p&gt;这里是内容&lt;/p&gt;这就是一个元素， 也就是说元素由一个开始的标签和结束的标签组成，用来包含某些内容。 属性： 为HTML元素提供各种附加信息的就是HTML属性，它总是以”属性名=属性值”这种名值对的形式出现，而且属性总是在HTML元素的开始标签中进行定义。 节点的作用： 在有了标签，元素，属性后，引申出节点的概念，标签的元素中可能会有更多的元素，将多个或一个元素看作节点，节点就是为了去操作元素的。 virtual DOM一些理解： 虚拟DOM，是一个模拟DOM数的js对象。 就是当我们需要更改DOM的时候，如果用原始方法比较慢，这在多节点的页面中体现就更明显了，原因是dom设计的复杂，所以我们用一个虚拟的DOM，虚拟的DOM记录了要更改的DOM，它通常不是立刻执行的，等到需要的时候，计算最小的执行，把执行更新到DOM上。这里为什么会有最小的DOM执行，是应为不是所有的地方都需要变更。 总结：virtual DOM 通过计算最小的DOM执行，能更快的渲染DOM。 别人的讲解： Virtual DOM 是一个模拟 DOM 树的 JavaScript 对象。 React 使用 Virtual DOM 来渲染 UI，当组件状态 state 有更改的时候，React 会自动调用组件的 render 方法重新渲染整个组件的 UI。 React 主要的目标是提供一套不同的, 高效的方案来更新 DOM.不是通过直接把 DOM 变成可变的数据, 而是通过构建 “Virtual DOM”, 虚拟的 DOM, 随后 React 处- 理真实的 DOM 上的更新来进行模拟相应的更新。 引入额外的一个层怎么就更快了呢? 那不是意味着浏览器的 DOM 操作不是最优的, 如果在上边加上一层能让整体变快的话?是有这个意思, 只不过 virtual DOM 在语义上和真实的 DOM 有所差别.最主要的是, virtual DOM 的操作, 不保证马上就会产生真实的效果.这样就使得 React 能够等到事件循环的结尾, 而在之前完全不用操作真实的 DOM。在这基础上, React 计算出几乎最小的 diff, 以最小的步骤将 diff 作用到真实的 DOM 上。批量处理 DOM 操作和作用最少的 diff 是应用自身都能做到的.任何应用做了这个, 都能变得跟 React 一样地高效。但人工处理出来非常繁琐, 而且容易出错. React 可以替你做到。 前面提到 virtual DOM 和真实的 DOM 有着不用的语义, 但同时也有明显不同的 API。 DOM 树上的节点被称为元素, 而 virtual DOM 是完全不同的抽象, 叫做 components。 component 的使用在 React 里极为重要, 因为 components 的存在让计算 DOM diff 更高效。 简单的说就是： 当然如果真的这样大面积的操作 DOM，性能会是一个很大的问题，所以 React 实现了一个虚拟 DOM，组件 DOM 结构就是映射到这个虚拟 DOM 上，React 在这个虚拟 DOM 上实现了一个 diff 算法，当要更新组件的时候，会通过 diff 寻找到要变更的 DOM 节点，再把这个修改更新到浏览器实际的 DOM 节点上，所以实际上不是真的渲染整个 DOM 树。这个虚拟 DOM 是一个纯粹的 JS 数据结构，所以性能会比原生 DOM 快很多。 React的核心机制之一就是可以在内存中创建虚拟的DOM元素。React利用虚拟DOM来减少对实际DOM的操作从而提升性能。 indexOf数组过滤。indexOf作用是返回字符串第一次出现在给定字符串的index，可以用来处理某个字符串有没有在给定字符串中。 给定 str.indexOf(某个字符串) = 0 说明第一个就匹配到，这个给定字符串。如果是空格分隔的，如几个单词，那么结果就不一定是0了，因为会在后面的位置。记住是给定来调用这个方法就行了 补充： js array indexOf 参数是对象的时候，不一定能返回对应位置的index(有的时候可以，我查了资料，有人是这么说的：让数组去判断一个新创建的对象，所以会得到 -1。我在vue中，把循环出来的元素做为参数去在原数组中判断，是可以的，不是循环出来的对象，虽然对象和数组元素字面看起来一摸一样，但是不行，猜测这和底层有关) 所以这个东西的使用，要很小心推荐使用 Array.findIndex() findIndex()方法返回数组中满足提供的测试函数的第一个元素的索引。否则返回-1。 123456789var array1 = [5, 12, 8, 130, 44];function findFirstLargeNumber(element) &#123; return element &gt; 13;&#125;console.log(array1.findIndex(findFirstLargeNumber));// expected output: 3 find() 方法返回数组中满足提供的测试函数的第一个元素的值。否则返回 undefined。 123456789var array1 = [5, 12, 8, 130, 44];var found = array1.find(function(element) &#123;return element &gt; 10;&#125;);console.log(found);// expected output: 12 通过find，findIndex可以完成很多的事情，少用通过各种方法获取索引，然后再去 array[index]。find就可以了 更详细的使用查看文档。文档地址 我发现这个从列表中给出来的数据，你不段的引用，其中一个引用改了，也会影响到原数组。 格式化字符串1`a$&#123;var&#125;` 如果var是1，result 为 a1。注意两边的符号为tab键上面的 bject.keys(obj)返回值: 一个表示给定对象的所有可枚举属性的字符串数组 传入字符串，返回索引 12var arr = ['a', 'b', 'c'];console.log(Object.keys(arr)); // console: ['0', '1', '2'] 传入对象，返回属性名 12var obj = &#123; a: 'alive', b: 'bike', c: 'color' &#125;;console.log(Object.keys(obj)); // console: ['a', 'b', 'c'] length只对字符串和数组有用，整形数字和对象返回未定义undefined includes数组调用，监测数组是否包含给定的元素 array.include(0) 返回boolean this箭头函数与普通函数中的this指向不一样，前者基于定义时的上下文环境，后者则只是基于调用者。 typeof cb == “function” &amp;&amp; cb()强大的js总有一些没见过的用法 function delay(time, cb) { typeof cb == &quot;function&quot; &amp;&amp; cb(time) } cb&amp;&amp;cb(value) 的意思是： 如果cb为真（有值），那么执行cb(value)； 如果cb为假，&amp;&amp;短路，那么不执行cb(value)。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"javascript","slug":"javascript","permalink":"http://www.liuzhidream.com/tags/javascript/"}]},{"title":"linux-base","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Linux/linux-base/","text":"Linux学习笔记 文件目录/etc存放系统管理和配置文件 /usr (Unix System Resource)用于存放系统应用程序，比较重要的目录/usr/local本地系统管理员软件安装目录（安装系统级的应用）。这是最庞大的目录，要用到的应用程序和文件几乎都在这个目录。 /usr/bin众多的应用程序/usr/sbin超级用户的一些管理程序 /usr/src源代码，linux内核的源代码就放在/usr/src/linux里 /usr/local/bin本地增加的命令/usr/local/lib本地增加的库 /proc虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息。 /sbin存放二进制可执行文件，只有root才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如ifconfig等 一般，系统带的应用在/usr/bin 自己安装的在/usr/local/bin，/usr/sbin 也会有应用 如果你是编译安装的，最好用ln -s 源命令 /usr/local/bin，把编译安装的启动程序在通用安装目录下创建符号链接，这样就能直接在任何地方从命令行运行程序 文件类型目录（d） 文件（-） 字符型文件（c ） 块设备（b） l 链接文件 p 管道文件 创建文件 touch 复制文件 cp -i (覆盖提醒) cp -i file newfile 链接文件（new） 命令 ln 有硬链接和符号链接（软链接） 重命名 命令 mv mv a b 操作上称为移动文件，a在当前目录移动成b，实现了修改名字的作用 文件权限权限 r w x 文件的权限如下图所示，开始指文件类型 12-rw-r--r-- 1 root root 664 Apr 12 22:46 uwsgi_params-rw-r--r-- 1 root root 3610 Apr 12 22:46 win-utf 除去类型，开始三个 rw- 描述的是文件所有者的权限，r– 文件所属组 ，最后是其他用户。 关于所属组，比如system组，可以执行系统相关命令，当某个用户被临时加入到系统组，则该用户将拥有对应权限，比如： 1-r-xr-sr-x（- 类型， r-x 文件所有者权限 r-s 文件所属组权限 r-x 文件其它用户权限 如某个用户像执行它，只要加入系统组即可。 文件特殊权限 SUID SGID 目录给予SGID权限，该目录下创建的文件都将是这个组的。 目录设置SBIT位，只能自己修改目录下的文件，该目录可能创建多个文件（不同用户），防止别人来修改自己的文件。 文件权限可以隐藏，此时ls -l 看不到，用lsattr查看隐藏权限。 更进一步，对某个命令设置特定用户才能执行，对某个用户做设置。 权限后面是链接数，然后是文件所属用户名，之后是所属组名，然后文件大小，日期时间，文件名。 记住，一个文件被创建的时候，它拥有inode和block，每个文件占用一个独立的inode table，记录文件的权限和属性，包括数据地址。block数据存放的实际内容。ls -il 这个i参数可以查看inode。 知道该文件的einode，使用find-inum 可以找到所有指向inode的文件。 补充： 符号链接，可以对文件和目录创建符合链接。符号链接可以理解为快捷方式，它和原文件是两个不同的文件，所有他们的inode不一样，而且他数据很小，因为只做指向。在ls命令下，可以看到文件类型是 l，并且后面会有 fileA -&gt; fileB，意为A是B的符号链接。原始文件被删除后，符号链接也失效。可以跨文件系统创建符号链接。不要创建符号链接的符号链接。 硬链接，会创建独立的虚拟文件，但是共享原文件的inode，使用ls命令查看，会发现它们完全一样（链接数都是2），除了名字外。引用硬链接等于引用原文件。不能对目录创建硬链接（目录下的所有数据都会被创建硬链接），不能跨文件系统。 挂载与分区linux 硬盘第一扇区512byte，记录着主引导记录和分区信息。主引导占了446byte，后面的空间一般分配3个主分区，1个扩展分区。每个占16byte。如果全是主分区，只能有4个，所以主分区不能超过4个。 挂载，/etc/fstab记载着挂载信息，SWAP称为交换分区，类似虚拟内存。 磁盘冗余阵列RAID RAID 0～RAID 50等数个规范 RAID 0是组建磁盘阵列中最简单的一种形式，只需要2块以上的硬盘即可，成本低，可以提高整个磁盘的性能和吞吐量。RAID 0没有提供冗余或错误修复能力，但实现成本是最低的。最大的缺点在于任何一块硬盘出现故障，整个系统将会受到破坏，可靠性仅为单独一块硬盘的1/N。 RAID1 称为磁盘镜像，原理是把一个磁盘的数据镜像到另一个磁盘上，也就是说数据在写入一块磁盘的同时，会在另一块闲置的磁盘上生成镜像文件，在不影响性能情况下最大限度的保证系统的可靠性和可修复性上，只要系统中任何一对镜像盘中至少有一块磁盘可以使用，甚至可以在一半数量的硬盘出现问题时系统都可以正常运行,当一块硬盘失效时，系统会忽略该硬盘，转而使用剩余的镜像盘读写数据，具备很好的磁盘冗余能力。缺点磁盘利用率不高。 epoll这是linux的模块，python 的 torado会对其进行封装，提供接口，是实现高并发的关键。BSD系统的是kqueue，大概概念应该是类似的，BSD接触的较少了。 epoll是整个框架实现高性能的基础，所以为了发挥性能，你需要把程序部署在linux上，使用linux的epoll。 要理解这个模块是做什么的，先说任务阻塞，多个任务阻塞了，一般的操作系统机制是使用轮询的方法，循环所有阻塞任务，看是否有被唤醒的，这样太浪费时间了，如果当前循环任务没有被唤醒的，CPU白白浪费了一次循环，所以有了epoll 这是一个代理，在操作系统设计的代码大概是这样的，原来的思路是循环任务列表，现在使用epoll，被循环的任务列表将由epoll提供，如果没有，那么CPU就不用浪费时间了，那么什么情况下会有呢？就是当有任务被唤醒的时候，比如任务因为别人的事件被唤醒，比如A给被阻塞的任务B一个事件“缓冲区非空”，B得到这个事件，B不用被阻塞了，它需要去缓冲区读取数据，这个时候就通知epoll，我可以被调度了。epoll的好处就是可以告诉内核那个任务可以调度，传统的轮询要一个一个任务的查看谁能被调度，如此，加入一个代理加快了CPU处理任务的速度。 nohupnohup 是后台作业的意思， nohup运行的进程将会忽略终端信号运行。即后台运行一个命令。 nohup COMMAND &amp; 用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响它的运行。 supervisorsupervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。 安装 apt-get install -y supervisor 注意：终止进程后重启电脑，进程将会重启。所以要移除某个进程，要把对应的配置删除。 守护进程什么是守护进程？其实感觉守护进程并没有什么明确的定义，只是守护进程有一些特征，这是它需要遵循的。 守护进程的第一个特征是长时间在后台运行的程序，并且主要是为了提供某种服务，而为了能够让服务尽可能随时都可用，就要求这个服务是一直运行的，于是守护进程就守护着这个服务不挂掉。linux里面常见的守护进程一般都是以d结尾的，比如apache的httpd,samba的smbd,ssh的sshd。 它的第二个特征是与启动它的进程的环境隔离，包括关闭它打开的所有文件描述符，终端，会话，进程组，某些环境变量（如工作目录），文件掩码。 为什么要脱离终端？ 如果它不脱离终端，那么就有可能收到来自终端的信号，比如SIGINT(Ctrl+c,会被发往所有前台进程组的进程，它的默认行为就是结束进程),SIGHUP（会被发往会话首进程） 为什么要关闭它打开的所有文件描述符？ 如果创建它的进程之前打开了某个文件，然后创建这个守护进程，这样子进程就继承了fd,如果守护进程不关闭这个fd,一个是会占用资源，二个我猜测和改变工作目录一样，如果这个文件是位于挂载目录，那么就无法umount了 为什么要清掩码？ 这是因为假设它的父进程之前对掩码做过特殊设置，守护进程作为子进程会继承这个，那么它创建文件时，因为掩码的缘故，文件的权限就可能和实际设置的不一致。 第三个特征，守护进程通常由启动脚本启动 apt-utilsapt-utils是Linux系统的兼容程序，在安装系统时有提示推荐安装apt-utils，如果未安装会无法安装第三方提供的Linux软件，只能使用官方推出的软件。比如wget是第三方软件，如果没有apt-utils会导致安装不上","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"}]},{"title":"Mysql","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/MySql/base/","text":"mysql学习笔记 基础一般对于命令是不区分大小写的，为了区分保留关键字，一般保留关键字大写，变量和数据小写。 sudo service mysql start mysql -u root mysql -u root -p show databases; use dataname; show tables; create database; 库名 //创建数据库 drop databses; 库名 //删除数据库 请先到 /etc/mysql 配置 my.cnf 避免中文插入有误 123456[client] default-character-set=utf8 [mysqld] character-set-server=utf8 collation-server=utf8_general_ci mysql –verbose –help | grep -A 1 ‘Default options’ 理解数据库和实例，数据库引擎关于引擎：引擎是数据库进行读写，保存，执行事务等一系列行为时，如何进行这些行为，就是由引擎来决定的。mysql默认会使用InnoDB引擎，引擎可以修改，可以对表指定不同的引擎（数据库应该要支持这种引擎），例如对于需要大量数据访问的，指定查询能力较强的引擎，对于需要事务处理的表，指定能处理事务的引擎。有些引擎是不支持事务的，InnoDB是功能较为齐全的引擎，各方面能力均衡。 索引：引擎不同，索引的实现也不用，保存的索引文件也不同（对于数据库来说，会有表结构文件，表数据文件，索引文件等，引擎不同也文件也不同，因为存储方式不一样）。索引类型 B-Tree索引，哈希索引，空间数据索引（R-Tree），全文索引（数据库引擎要支持，这种索引用来做海量搜索，但是如果需求高，还是用专业的搜索引擎）。主键索引，唯一索引，普通索引 mysql锁：大致分为表级锁，行级锁，页面锁。理解这三种锁很简单，从字面就可以看出锁的锁定粒度，也就知道他们的区别了。其中这个页面锁的粒度介于另外两者之间。同样，锁怎么去控制数据库，也是和引擎有关的。 乐观和悲观：常会看到乐观锁，悲观锁，是一类概念的统称，比如假定对数据库的操作都会产生资源竞争的问题，这个时候就要锁库，悲观的做法就是都锁，实现这样的锁也可以被称为悲观锁。乐观的概念就是相反的，你假定不会出现资源竞争的情况。 悲观的做法 悲观的做法表明，您应该完全锁定资源，直到完成它 。 如果没有人可以在您处理对象时获取对象上的锁定，那么可以确保对象没有被更改。我们使用数据库锁有几个原因： 数据库非常擅长管理锁并保持一致性。 数据库是访问数据的最低级别 - 获取最低级别的锁也会防止其他进程尝试修改数据。 例如，DB中的直接更新，cron作业，清理任务等。 Django应用程序可以在多个进程 （例如工作者）上运行。 在应用程序级别维护锁将需要大量（不必要的）工作。 要在Django中锁定一个对象，我们使用 select_for_update。 主键 id int primary key not null auto_increment 外键 CONSTRAINT emp_fk FOREIGN KEY (in_dpt) REFERENCES department(dpt_name) CONSTRAINT 后面的名字在一张表里面不能重复 插入数据 INSERT INTO tablename (column, column) VALUES （values） 数据类型 除了我们常用的，补充 可变字符VARCHAR， ENUM单选（必须是定义时枚举的值之一） SET多选 SQL约束 通过对表的行为或列的数据做出限制，来确保表的数据的完整性、唯一性 约束类型 主键 默认值 唯一 外键 非空 主键 ：对于主键还有复合主键，由两个字段来确定唯一性，比如一个学生成绩表，有学号，课程号，成绩。通过学号和课程号我们可以得到他的成绩，这个两个字段就组成复合主键，联合主键就是多个字段来决定主键。 唯一 ： 这个约束就是这个字段的这一列的值是唯一的，在执行INSERT 语句的时候，如果插入重复的值则会失败。例如 UNIQUE （phone） 对这个字段进行唯一约束 非空约束： age INT(10) NOT NULL, 在创建的表的语句中出现了这个，就是非空约束，如果插入数据的时候不填，会警告，不会报错。（可能有些mySQL版本会报错） select fields from table where 限制条件 限制条件比如大于小于，在什么范围。 where in (3, 10) where not in (5, 20) where age between 20 and 25 年龄在20到25包括20和25 通配符 where fieldname like ‘12_’ 可以匹配到123 125等 用 % 代表不定个未指定字符 其它内容合并排序：一种将数据排序的算法，在数据库排序的时候使用，这种算法比较灵活，比如你不必把数据完全读取出来，这种方法称为 原地排序 二维阵列：最简单的数据结构，就是一张表 二叉查找树：用来做索引。数据在保存的时候，如果使用了索引，则这个索引信息将建立一个二叉查找树。当然的，你每次更新新的数据都要维护和更新这个查找数，这个算法比起从头到尾查找数据，将会快很多。 B+索引树：二叉的升级版，新的索引结构方式，支持范围查找，比如1到5，你只要找到1，在结果里面，1下面对应的数据一直到5，我们需要的就得到了。如果是二叉树，那么你要找1，然后找2，2还不一定有，接着找3… 哈希表：是一种数据结构，保存的数据是键值对类型的。散列函数（哈希函数）是把键转换成哈希码的函数，散列表（哈希表）是存放记录的数组（这个记录空间是一片连续的空间），数据的键通过散列函数得到一样结果的，都分类在一个数组里面。 概述就是对数据保存进行哈希，得到一个哈希表，去查找数据的时候，对数据的键进行哈希函数运算（得到哈希码后，可能还要进行求模运算才得到记录数组的下标），得到的结果就是记录里面数组的下标，在这个数组里面去找值。 一些概念扩展：数据库是数据库和实例结合的，数据库服务被启动后，用户需要链接到服务上，我们去链接数据库后，系统为你分配了各种资源来操作数据库，就是你得到了数据库的一个实例。这个链接由客户端管理器来处理 多实例：理解了实例和数据库后，我们可以使用多实例，你只需要部署一次数据库应用（在linux上装一个MySql server）然后通过多个实例进行链接，生成的数据库文件也是多个的，这样可以实现很多功能，比如主从数据库。 数据库是多个组件构成的：一般有查询管理器，数据管理器，工具，核心组件 核心组件：进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。安全管理器（Security Manager）：用于对用户的验证和授权。客户端管理器（Client manager）：用于管理客户端连接。…… 工具：备份管理器（Backup manager）：用于保存和恢复数据。复原管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。Administration管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。…… 查询管理器：查询解析器（Query parser）：用于检查查询是否合法查询重写器（Query rewriter）：用于预优化查询查询优化器（Query optimizer）：用于优化查询查询执行器（Query executor）：用于编译和执行查询数据管理器：事务管理器（Transaction manager）：用于处理事务缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存数据访问管理器（Data access manager）：访问磁盘中的数据 获取数据和联接数据 如何获取数据？ 全扫描：完全读取一个表或者索引 范围扫描：where语句 唯一扫描：索引中获取一个值 存取路径： 1、问题的提出 数据库必须支持多个用户的多种应用，因而也就必须提供对数据访问的多个入口，也就是说对同一数据的存储要提供多条存取路径。数据库物理设计的任务之一就是确定应建立哪些存取路径。存取路径即索引结构，因为索引结构提供了定位和存取数据的一条路径。存取方法是快速存取数据库中数据的技术。数据库管理系统一般都提供多种存取方法。常用的存取方法有三种： 索引方法； 簇集方法； HASH方法； B+树索引方法是数据库中经典的索引存取方法，使用最普遍。 2、存取路径的特点 在关系数据库中存取路径具有以下特点： 存取路径和数据是分离的，对用户来说是不可见的； 存取路径可以由用户建立、删除，也可以由系统动态地建立、删除。例如，在执行查询时DBMS的查询优化器会根据优化策略自动地建立索引，以提高查询效率； 存取路径的物理组织通常采用顺序文件、Ｂ+树文件和散列文件结构等等。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"database","slug":"database","permalink":"http://www.liuzhidream.com/tags/database/"}]},{"title":"Flask","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/Flask/","text":"flask框架学习笔记 Flask image 关于扩展通过安装对应的扩展包，可以扩展框架的很多功能（这些扩展和框架会有结合，有点想开启框架的功能一样），Flask的扩展都暴露在flask.ext命名空间下，你可以在环境中通过pip安装好相应扩展，然后再在程序中导入相应的包即可使用扩展。 在新的版本中，引入flask扩展不能再从flask.ext导入了，直接从安装模块导入，比如 from flask_sqlalchemy import SQLAlchemy 自定义url转换器在路由中，使用&lt;&gt;来获取动态参数，默认是字符串类型的，如果想要指定参数类型，需要标记成&lt;converter:variable_name&gt; 这样的格式，类似 &lt;int:quantity&gt;，使用any可以指定多种路径，类似&lt;any(a, b:page_name)&gt;。像any，int做为类型可以自定义，比如定义list类型，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839from urllib import parsefrom flask import Flaskfrom werkzeug.routing import BaseConverterapp = Flask(__name__)class ListConverter(BaseConverter): def __init__(self, url_map, separator='+'): super(ListConverter, self).__init__(url_map) self.separator = parse.unquote(separator) # unquote 对url进行解码 def to_python(self, value): return value.split(self.separator) def to_url(self, values): return self.separator.join(BaseConverter.to_url(self, value) for value in values)app.url_map.converters['list'] = ListConverter@app.route('/list1/&lt;list:page_names&gt;/')def list1(page_names): print(page_names) return 'Separator: &#123;&#125; &#123;&#125;'.format('+', page_names)@app.route('/list2/&lt;list(separator=u\"|\"):page_names&gt;/')def list2(page_names): return 'Separator: &#123;&#125; &#123;&#125;'.format('|', page_names)if __name__ == '__main__': app.run(host='0.0.0.0', port=9000) 唯一url在路由的装饰器中，如果指定了结尾的反斜杠，类似这样的路径 \\page\\，那么浏览器访问地址以反斜杠结尾，或者没有反斜杠都可以访问(访问一个不以反斜杠结尾的url会被重定向到到反斜杠的url上)，如果路由是\\page，那么浏览器访问以反斜杠结尾会报错。 扩展响应这是一个很常见的需求，对返回对象进行包装，比如返回一个ORM的查询实例，这个是不能被json序列化的，通过扩展返回数据，可以对特定对象进行处理。另一种情况，是重写响应类，app.response = JSONResponse 静态文件管理在创建flask实例的时候，通过static_folder修改默认静态文件路径，Flask(__name__, static_folder=&#39;/tmp&#39;) 关于视图通常使用函数视图，但是这样就发挥不出类的作用了，比如继承一个基类，定义一些基础的东西，flask也可以使用基于类的视图 标准类视图标准类视图是继承自 flask.views.View，并且在子类中必须实现 dispatch_request 方法，这个方法类似于视图函数，也要返回一个基于Response或者其子类的对象。通过 app.add_url_rule(url_rule, view_func) 来进行注册 1234567from flask.views import Viewclass PersonalView(View): def dispatch_request(self): return \"hello\"app.add_url_rule('/users/',view_func=PersonalView.as_view('personalview')) 基于调度方法的视图继承自 flask.views.MethodView，可以对不同的HTTP方法执行对应的函数，使用方法的小写名。在类视图中定义一个属性叫做decorators，然后存储装饰器。以后每次调用这个类视图的时候，就会执行这个装饰器 12345678910111213141516171819202122232425262728293031323334from flask import Flask, jsonifyfrom flask.views import MethodViewfrom flask import sessionapp = Flask(__name__)def login_required(func): def wrapper(*args, **kwargs): if not session.get(\"user_id\"): return 'auth failure' return func(*args, **kwargs) return wrapperclass UserAPI(MethodView): decorators = [login_required] def get(self): return jsonify(&#123; 'username': 'fake', 'avatar': 'http://lorempixel.com/100/100/nature/' &#125;) def post(self): return 'UNSUPPORTED!'app.add_url_rule('/user', view_func=UserAPI.as_view('userview'))if __name__ == '__main__': app.run(host='0.0.0.0', port=9000) 使用命令行接口和Django一样，flask框架也提供了很多命令，flask命令需要添加都环境变量，这个一般在安装后就有了。然后需要设置flask应用的环境变量，可以使用 export FLASK_APP=&#39;app.py path&#39; 。 也可以自定义命令，比如 flask run_test 执行一个测试脚本，代码如下： 1234@app.cli.command()def run_test(): print('this is a test script') Context理解请求上下文和应用上下文。 werkzeugWSGI 协议工具集 配置参数讲解创建app需要传递配置参数，以供各个模块使用 SECRET_KEY：密码加盐的参数，推荐设置成系统变量 扩展模块扩展模块很多是基于现有的模块做扩展，封装成flask的扩展，比如把实例加入请求上下文中；模块的更多用法可以参考原模块。 需要分析用法的模块，列出项目地址。 flask_script用来自定义命令的，不过模块没有维护了，官方也推荐不要再使用它了，推荐使用 `@app.cli.command` 的形式来添加命令。然后配置环境变量，通过flask command的形式来执行命令。 可以使用装饰器，和类来添加命令。装饰器：`@manager.command`；类：继承Command类，实现run方法。 由于是弃用的模块，不再赘述。 flask_migrateFlask-Migrate是用于处理SQLAlchemy 数据库迁移的扩展工具。当Model出现变更的时候，通过migrate去管理数据库变更。依赖alembic模块。 用法： 12345678910from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyfrom flask_migrate import Migrateapp = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///app.db'db = SQLAlchemy(app)migrate = Migrate(app, db) 命令： 初始化flask db init这个命令会在当前目录下生成一个migrations文件夹。这个文件夹也需要和其他源文件一起，添加到版本控制。 生成最初的迁移flask db migrate此命令会在migrations下生成一个version文件夹，下面包含了对应版本的数据库操作py脚本。 数据库升级flask db upgrade最后一步。此命令相当于执行了version文件夹下的相应py版本，对数据库进行变更操作。此后，对model有变更，只要重复migrate和upgrade操作即可。 由于migrate并不一定全部发现你对model的所有改动，因此生成的py脚本需要review, 有错的话则需要edit。 例如目前知道的，表名称表更，列名称变更，或给constraints命名等，migreate都不能发现的。更多限制细节见此：Alembic autogenerate documentation。 在Alembic 中，数据库迁移用迁移脚本表示。脚本中有两个函数，分别是upgrade() 和downgrade()。upgrade() 函数把迁移中的改动应用到数据库中，downgrade() 函数则将改动删除。Alembic 具有添加和删除改动的能力，因此数据库可重设到修改历史的任意一点。 我们可以使用revision 命令手动创建Alembic 迁移，也可使用migrate 命令自动创建。手动创建的迁移只是一个骨架，upgrade() 和downgrade() 函数都是空的，开发者要使用Alembic 提供的Operations 对象指令实现具体操作。自动创建的迁移会根据模型定义和数据库当前状态之间的差异生成upgrade() 和downgrade() 函数的内容。自动创建的迁移不一定总是正确的，有可能会漏掉一些细节。自动生成迁移脚本后一定要进行检查。 查看帮助文档：flask db –help 运行flask db init后，提示配置日志输出，默认输出到终端，应该配置日志到文件，方便以后排查问题（看看是谁动了数据库） flask_loggingGitHub地址 用来快速实现登录验证。在User模型中，通过继承UserMixin实现以下属性： is_authenticated 属性，用来判断是否是已经授权了，如果通过授权就会返回true is_active 属性，判断是否已经激活 is_anonymous 属性，判断是否是匿名用户 get_id() 方法，返回用户的唯一标识 模块提供了login_required, login_user, logout_user等方法，验证成功后，通过login_user设置session。 flask_sqlalchemy配置参数： SQLALCHEMY_DATABASE_URI：配置数据库连接 sqlite:////tmp/test.db 或 mysql://username:password@server/db SQLALCHEMY_BINDS：用来绑定多个数据库，例如：12345SQLALCHEMY_DATABASE_URI = &apos;postgres://localhost/main&apos;SQLALCHEMY_BINDS = &#123; &apos;users&apos;: &apos;mysqldb://localhost/users&apos;, &apos;appmeta&apos;: &apos;sqlite:////path/to/appmeta.db&apos;&#125; 多个数据库在创建数据库或在模型中声名使用哪个，比如在模型中 __bind_key__ = &#39;users&#39; SQLALCHEMY_ECHO：值为Boolean（默认为False），设置为True，会把查询语句输出到stderr SQLALCHEMY_RECORD_QUERIES：可以用于显式地禁用或者启用查询记录。查询记录 在调试或者测试模式下自动启用。一般我们不设置。 QLALCHEMY_NATIVE_UNICODE：可以用于显式地禁用支持原生的unicode。 SQLALCHEMY_POOL_SIZE：数据库连接池的大小。默认是数据库引擎的默认值（通常是 5）。当用户需要访问数据库时，并非建立一个新的连接，而是从连接池中取出一个已建立的空闲连接对象。使用完毕后，用户也并非将连接关闭，而是将连接放回连接池中，以供下一个请求访问使用。而连接的建立、断开都由连接池自身来管理。 SQLALCHEMY_POOL_TIMEOUT：指定数据库连接池的超时时间。默认是10。 SQLALCHEMY_POOL_RECYCLE：自动回收连接的秒数（1200即为2小时）。这对MySQL是必须的，默认情况下MySQL会自动移除闲置8小时或者以上的连接，Flask-SQLAlchemy会自动地设置这个值为2小时。也就是说如果连接池中有连接2个小时被闲置，那么其会被断开和抛弃。 SQLALCHEMY_MAX_OVERFLOW：控制在连接池达到最大值后可以创建的连接数。当这些额外的连接使用后回收到连接池后将会被断开和抛弃。保证连接池只有设置的大小。 SQLALCHEMY_TRACK_MODIFICATIONS：如果设置成 True (默认情况)，Flask-SQLAlchemy 将会追踪对象的修改并且发送信号。这需要额外的内存，如果不必要的可以禁用它。 常用字段 Command Description Integer int普通整数，一般是32位 SmallInteger int取值范围小的整数，一般是16位 BigInteger int或long不限制精度的整数 Float float浮点数 Numeric decimal.Decimal普通整数，一般是32位 String str变长字符串 Text str变长字符串，对较长或不限长度的字符串做了优化 Unicode unicode变长Unicode字符串 UnicodeText unicode变长Unicode字符串，对较长或不限长度的字符串做了优化 Boolean bool布尔值 Date datetime.date时间 Time datetime.datetime日期和时间 LargeBinary str二进制文件 Enum enum枚举类型 字段选项 Command Description primary_key 如果为True，代表表的主键 unique 如果为True，代表这列不允许出现重复的值 index 如果为True，为这列创建索引，提高查询效率 nullable 如果为True，允许有空值，如果为False，不允许有空值 default 为这列定义默认值，如default=1 flask_sqlalchemy的db实例提供了创建数据库的方法，不过这个是把当前上下文的模型创建数据库，如果是大型项目，那么就是把所有模型创建数据库，它的使用也有局限性，一般做为外部使用（一个测试工具，在这个上下文中创建db实例，对指定的模型来创建表）。所以应该使用迁移工具来管理数据库。 常用的过滤器 Command Description filter() 把过滤器添加到原查询上，返回一个新查询 filter_by() 把等值过滤器添加到原查询上，返回一个新查询 limit() 使用指定的值限定原查询返回的结果 offset() 偏移原查询返回的结果，返回一个新查询 order_by() 根据指定条件对原查询结果进行排序，返回一个新查询 group_by() 根据指定条件对原查询结果进行分组，返回一个新查询 执行器 Command Description all() 以列表形式返回查询的所有结果 first() 返回查询的第一个结果，如果未查到，返回None first_or_404() 返回查询的第一个结果，如果未查到，返回404 get() 返回指定主键对应的行，如不存在，返回None get_or_404() 返回指定主键对应的行，如不存在，返回404 count() 返回查询结果的数量 paginate() 返回一个Paginate对象，它包含指定范围内的结果","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"farmework","slug":"farmework","permalink":"http://www.liuzhidream.com/tags/farmework/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Python-multiprocessing","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python-multiprocessing/README/","text":"python多进程学习笔记 进程Python标准库为我们提供了 threading 和 multiprocessing 模块编写相应的多线程/多进程代码。从Python3.2开始，标准库为我们提供了 concurrent.futures 模块，它提供了 ThreadPoolExecutor 和 ProcessPoolExecutor 两个类，实现了对 threading 和 multiprocessing 的更高级的抽象，对编写线程池/进程池提供了直接的支持。 concurrent.futures基础模块是executor和future。future是concurrent.futures模块和asyncio模块的重要组件 概念fork()pid=os.fork() 只用在Unix系统中有效，Windows系统中无效 fork函数调用一次，返回两次：在父进程中返回值为子进程id，在子进程中返回值为0 和线程的区别进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位 进程池python中，进程池内部会维护一个进程序列。当需要时，程序会去进程池中获取一个进程。如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。 进程池支持同步，异步，映射方式添加任务到进程池。 预创建预先创建一组子进程，当有新任务来时，系统通过 调配 该组进程中的某个 子进程 完成此任务。 为什么需要？ 进程创建，销毁需要消耗cpu时间 预先创建，以空间换时间，提升性能。时间是唯一稀缺资源，空间不足加内存，能够用钱解决的问题，都不是问题，钱都解决不了的问题才是问题 通过系统合理分配任务，提高性能。尽量实现真正的并行处理，提升系统处理效率 关于GIL多进程，一个进程就有一个GIL 内核态和用户态我们知道现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操心系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。每个进程可以通过系统调用进入内核，因此，Linux内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。我们常说的陷入内核态，就是当前进程进入内核，去访问更高权限的东西。 需要注意的细节问题： 内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中。 Linux使用两级保护机制：0级供内核使用，3级供用户程序使用。 当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。 当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。 windows中创建进程在windows中创建进程，相当于导入模块，所以要把进行放在 if __name__ == &#39;__main__&#39;: 后面来执行，而且子进程会把代码再跑一次，如果你在代码块最外层有打印等执行语句，也会被执行（所以一般外层的代码都封装在函数里面，在linux上不会这样，由于外层代码不一定全是函数，只要是会被执行的都要执行，这和想像的情况相差太多，所以我建议多进程只在linux上使用，在windos上的多进程，只有演示学习的意义，过于复杂的程序受到太多的限制） 这是 Windows 上多进程的实现问题。在 Windows 上，子进程会自动 import 启动它的这个文件，而在 import 的时候是会执行这些语句的。如果你这么写的话就会无限递归创建子进程报错。但是在multiprocessing.Process的源码中是对子进程再次产生子进程是做了限制的，是不允许的，于是出现如上的错误提示。所以必须把创建子进程的部分用那个 if 判断保护起来，import 的时候 name 不是 main ，就不会递归运行了。 操作系统的设计 以多进程形式，允许多个任务同时运行； 以多线程形式，允许单个任务分成不同的部分运行； 提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。 队列标准库提供了队列模块queue，在py2中，通过 import Queue 使用队列，在py3中通过 from queue import Queue 来使用队列。在multiprocessing模块中，通过了Queue类来实现队列。queue.Queue是进程内非阻塞队列，multiprocess.Queue是跨进程通信队列。 from queue import Queue这个是普通的队列模式，类似于普通列表，先进先出模式，get方法会阻塞请求，直到有数据get出来为止 from multiprocessing.Queue import Queue（各子进程共有）这个是多进程并发的Queue队列，用于解决多进程间的通信问题。普通Queue实现不了 multiprocessing.Queuequeue = Queue(5) 初始化Queue()对象时（ 例如：q=Queue() ），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头） Queue.qsize()：返回当前队列包含的消息数量，结果不可靠，理由同q.empty()和q.full()一样 Queue.empty()：如果队列为空，返回True，反之False。该结果不可靠，比如在返回True的过程中，如果队列中又加入了项目。 Queue.full()：如果队列满了，返回True，反之False。该结果不可靠，比如在返回True的过程中，如果队列中的项目被取走。 Queue.get([block[, timeout]])：获取队列中的一条消息，然后将其从列队中移除，block默认值为True；这里的block代表阻塞。 如果block使用默认值，且没有设置timeout（单位秒），消息列队如果为空，此时程序将被阻塞（停在读取状态），直到从消息列队读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出”Queue.Empty”异常 如果block值为False，消息列队如果为空，则会立刻抛出”Queue.Empty”异常 Queue.get_nowait()：相当Queue.get(False) Queue.put(item,[block[, timeout]])：将item消息写入队列，block默认值为True 如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出”Queue.Full”异常 如果block值为False，消息列队如果没有空间可写入，则会立刻抛出”Queue.Full”异常 Queue.put_nowait(item)：相当Queue.put(item, False) 管道进程间通信（IPC）方式二：管道 创建管道的类：Pipe([duplex])，在进程之间创建一条管道，并返回元组（conn1,conn2），其中conn1，conn2表示管道两端的连接对象，强调一点：必须在产生Process对象之前产生管道 参数介绍： duplex:默认值是True，管道是全双工的，如果将duplex改成False，conn1只能用于接收，conn2只能用于发送。 方法介绍：（详情参考文档：multiprocessing.connection.Connection类） conn1.recv()：接收conn2.send(obj)发送的对象。如果没有消息可接收，recv方法会一直阻塞。如果连接的另外一端已经关闭，那么recv方法会抛出EOFError conn1.send(obj)：将一个对象发送到应该使用recv()读取的连接的另一端。obj必须是与序列化兼容的任意对象。非常大的pickle(大约32 MiB+，尽管这取决于操作系统)可能会引发ValueError异常 conn1.close()：关闭连接。如果conn1被垃圾回收，将自动调用此方法 conn1.fileno()：返回连接使用的整数文件描述符 conn1.poll([timeout])：返回是否有任何数据可供读取(如果连接上的数据可用，返回True)。timeout指定等待的最长时限。如果省略此参数，方法将立即返回结果。如果将timeout射成None，操作将无限期地等待数据到达 conn1.recv_bytes([maxlength])：接收c.send_bytes()方法发送的一条完整的字节消息。maxlength指定要接收的最大字节数。如果进入的消息，超过了这个最大值，将引发IOError异常，并且在连接上无法进行进一步读取。如果连接的另外一端已经关闭，再也不存在任何数据，将引发EOFError异常 conn.send_bytes(buffer [, offset [, size]])：通过连接发送字节数据缓冲区，buffer是支持缓冲区接口的任意对象，offset是缓冲区中的字节偏移量，而size是要发送字节数。结果数据以单条消息的形式发出，然后调用c.recv_bytes()函数进行接收 conn1.recv_bytes_into(buffer [, offset])：接收一条完整的字节消息，并把它保存在buffer对象中，该对象支持可写入的缓冲区接口（即bytearray对象或类似的对象）。offset指定缓冲区中放置消息处的字节位移。返回值是收到的字节数。如果消息长度大于可用的缓冲区空间，将引发BufferTooShort异常。 代码举例： 123456789101112131415161718192021222324252627282930313233343536373839404142from multiprocessing import Process, Pipeimport timedef consumer(p, name): left_conn, right_conn = p left_conn.close() while True: try: data = right_conn.recv() print('%s 消费产品:%s' % (name, data)) except EOFError: right_conn.close() breakdef producer(sequence, p): left_conn, right_conn = p right_conn.close() for i in sequence: left_conn.send(i) print('%s 生产产品:%s' % ('c2', i)) time.sleep(1) else: left_conn.close()if __name__ == '__main__': left, right = Pipe() c1 = Process(target=consumer, args=((left, right), 'c1')) c1.start() seq = (i for i in range(10)) producer(seq, (left, right)) right.close() left.close() c1.join() print('主进程') 注意：生产者和消费者都没有使用管道的某个端点，就应该将其关闭，如在生产者中关闭管道的右端，在消费者中关闭管道的左端。如果忘记执行这些步骤，程序可能再消费者中的recv()操作上挂起。管道是由操作系统进行引用计数的，必须在所有进程中关闭管道后才能生产EOFError异常。因此在生产者中关闭管道不会有任何效果，付费消费者中也关闭了相同的管道端点。 管道可以用于双向通信，利用通常在客户端/服务器中使用的请求／响应模型或远程过程调用，就可以使用管道编写与进程交互的程序（代码略） Process1234from multiprocessing import Processp = Process() 创建实例的参数： group参数未使用，值始终为None target表示调用对象，即子进程要执行的任务 args表示调用对象的位置参数元组，args=(1,2,’hexin’,) kwargs表示调用对象的字典，kwargs={‘name’:’hexin’,’age’:18} name为子进程的名称 Process()由该类实例化得到的对象，表示一个子进程中的任务（尚未启动） 方法介绍： p.start()：启动进程，并调用该子进程中的p.run() p.run()：进程启动时运行的方法，正是它去调用target指定的函数，我们自定义类的类中一定要实现该方法 p.terminate()：强制终止进程p，不会进行任何清理操作，如果p创建了子进程，该子进程就成了僵尸进程，使用该方法需要特别小心这种情况。如果p还保存了一个锁那么也将不会被释放，进而导致死锁 p.is_alive()：如果p仍然运行，返回True p.join([timeout])：主线程等待p终止（强调：是主线程处于等的状态，而p是处于运行的状态）。timeout是可选的超时时间，需要强调的是，p.join只能join住start开启的进程，而不能join住run开启的进程 实例属性： p.daemon：默认值为False，如果设为True，代表p为后台运行的守护进程，当p的父进程终止时，p也随之终止，并且设定为True后，p不能创建自己的新进程，必须在p.start()之前设置— p.name：进程的名称 p.pid：进程的pid p.exitcode：进程在运行时为None、如果为–N，表示被信号N结束(了解即可) p.authkey：进程的身份验证键，默认是由os.urandom()随机生成的32字符的字符串。这个键的用途是为涉及网络连接的底层进程间通信提供安全性，这类连接只有在具有相同的身份验证键时才能成功（了解即可）","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Celery","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/Celery/","text":"Celery - Distributed Task Queue。要理解 Celery 本身不是任务队列，它是管理分布式任务队列的工具，或者换一种说法，它封装好了操作常见任务队列的各种操作，我们用它可以快速进行任务队列的使用与管理，当然你也可以自己看 rabbitmq 等队列的文档然后自己实现相关操作都是没有问题的。 安装通过Python的包管理工具来安装，在我查到的一些资料中，celery和docker的配合不是很好，建议不要在单一容器中使用celery了。 架构 生产者(Celery client)。生产者(Celery client)发送消息。在Flask上工作时，生产者(Celery client)在Flask应用内运行。 消费者(Celery workers)。消费者用于处理后台任务。消费者(Celery client)可以是本地的也可以是远程的。我们可以在运行Flask的server上运行一个单一的消费者(Celery workers)，当业务量上涨之后再去添加更多消费者(Celery workers)。 消息传递者(message broker)。生产者(Celery client)和消费者(Celery workers)的信息的交互使用的是消息队列(message queue)。Celery支持若干方式的消息队列，其中最常用的是RabbitMQ和Redis. 以上是最基本的架构，完整的组件还包括： Celery Beat：任务调度器 Celery Worker：执行任务的消费者 Broker：消息代理 Product：任务生产者（通过API，装饰器等产生任务并交个任务队列处理） Result Backend：任务处理完成后，保存状态信息，以供查询 1，4都是任务的生产者，只是方式不一样，1的方式是Beat进程读取配置文件，周期性的将到期的任务发给任务队列执行，就是定时任务。 在flask中使用celery如何集成，并且很好的解耦模块是celery运用的关键。你总不能把代码都堆叠在一起吧。 注意事项 flask_celery不能支持celery4.0，所以弃用扩展模块，直接使用celery模块。使用扩展的好处是在扩展模块在一个文件初始化，并且全局保持一个实例对象，所以你的celery需要在app创建后才能创建，需要考虑是否使用了全局的celery对象 创建celery的实例对象的名字使用flask应用程序app的名字，通过 app.name 获取，如果你使用扩展插件，建议不要修改此名称，否则创建失败，不使用扩展插件也不建议修改 当有多个装饰器的时候，celery.task一定要在最外层 init代码 123app = create_app(CONFIG)celery = CeleryApp(app.name)celery.conf.update(app.config) 首先创建Flask app的实例app，然后创建Celery的实例celery，这里需要传递一个名称，这个名称会作为celery task的前缀，例如 flask_app.celery_app.task.long_task，long_task是我们定义的任务，你要改创建实例的参数也可以，建议不要修改。这里的CeleryApp是自己编写的，继承Celery的一个类，目的是实现单实例，让其它模块通过CeleryApp创建的实例保持一样，然后调用celery.conf.update更新参数，flask app.config 是继承dict的Config类，这样就把需要的参数配置通过flask配置，作用于celery。 flask大多数的插件做的事情就是在单独的扩展文件中，先不传递参数实例化扩展，然后在创建app的时候初始化它，估计flask_celery也是做差不多的事情，不过实例化Celery必须要先传递参数，现在插件没有在更新了(有一些其他名称的扩展可以支持)，主要还是为了工程化。 这里记录一下扩展包的情况吧，在py3中，有： Flask-Celery：这个其实不是扩展，而是装这个就把Celery相关的给安装了，这个是Celery的作者写的，他也说在4.0版本不再需要了，我也没看出来这个有什么用 Flask-Celery-Helper：这个就是扩展了，导入用flask_celery，不支持4.0 Flask-Celery-py3，Flask-Celery3：好像都是不支持4.0的 Flask-CeleryExt：在文档中写明可以支持4.0了，和大部分扩展使用方法一样，用懒加载的方式实例化 数据序列化 Command Description pickle: 二进制序列化方式；是标准库的一个模块，支持Python的内置数据结构，但是他是Python的专有协议，在celery3.2开始，出于安全考虑，不再采用此方案； json: json支持多种语言，可用于跨语言方案，但好像不支持自定义的类对象； XML: 类似标签语言； msgpack: 二进制的类json序列化方案，但比json的数据结构更小，更快； yaml: yaml表达能力更强，支持的数据类型较json多，但是python客户端的性能不如json; 在自定义对象上，序列化方案我也出现过问题，pickle用了不行，可能就是不支持了，有待解决 使用步骤 celery = Celery(app.name) 创建celery实例 celery.conf.update(app.config) 更新配置 在需要后台运行的任务使用@celery.task 123@celery.taskdef hello_world(): return \"hello_world\" 需要注意的是，被装饰的任务需要调用才会加到任务队列，也就是通过hello_world.delay()调用，在官方的例子中，通过继承的方式，增加 __call__ 方法，内部调用run，这样装饰器@celery.task()便会直接加入任务队列了，不过这样的功能应该是不需要的。 通过 r = hello_world.delay() 方法，返回的对象拥有以下方法： Command Description r.ready() #查看任务状态，返回布尔值，任务执行完成，返回True，否则返回False. r.wait() #等待任务完成,返回任务执行结果，很少使用； r.get(timeout=1) #获取任务执行结果，可以设置等待时间 r.result #任务执行结果. r.state #PENDING,START,SUCCESS，任务当前的状态 r.status #PENDING,START,SUCCESS，任务当前的状态 r.successful #任务成功返回true r.traceback #如果任务抛出了一个异常，你也可以获取原始的回溯信息 装饰器参数`@celery.task()` name：可以显示指定任务的名字； serializer：指定序列化的方法； bind：一个bool值，设置是否绑定一个task的实例，如果把绑定，task实例会作为参数传递到任务方法中，可以访问task实例的所有的属性，具体属性可参照 celery--app--task.py 中的Task类，通过self.request.__dict__打印相关属性； base：指定任务的基类，可以定义一个类，继承celery.Task，利用重写或扩展的类接口技术制定需求，例如on_success方法，默认是没有返回值的，就是提供这个钩子让开发者自定义的； 调用任务任务被装饰器装饰后，通过task.delay()，task.apply_async()把任务加入到队列中，send_task()，可以发送未被注册的异步任务，即没有被celery.task装饰的任务 apply_async的参数 Command Description countdown 设置该任务等待一段时间再执行，单位为s； eta 定义任务的开始时间；eta=time.time()+10; expires 设置任务时间，任务在过期时间后还没有执行则被丢弃； retry 如果任务失败后,是否重试;使用true或false，默认为true shadow 重新指定任务的名字str，覆盖其在日志中使用的任务名称； retry_policy 重试策略，为一个字典，各个键值配置：max_retries-最大重试次数，默认为 3 次. interval_start-重试等待的时间间隔秒数，默认为 0 ，表示直接重试不等待. interval_step-每次重试让重试间隔增加的秒数，可以是数字或浮点数，默认为 0.2. interval_max-重试间隔最大的秒数,即通过 interval_step 增大到多少秒之后，就不在增加了，可以是数字或者浮点数，默认为 0.2 . routing_key 自定义路由键； queue 指定发送到哪个队列； exchang 指定发送到哪个交换机； priority 任务队列的优先级，0-9之间； serializer 任务序列化方法；通常不设置； compression 压缩方案，通常有zlib,bzip2 headers 为任务添加额外的消息； link 任务成功执行后的回调方法；是一个signature对象；可以用作关联任务； link_error 任务失败后的回调方法，是一个signature对象； 自定义发布者,交换机,路由键, 队列, 优先级,序列方案和压缩方法: 1234567task.apply_async((2,2), compression='zlib', serialize='json', queue='priority.high', routing_key='web.add', priority=0, exchange='web_exchange') 基本配置1234567891011121314151617181920212223242526272829303132333435363738394041424344# 注意，celery4版本后，CELERY_BROKER_URL改为BROKER_URLBROKER_URL = 'amqp://username:passwd@host:port/虚拟主机名'# 指定结果的接受地址CELERY_RESULT_BACKEND = 'redis://username:passwd@host:port/db'# 指定任务序列化方式CELERY_TASK_SERIALIZER = 'msgpack' # 指定结果序列化方式CELERY_RESULT_SERIALIZER = 'msgpack'# 任务过期时间,celery任务执行结果的超时时间CELERY_TASK_RESULT_EXPIRES = 60 * 20 # 指定任务接受的序列化类型.CELERY_ACCEPT_CONTENT = [\"msgpack\"] # 任务发送完成是否需要确认，这一项对性能有一点影响 CELERY_ACKS_LATE = True # 压缩方案选择，可以是zlib, bzip2，默认是发送没有压缩的数据CELERY_MESSAGE_COMPRESSION = 'zlib' # 规定完成任务的时间CELERYD_TASK_TIME_LIMIT = 5 # 在5s内完成任务，否则执行该任务的worker将被杀死，任务移交给父进程# celery worker的并发数，默认是服务器的内核数目,也是命令行-c参数指定的数目CELERYD_CONCURRENCY = 4 # celery worker 每次去rabbitmq预取任务的数量CELERYD_PREFETCH_MULTIPLIER = 4 # 每个worker执行了多少任务就会死掉，默认是无限的CELERYD_MAX_TASKS_PER_CHILD = 40 # 设置默认的队列名称，如果一个消息不符合其他的队列就会放在默认队列里面，如果什么都不设置的话，数据都会发送到默认的队列中CELERY_DEFAULT_QUEUE = \"default\" # 设置详细的队列CELERY_QUEUES = &#123; \"default\": &#123; # 这是上面指定的默认队列 \"exchange\": \"default\", \"exchange_type\": \"direct\", \"routing_key\": \"default\" &#125;, \"topicqueue\": &#123; # 这是一个topic队列 凡是topictest开头的routing key都会被放到这个队列 \"routing_key\": \"topic.#\", \"exchange\": \"topic_exchange\", \"exchange_type\": \"topic\", &#125;, \"task_eeg\": &#123; # 设置扇形交换机 \"exchange\": \"tasks\", \"exchange_type\": \"fanout\", \"binding_key\": \"tasks\", &#125;,&#125; 命令celery worker -A auto_app.celery --loglevel=info 启动Worker 任务状态 Command Description PENDING 任务等待中 STARTED 任务已开始 SUCCESS 任务执行成功 FAILURE 任务执行失败 RETRY 任务将被重试 REVOKED 任务取消 通过 r.get(&#39;status&#39;) == &#39;PENDING&#39; 获取状态 设置任务调度器配置文件: 123456789101112from datetime import timedeltafrom celery.schedules import crontabConfig = dict( CELERYBEAT_SCHEDULE=&#123; 'ptask': &#123; 'task': 'flask_app.celery_app.task.period_task', 'schedule': timedelta(seconds=5), &#125;, &#125;, CELERY_TIMEZONE='Asia/Shanghai') 配置中 schedule 就是间隔执行的时间，这里可以用 datetime.timedelta 或者 crontab，如果定时任务涉及到 datetime 需要在配置中加入时区信息，否则默认是以 utc 为准。例如中国可以加上： CELERY_TIMEZONE = &#39;Asia/Shanghai&#39; task的任务路径不能出错，在启动Worker进程的时候，可以看到task列表，这里指的的定时任务和其对应即可。 启动命令： 需要执行两个进程，一个是Worker进程，用来处理生成的任务，一个就是beat进程，启动任务调度器进程，定时生成任务 celery beat -A auto_app.celery --loglevel=info celery worker -A auto_app.celery --loglevel=info 任务调度会有需要动态添加任务，管理任务的情况，Django框架通过djang-celery实现在管理后台创建，删除，更新任务，它通过自定义调度类来实现，如果有类似的需求，可以参考源码实现 工作流Signature 对象，把任务通过签名的方法传递给其它任务，成为一个子任务 12345In [6]: task = signature(&apos;flask_app.celery_app.task.add&apos;, args=(2, 2), countdown=5)In [7]: taskOut[7]: flask_app.celery_app.task.add(2, 2)In [8]: task.apply_async()Out[8]: &lt;AsyncResult: 0cbe319e-c3f6-48b9-b1e4-6a034711cf3a&gt; from celery import signature 导入signature，可以看到，传递的第一个参数是已经存在的任务，也可以先把add导入，通过 add.subtask((2, 2), countdown=5)，或使用subtask的缩写s，add.s()。 子任务能支持偏函数的方式，利用它实现工作流。 支持原语实现工作流，原语表示由若干条指令组成的，用于完成一定功能的过程 1.chain - 调用链，任务的链式执行，前面的执行结果作为参数传递给后面，直到任务完成 chain 函数接受一个任务的列表，Celery 保证一个 chain 里的子任务会依次执行，在 AsynResult 上执行 get 会得到最后一个任务的返回值。和 link 功能类似，每一个任务执行结果会当作参数传入下一个任务，所以如果你不需要这种特性，采用 immutable signature 来取消。 123456def subtask(): from celery import chain part = add.s(1, 2) | add.s(3) | add.s(5) # or part = (add.s(1, 2), add.s(3), add.s(5)) res = chain(part)() print(res.get()) 2.group - 任务的并发执行 1234def subtask(): from celery import group res = group([add.s(i, i) for i in range(1, 10)])() print(res.get()) group 函数也接受一个任务列表，这些任务会同时加入到任务队列中，且执行顺序没有任何保证。在 AsynResult 上执行 get 会得到一个包含了所有返回值的列表。意参数必须是list对象 chord - 带回调的 group chord 基本功能和 group 类似，只是有一个额外的回调函数。回调函数会在前面的任务全部结束时执行，其参数是一个包含了所有任务返回值的列表。在 AsynResult 上执行 get 会得到回调函数的返回值。 map/starmap - 每个参数都作为任务的参数执行一遍 chunks - 将任务分块 总结在启动Worker进程后，可以看到被装饰的任务已经被列出来了，这说明Celery有读取文件的机制(你可以在任务模块的最外层使用print测试)，被装饰的函数应该要在最外层，而且，创建实例后，再去修改配置，似乎没有生效（在我的测试中是这样的），其实这也符合逻辑，在进程被创建了，却又动态的去修改配置，与之对应的风险也很高。 celery是队列管理工具，真正的队列是Broker，更深入一点要了解RabbitMQ，AMQP协议，一般在celery上关注Worker，可以使用多个Worker，任务的生成使用定时器或触发的机制，任务本身就要由Python来编写，也包括对执行结果的处理。 任务生成，处理有了，还有队列的管理，默认使用名为celery的队列，可以配置队列，比如队列A，队列B，进入A队列的任务优先级要高，会被先处理。可以在启动worker进程的时候指明队列(通过-Q指定队)，这样这个Worker只会处理指定的队列。 后续扩展内容：celery信号，分析任务执行情况。Worker管理，监控和管理celery。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"https ssl 证书","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Web/ssl-credential/","text":"使用https协议需要证书，可以自己创建，不足之处是不被认可，加密效果是一样的 https ssl 证书使用https协议需要证书，可以自己创建，不足之处是不被认可，加密效果是一样的。以下内容截取自网络。 需要依次输入国家，地区，组织，email。最重要的是有一个common name，可以写你的名字或者域名。如果为了https申请，这个必须和域名吻合，否则会引发浏览器警报。生成的csr文件交给CA签名后形成服务端自己的证书。 创建自签名证书的步骤注意：以下步骤仅用于配置内部使用或测试需要的SSL证书。第1步：生成私钥使用openssl工具生成一个RSA私钥$ openssl genrsa -des3 -out server.key 2048说明：生成rsa私钥，des3算法，2048位强度，server.key是秘钥文件名。注意：生成私钥，需要提供一个至少4位的密码。第2步：生成CSR（证书签名请求）生成私钥之后，便可以创建csr文件了。此时可以有两种选择。理想情况下，可以将证书发送给证书颁发机构（CA），CA验证过请求者的身份之后，会出具签名证书（很贵）。另外，如果只是内部或者测试需求，也可以使用OpenSSL实现自签名，具体操作如下： $ openssl req -new -key server.key -out server.csr说明：需要依次输入国家，地区，城市，组织，组织单位，Common Name和Email。其中Common Name，可以写自己的名字或者域名，如果要支持https，Common Name应该与域名保持一致，否则会引起浏览器警告。 Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:BeijingLocality Name (eg, city) []:BeijingOrganization Name (eg, company) [Internet Widgits Pty Ltd]:joyiosOrganizational Unit Name (eg, section) []:info technologyCommon Name (e.g. server FQDN or YOUR name) []:demo.joyios.comEmail Address []:liufan@joyios.com 第3步：删除私钥中的密码在第1步创建私钥的过程中，由于必须要指定一个密码。而这个密码会带来一个副作用，那就是在每次Apache启动Web服务器时，都会要求输入密码，这显然非常不方便。要删除私钥中的密码，操作如下： cp server.key server.key.orgopenssl rsa -in server.key.org -out server.key 第4步：生成自签名证书如果你不想花钱让CA签名，或者只是测试SSL的具体实现。那么，现在便可以着手生成一个自签名的证书了。 $ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt说明：crt上有证书持有人的信息，持有人的公钥，以及签署者的签名等信息。当用户安装了证书之后，便意味着信任了这份证书，同时拥有了其中的公钥。证书上会说明用途，例如服务器认证，客户端认证，或者签署其他证书。当系统收到一份新的证书的时候，证书会说明，是由谁签署的。如果这个签署者确实可以签署其他证书，并且收到证书上的签名和签署者的公钥可以对上的时候，系统就自动信任新的证书。第5步：安装私钥和证书将私钥和证书文件复制到Apache的配置目录下即可，在Mac 10.10系统中，复制到/etc/apache2/目录中即可。需要注意的是，在使用自签名证书时，浏览器会提示证书不受信任，如果你是对外网站使用，建议还是去CA机构申请可信的SSL证书，现在证书也很便宜，沃通CA超快SSL Pre才488元/年。 一般情况下，如果能找到可用的证书，就可以直接使用，只不过会因证书的某些信息不正确或与部署证书的主机不匹配而导致浏览器提示证书无效，但这并不影响使用。需要手工生成证书的情况有：找不到可用的证书需要配置双向SSL，但缺少客户端证书需要对证书作特别的定制首先，无论是在Linux下还是在Windows下的Cygwin中，进行下面的操作前都须确认已安装OpenSSL软件包。 创建根证书密钥文件(自己做CA)root.key：openssl genrsa -des3 -out root.key输出内容为：[lenin@archer ~]$ openssl genrsa -des3 -out root.keyGenerating RSA private key, 512 bit long modulus……………..++++++++++++..++++++++++++e is 65537 (0×10001)Enter pass phrase for root.key: ← 输入一个新密码Verifying – Enter pass phrase for root.key: ← 重新输入一遍密码 创建根证书的申请文件root.csr：openssl req -new -key root.key -out root.csr输出内容为：[lenin@archer ~]$ openssl req -new -key root.key -out root.csrEnter pass phrase for root.key: ← 输入前面创建的密码You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter ‘.’, the field will be left blank.—–Country Name (2 letter code) [AU]:CN ← 国家代号，中国输入CNState or Province Name (full name) [Some-State]:BeiJing ← 省的全名，拼音Locality Name (eg, city) []:BeiJing ← 市的全名，拼音Organization Name (eg, company) [Internet Widgits Pty Ltd]:MyCompany Corp. ← 公司英文名Organizational Unit Name (eg, section) []: ← 可以不输入Common Name (eg, YOUR name) []: ← 此时不输入Email Address []:admin@mycompany.com ← 电子邮箱，可随意填Please enter the following ‘extra’ attributesto be sent with your certificate requestA challenge password []: ← 可以不输入An optional company name []: ← 可以不输入 创建一个自当前日期起为期十年的根证书root.crt：openssl x509 -req -days 3650 -sha1 -extensions v3_ca -signkey root.key -in root.req -out root.crt输出内容为：[lenin@archer ~]$ openssl x509 -req -days 3650 -sha1 -extensions v3_ca -signkey root.key -in root.csr -out root.crtSignature oksubject=/C=CN/ST=BeiJing/L=BeiJing/O=MyCompany Corp./emailAddress=admin@mycompany.comGetting Private keyEnter pass phrase for root.key: ← 输入前面创建的密码 创建服务器证书密钥server.key：openssl genrsa –des3 -out server.key 2048输出内容为：[lenin@archer ~]$ openssl genrsa -out server.key 2048Generating RSA private key, 2048 bit long modulus….+++…………………………………………..+++e is 65537 (0×10001)运行时会提示输入密码,此密码用于加密key文件(参数des3便是指加密算法,当然也可以选用其他你认为安全的算法.),以后每当需读取此文件(通过openssl提供的命令或API)都需输入口令.如果觉得不方便,也可以去除这个口令,但一定要采取其他的保护措施!去除key文件口令的命令:openssl rsa -in server.key -out server.key5.创建服务器证书的申请文件server.csr：openssl req -new -key server.key -out server.csr输出内容为：[lenin@archer ~]$ openssl req -new -key server.key -out server.reqYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter ‘.’, the field will be left blank.—–Country Name (2 letter code) [AU]:CN ← 国家名称，中国输入CNState or Province Name (full name) [Some-State]:BeiJing ← 省名，拼音Locality Name (eg, city) []:BeiJing ← 市名，拼音Organization Name (eg, company) [Internet Widgits Pty Ltd]:MyCompany Corp. ← 公司英文名Organizational Unit Name (eg, section) []: ← 可以不输入Common Name (eg, YOUR name) []:www.mycompany.com ← 服务器主机名，若填写不正确，浏览器会报告证书无效，但并不影响使用Email Address []:admin@mycompany.com ← 电子邮箱，可随便填Please enter the following ‘extra’ attributesto be sent with your certificate requestA challenge password []: ← 可以不输入An optional company name []: ← 可以不输入 创建自当前日期起有效期为期两年的服务器证书server.crt：openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAserial root.srl -CAcreateserial -in server.csr -out server.crt输出内容为：[lenin@archer ~]$ openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAcreateserial -in server.csr -out server.crtSignature oksubject=/C=CN/ST=BeiJing/L=BeiJing/O=MyCompany Corp./CN=www.mycompany.com/emailAddress=admin@mycompany.comGetting CA Private KeyEnter pass phrase for root.key: ← 输入前面创建的密码 创建客户端证书密钥文件client.key：openssl genrsa -des3 -out client.key 2048输出内容为：[lenin@archer ~]$ openssl genrsa -des3 -out client.key 2048Generating RSA private key, 2048 bit long modulus……………………………………………………………………………..+++……………………………………………………………………………………………………….+++e is 65537 (0×10001)Enter pass phrase for client.key: ← 输入一个新密码Verifying – Enter pass phrase for client.key: ← 重新输入一遍密码 创建客户端证书的申请文件client.csr：openssl req -new -key client.key -out client.csr输出内容为：[lenin@archer ~]$ openssl req -new -key client.key -out client.csrEnter pass phrase for client.key: ← 输入上一步中创建的密码You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter ‘.’, the field will be left blank.—–Country Name (2 letter code) [AU]:CN ← 国家名称，中国输入CNState or Province Name (full name) [Some-State]:BeiJing ← 省名称，拼音Locality Name (eg, city) []:BeiJing ← 市名称，拼音Organization Name (eg, company) [Internet Widgits Pty Ltd]:MyCompany Corp. ← 公司英文名Organizational Unit Name (eg, section) []: ← 可以不填Common Name (eg, YOUR name) []:Lenin ← 自己的英文名，可以随便填Email Address []:admin@mycompany.com ← 电子邮箱，可以随便填Please enter the following ‘extra’ attributesto be sent with your certificate requestA challenge password []: ← 可以不填An optional company name []: ← 可以不填 创建一个自当前日期起有效期为两年的客户端证书client.crt：openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAserial root.srl -CAcreateserial -in client.csr -out client.crt输出内容为：[lenin@archer ~]$ openssl x509 -req -days 730 -sha1 -extensions v3_req -CA root.crt -CAkey root.key -CAcreateserial -in client.csr -out client.crtSignature oksubject=/C=CN/ST=BeiJing/L=BeiJing/O=MyCompany Corp./CN=www.mycompany.com/emailAddress=admin@mycompany.comGetting CA Private KeyEnter pass phrase for root.key: ← 输入上面创建的密码 将客户端证书文件client.crt和客户端证书密钥文件client.key合并成客户端证书安装包client.pfx：openssl pkcs12 -export -in client.crt -inkey client.key -out client.pfx输出内容为：[lenin@archer ~]$ openssl pkcs12 -export -in client.crt -inkey client.key -out client.pfxEnter pass phrase for client.key: ← 输入上面创建的密码Enter Export Password: ← 输入一个新的密码，用作客户端证书的保护密码，在客户端安装证书时需要输入此密码Verifying – Enter Export Password: ← 确认密码 保存生成的文件备用，其中server.crt和server.key是配置单向SSL时需要使用的证书文件，client.crt是配置双向SSL时需要使用的证书文件，client.pfx是配置双向SSL时需要客户端安装的证书文件 .crt文件和.key可以合到一个文件里面，把2个文件合成了一个.pem文件（直接拷贝过去就行了）参考：http://sinolog.it/?p=1460////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////http://blog.sina.com.cn/s/blog_4fd50c390101891c.htmlx509证书一般会用到三类文，key，csr，crt。Key是私用密钥openssl格，通常是rsa算法。Csr是证书请求文件，用于申请证书。在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥。crt是CA认证后的证书文，（windows下面的，其实是crt），签署人用自己的key给你签署的凭证。 1.key的生成opensslgenrsa -des3 -out server.key 2048这样是生成rsa私钥，des3算法，openssl格式，2048位强度。server.key是密钥文件名。为了生成这样的密钥，需要一个至少四位的密码。可以通过以下方法生成没有密码的key:opensslrsa -in server.key -out server.key server.key就是没有密码的版本了。 2.生成CA的crtopensslreq -new -x509 -key server.key -out ca.crt -days3650生成的ca.crt文件是用来签署下面的server.csr文件。 3.csr的生成方法opensslreq -new -key server.key -outserver.csr需要依次输入国家，地区，组织，email。最重要的是有一个common name，可以写你的名字或者域名。如果为了https申请，这个必须和域名吻合，否则会引发浏览器警报。生成的csr文件交给CA签名后形成服务端自己的证书。 4.crt生成方法CSR文件必须有CA的签名才可形成证书，可将此文件发送到verisign等地方由它验证，要交一大笔钱，何不自己做CA呢。opensslx509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key-CAcreateserial -out server.crt输入key的密钥后，完成证书生成。-CA选项指明用于被签名的csr证书，-CAkey选项指明用于签名的密钥，-CAserial指明序列号文件，而-CAcreateserial指明文件不存在时自动生成。最后生成了私用密钥：server.key和自己认证的SSL证书：server.crt证书合并：catserver.key server.crt &gt; server.pem","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"http","slug":"http","permalink":"http://www.liuzhidream.com/tags/http/"}]},{"title":"人生的意义","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/blog/rensheng-blog/","text":"胡适说，人生应该有梦，否则人生不是太不丰富吗？ 现在你们都有理想，但出了社会便可能不同了。那时各奔前程，各种打击，各种现实的考虑，都可能使得你把崇高的理想收敛起来。这就是现实在考验我们的道德力，我们的理想性，我们对真对善对美的追求是否迫切。在世界上每一个角落都是如此的。我们是否能撑得住，就在这个关头。现在是考验我们的时候了。 人生的意义今天是一九六六年四月八日，我今天要跟大家谈的问题是「人生的意义」。我为什么要选这个问题呢？这有两个理由： 第一个理由是我个人是非常喜欢思考的。从少年时代到青年时代，从青年时代到中年时代，都是不停的想问题，对人生的辛酸波折也经历过一些。因此把我所想的人生的意义是什么，人生的道路是什么陈示出来，给各位参考；我只说参考，但我没有说各位一定要采取我的人生观和人生的意义。人生的意义是各人自己的。我只是把我的提供各位参考而已。 第二个理由是：就我观察所及，我们正处在一个转型的社会，我们的文化在蜕变中，而且这个世界是这样的扰攘不安，差不多的人实实在在说来心灵都失落了：失落在街头，失落在弹子房，失落在电影院，失落在会客室里，种种的失落。他们的心灵是不凝炼，不坚强的。 比如说，有些体育家，运动家，他们的个子是蛮大的，打人蛮行的，但他的心灵很脆弱。譬如说，他们稍微把一句话说错了，就怕这个人不喜欢吧，怕那个人被得罪了。这充分表现出心灵的脆弱。 假如我们具有强健的身体而心灵如此脆弱，这是很可悲的，我们只有做别人的工具。这是时代的厄运。为了免于这一厄运，所以我愿意把我自己的想法提供出来。 这就是今天讨论这个问题的基础，并以此为范围。 人生是有很多层次的，此处我只能简略的说。 首先要说的是物理层。 任何人无法不受物理定律的支配。如果有人活得不耐烦的话，他从楼上跳下来，非伤即死，毫无问题的。那就是受物理定律的支配。人是有限的动物，虽然有时觉得自己是无限的，那大概是太狂妄了。这层是用不着多说了。 第二层是生物逻辑层。 人不仅是物而且是生物，是有生命的。有生命则不能不受生物法则的支配，如呼吸，心脏的搏动，肌肉的收缩都是受生理法则的支配，没有人能例外。我们就是这种构造的。可是，在这层有一种特别的现象，这在别的生物里是不发达的──即使不是没有的话。这就是一个生物文化的界域。 我们是一种生物，有许多是需要必须满足的，如吃饭喝水，到一定的岁数要结婚，所谓「窈窕淑女，君子好逑，求之不得，辗转反侧」，那么难过，这都属生物逻辑层。固然，别的生物也都要吃东西，寻配偶。但它们与人有大不同之处：它们是赤裸裸的，没有文化，人则不同，吃东西要讲礼貌，有不同的分殊，不同的形式。就穿衣而论，我不相信任何一位小姐，本来就像孔雀般美丽，而是藉各种物质的工具来补足其美。人为了御寒有棉、皮革、尼龙、奥龙、达克龙。这都是生物文化层的东西。我们满足人类之生物文化。但人类的生存并非发展到此结束的。 人是有「意识」的。这最关重要。别的生物大概没有，至少到现在为止大概尚末发展到这地步。这在生物发展的过程中是一个很重要的关键。别的生物大概不知道自身的生死间题，人则知道，晓得有生就有死。彭祖长寿，但到了八百岁时依然要死。而且人都怕死，但上帝绝不因此多留你一天，打针吃药于事无补。由于我们有死的意识，便产生许多神话，许多礼仪。 就这样，慢慢的发展，扩充我们的界域，由单纯的物理层，进为生物逻辑层，再由此发展到生物文化界，继续发展。 然后人类有真善美的意识，有理想、有道德，这也就是价值层。 这层就是人之所以为人的层级，生物逻辑层则是凡高等生物皆有。生物文化界别的高等动物虽可分享一部份，但人最多。唯最高层是人所独有。 我们讲道德，追求理想，要创造理想杜会，从柏拉图的理想国，托马斯穆尔的乌托邦，以至我们追求真善美等等，这都是超生物逻辑的东西，借用黑格尔的话说是「精神的创造」。我想大概说来只有人类有精神的创造。这层是人所特有的。当然，人只是太空中的一种生物而已，将来星际交通发达了，在别的星球中可能有超人类存在。超人类的智慧是可能比人类发达得多。 现在我已把我要讨论的基本架构说出。依此，我们讨论人生的意义何在，人生的道路何在。人活在这世界上，首先必须要能生存。可是不同的文化价值，对这种需要的满足方式是不同的。而且有的文化价值取向不把重点放在这上面。 例如古代圣贤说：君子谋道不谋食。当我少年时，同学间常以为问舍求田的人，是没有大志的。因为，当时大家只谈理想，只谈学问。万一有人谈钱，大家一定笑他的。这是当时一般知识分子的价值观念。这也表示文化价值的重点之所在。又如古时有人说「饿死事小，失节事大」；「饿死首阳之山，义不食周粟」。这是认为生物需要不及道德价值之重要。尤其宋明理学家就是如此的。他们的想法高得很，但也空得很的。他们从不屑谈这些经济事务。但是，我们现在重视这个了。 第二次世界大战以后，亚非地区的人众抬头了。十九世纪末叶以迄二次世界大战以前约八十年间非洲地区是白种人的殖民地，有色人种受白种人的轻视，尤其认为有色人种无论是体力、道德或天然的脑力都不如白人。可是，曾几何时，现在非洲人受白人之哄抬。这个变化真非始料所及！亚非地区的人特别多，经济落后，但是我并非认为经济落后是罪恶。 正好相反，不开发，不开马路，漫步森林之中，享受天然之乐，岂不更好？现在，亚非地区受重视，却经济落后、知识水平低、贫困、饥荒，野心份子可用他们来扰乱世界和平。于是乎，自由国家要开发落后地区了。现在世界，无论何地均拼命经济发展，刻意经营。这些努力无非在生物文化层。 我并不是说这一层是可以忽略的。在实际上，我们不可能不经此层而跳至最上层。因为，如果腾空而起的话，高等精神文化的发展和道德实践便失去支持。宋明理学的大病在此。他们的毛病在当时并不严重。因为吃饭问题不大，如朱熹、程颐、程颢等人在这方面都不成问题，顶多是有无肉吃的问题而已。因为他们有人供养，他们是士大夫阶层。据贵校金耀基先生说，我们已经不是士大夫了。我听后有股淡淡的哀愁！ 但是，落花流水春去也！又有什么办法呢？ 以前我是会做秋梦的，以为身为士大夫，四民之首，好神气﹗但现在不是了，一个月的收入不及华怡保的百分之一，因此你们可以说：殷海光，你的梦可以醒了！这样我们便要面对现实了。当时朱熹可不如此，好惬意哦！到山上开家书院，自任山长。But now all gone！现在时代不同了，生活的需要多了。 我们的传统文化价值取向把重点放在名教、仪制、伦序、德目的维系这一层次上，而不太注重生物文化层。于是精神文化和现实生活脱了节。到头来，我们的文化发展，像一座高楼似的，上一层的人在吹笙箫，底下一层劳动终日难得一饱，于是空了。整个文化建构都发生问题。这一历史的教训是值得今日的我们留意的。 我举一个现实的例子。经济落后的地区要人来协助。肚子被人抓住了还有什么自由哟！我们的肚子被人控制，很多志气便无法伸张，人的尊严便很难维持。有钱才能扬眉，才能吐气。否则高尚的志趣，卓越的理想，都要收起来。人到屋檐下不能不低头。所以我们必须充实生物文化层才能谈上一层的价值。现在发展外销，致力经济起飞，在这种意义下是对的。 然而，我们现在的问题是：人生的意义，人生的目的，人生的价值，人生的道路是否就停在这一层呢？你如何把你与其它高等动物分别开？丰衣足食后是否安心在此停顿？人之所以为人是否这就够了呢？ 这是要我们大学生，知识分子想的大问题。今天我们都受了时代沉闷空气的压力，担心出路，许多人不爱想这类问题，视之为高调。我个人的境遇困难，但从未停止想这类问题，尤其在困难的时候更要想！前面所说的生物逻辑的条件没有满足时，固然到不了最上层。但满足之后，高尚的理想和价值都可不要吗？希腊出那么多大哲学家、科学家、思想家，为后世之基础，我们多么向往啊！因为他们的精神生活是如此丰富。显然得很，要人生完美，必须透过生物文化层再往上升。生物文化层满足了，我们还要真善美、理想、道德，这样人生的道路才算完成。 这里又生一个问题：假设我们已有很好的文化遗产，如中国的。就中国来说，我认为孟轲有气象，他可说是一个标准的道德英雄；又如韩非子，思想那么严格，观察那么锐利。如果他生在现代的话，就可能是一个逻辑家了。 我们现在进一步提出一个问题：如果我们面临一个两难式，即是：如果我们要满足衣食等生物逻辑，那么势必牺牲道德或理想；如果我们要维持道德或理想，那末势必困难以满足衣食等生物逻辑的要求而难以生存。处此困境之下，我们怎样作决定？ 照现在的趋势，一般人在有意无意之间，碰到求生与顾及道德不能两全的情形，就为了求生而牺牲道德原则。有些人更因满足自己的利益而牺牲道德，陷害别人。所以，道德就「江河日下」了。人吃粗一点尚可活下去。人群没有道德来维系，势必难免为「率兽食人」的世界。如何得了！在这样的情形之下，我们怎样处理？我以为孟夫子所倡导的「义」是救药。他要人舍生而取义。这当然是一个极限原则。我们并不是说人必须动不动就牺牲生命来保全道德原则和崇高理想。 我的意思是说： 第一，我们万不可在自己的生存并末受威胁时为了换取现实利益而牺牲道德原则。 第二，在我们的生活勉强可过时万不可因要得到较佳报酬而牺牲他人。 第三，当我们因生活困难而被迫不得不放弃若干作人的原则时，我们必须尽可能作「道德的抗战」，把道德的领土放弃的愈少愈好；而且要存心待机「收复道德的失地」。 复次，我们有我们的好恶。 如果经济贫困了，我们的好恶是否就要放弃？是否就不能讲？ 还有尊严问题，如人的经济不能满足，尊严是否可以不顾呢？诸如此类的问题，作为一个人，真值得想一想。 在各位现在这种年龄大家都有梦。胡适说，人生应该有梦，否则人生不是太不丰富吗？ 现在你们都有理想，但出了社会便可能不同了。那时各奔前程，各种打击，各种现实的考虑，都可能使得你把崇高的理想收敛起来。这就是现实在考验我们的道德力，我们的理想性，我们对真对善对美的追求是否迫切。在世界上每一个角落都是如此的。我们是否能撑得住，就在这个关头。现在是考验我们的时候了。","tags":[{"name":"causerie","slug":"causerie","permalink":"http://www.liuzhidream.com/tags/causerie/"}]},{"title":"为什么那么多成功的人，他们每天只睡几个小时？","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/blog/sleep-blog/","text":"这是个值得思考的问题 为什么那么多成功的人，他们每天只睡几个小时？这个世界就是一波人昼夜不停地运转,另一波人醒来后发现世界变了！ 美剧都是骗人的，现实真的很累 一直有一个很大的困惑，为什么很多有名的成功人士可以睡得那么少？ 第一次意识到这个问题，是刚到美国读书的时候。 相信在美国上过学的人都有体会，学习强度非常大。 每天早上8点起床去上课，晚上在图书馆待到1点，周末也基本都安排得满满的。不是因为故意用功，而是功课实在太多，让你完全没有任何喘息的时间。 拿其中一门主课来说，一周上三次课，一次三小时，每次课后教授都会在学校内网上传当天的阅读材料，都是她从各种数据库里找的论文文献和在图书馆里扫描的书籍，通常是PDF文档，可以下载后到图书馆免费打印。 每次要打印上百张A4纸（正反两面打印），偶尔打印完一看，今天的材料竟然只有六七十张，就会觉得心情一下子轻松了不少。 不要忘了这不是看休闲杂志，里面的内容都是枯燥艰深的学术论文，而且通常排版得密密麻麻并且极少插图。 你以为光看这些材料就完了吗？并没有。 在还没有开学前，教授已经发邮件给每一个学生，列出了整个学期的阅读书目，一共有30多本，都是学术书籍，要求学生自己到书店里去买，每周课上会讨论其中的一两本书。 至于统一的教材，反而是没有的。此外，每周还要写两篇文章，还得抽时间准备毕业前要交的论文。 不要忘了，这还只是其中的一门课，其他每一门课的教授都会这样像地主恶霸一样地把你榨成渣渣。 读完一年的硕士课程，每一个人都像经历了一场生死炼狱，毕业时仿佛有重生之感。 那个时候最好的纪念，就是去学院里的纪念品商店买一件上面印着“I survived J School”的T恤衫（J School是学院的简称），意思是“我读完J School竟然活了下来”。 这么高强度的工作量，正常的作息时间是绝对不可能完成的。 所以几乎每天大部分人都只能蓬头垢面地在学校和住处之间两点一线地疲于奔命。 之前设想的要多去旁听其他系有意思的课、多认识人、多参加社会活动等等美好憧憬，全部都被残酷的现实击打得粉碎。 即使现在已经几年过去了，重新回想起来仍然觉得心有余悸。 尽管当时居住的地方右转300米就是著名的中央公园，但是整整三个月愣是没有时间去瞅一眼。 总有那么几个学霸天生不用睡觉 当时班里一共9个学生，除了两人以外，其他都是美国人。大多数人也都是疲于奔命，眼睛带着血丝。但是，有一个本科在哈佛读的美国同学，却每天都一副容光焕发精力充沛的样子。 曾经以为他是偷懒没看阅读材料，所以有足够的休息时间，可后来发现并非如此，他不但把大部分功课都完成了，而且还有时间去听个讲座、参加个派对什么的。 他说，他固定在凌晨3点半睡觉，早上7点半起床。这让人很震惊，问他睡这么少为什么还能保持这么旺盛的精力？一般人每天睡6个多小时，就已经觉得到了自己的极限了。 他笑笑说，他一直都是这样，每天睡4个小时就差不多够了。他还说，在美国就是这样，工作、社交、睡觉，每个人都只能保证两样，他不想耽误学习也不想没有社交，就只能牺牲睡眠了。 其实不仅仅是在顶尖的学校，美国社会里顶尖的那一批人，几乎都是处于这样一种疯狂高速运转的状态。为了保证工作学习和社交娱乐，他们不约而同地牺牲了自己的睡眠，每天只睡四五个小时是很常见的。 比如学院里的教授，也是如此。除了教书以外，她还是好几家媒体的专栏作者，每周都要写很多文章；还经常参加各种研讨会和研究计划；在这样的情况下，她还有时间每年写一本书。 相比学生，她的工作量只多不少。不知道她每天睡几个小时，只知道每天收到的最后一封电子邮件必定是她发的，每天早上收到的第一封邮件也是她发的。 有时候学生们晚上1点写完作业用电子邮件给她发过去，第二天一大早必然会收到她回复的修改意见，而且看邮件发送时间常常是凌晨三、四点。可是每天早上9点开始的课，她从来没有迟到过一次。 再比如工作以后遇到过的几位上司，几乎都是每天半夜两三点给大家发工作邮件，第二天一大早8点不到进办公室，而且天天如此。 媒体也时不时地会写关于睡眠时间的文章，列出那些成功人士只睡三四个小时的例子——奥巴马每天只睡6个小时，雅虎的美女 CEO 玛丽莎·梅耶尔每天只睡4个小时，还有特朗普据说也只睡4个小时…… 为什么他们不睡觉还有精力拼搏 在北美一个华人论坛上出现过这么一个话题： 为什么跨国公司的CEO们每天只睡四五个小时，却能有效地管理几百亿市值的公司？ 当然，这个问题并没有一个明确的答案。有科学家做过研究说，有些人可以每天只睡四五个小时还精力充沛，除了他们自己很拼很努力，更主要的原因是他们体内有一种异于常人的基因。 他们还把这种基因命名为“撒切尔基因”，因为据说撒切尔夫人就是一个非常著名的“少睡者”的典型。 所以，最大的解释就是，这就是天分吧。 对于那些没有少睡基因、“输在起跑线上”的人来说，办法大概是： 一，尽可能地保证睡眠的质量； 二，提高睡眠的效率，有些事情睡觉时能办的就在睡觉时办。 三，多运动，这是补充精力的有效方法。 前方高能，再来看看这22位CEO的作息： 1、美国在线公司（AOL）首席执行官Tim Armstrong 这位前谷歌执行官并不是一位“爱好睡觉”的人，他每天都在清晨5点或5：15醒来。之后要么工作，要么阅读，或者看看自家公司的产品，回复电子邮件。 为了保证更多的思考时间，Tim Armstrong通常不会自己开车，而是请专职司机。 2、苹果公司首席执行官Tim Cook 这位科技巨擘在业界正是以早起出名，苹果的员工会在清晨、或者说接近黎明时分的4：30就收到Tim Cook的电子邮件，且每日如此，他们已经习以为常。 当然，Tim Cook会在5点钟的时候准时出现在健身房。 3、通用电气（GE）首席执行官Jeff Immelt 通用电气（GE）首席执行官Jeff Immelt每一天的5：30都会起床做有氧运动。 期间，他还会读报纸，看CNBC。 他曾经提起，自己已经连续24年每周工作100个小时了。 这就是说，按照7天的时间计算，他每天的工作时长为14个小时以上…… 4、通用汽车公司（General Motors）首席执行官Mary Barra 早起大概成了通用公司的传统，现任CEO Mary Barra就像其前任Daniel Akerson一样，日日早起。 她每天准时准点地在清晨6点出现在办公室。 在这一点上，她比前任做的还要出色。 5、富士施乐（Xerox）首席执行官Ursula Burns 回复电邮是Ursula Burns每日清晨的习惯，为此，她会在5：15起床。 不过，尽管经常会工作到深夜，但Ursula Burns会保证自己每周两次的个人健康训练，这个时间定在6：00，每次一个小时。 6、菲亚特（Fiat）和克莱斯勒（Chrysler）首席执行官Sergio Marchionne 这位具有加拿大和意大利双重国籍的商人起床的时候，恐怕大部分人都还在梦乡中——3：30。 公司有位高管曾表示：“Sergio创造出了（一周里的）第八天，我们来实现它。” 还有一位高管曾在60 Minutes节目中这样说：“当意大利放假的时候，他回美国工作；当美国放假的时候，他再回意大利工作。” 7、太平洋投资管理公司（PIMCO）创始人Bill Gross Bill Gross的早起如同他那糟糕的君王脾气，以及职业二十一点玩家的身份一样出名。 他会在4：30就起床，查看全球市场行情和消息，并在6点钟准时坐在办公桌前。 8、Twitter创始人、移动支付公司Square首席执行官Jack Dorsey Jack Dorsey曾对媒体透露，他一般会在5：30起床，然后就开始做早课——冥想，以及一个小时的慢跑。 这样的生活方式他持续了很久，尤其是同时在Twitter和Square之间来回奔波工作的时候。 9、维珍集团（Virgin Group）创始人及董事局主席Richard Branson Richard Branson自曝起床时间是5：45，甚至在他的私人岛屿上度假时也是如此。他会拉开窗帘睡觉，这样，第二天的阳光就会叫醒自己。 10、百事集团（PepsiCo）首席执行官Indra Nooyi 这位这位印度裔女执行官最早的起床时间是清晨4点。 她曾称：“人们说，睡眠是上帝赐予的礼物……这份礼物我从未得到过。”她透露自己每天到公司的时间不会晚于7点。 11、维珍美国首席执行官David Cush 他曾向媒体表示，自己每天会在4：15起床，然后发邮件、致电东海岸的商业伙伴。 不过，每天清晨的达拉斯体育广播是他不会错过的节目，当然，还包括读报纸和健身。 12、迪斯尼集团首席执行官Bob Iger Bob Iger曾对纽约时报表示，他一般在4：30起床，利用上班前这段安静的时光读报纸、看电视。这段时间无人打扰，他能同时处理多项事情。 13、Hain Celestial Group首席执行官Irwin Simon 他是美国天然日用品制造商Hain Celestial集团CEO，他每天5点钟起床，之后的习惯就像上述几个CEO们一样，回复邮件、与欧洲和亚洲的商业伙伴通话。 不同的是，他还会在孩子们起来之前祈祷、遛狗、做运动。 而且，他还能在进入长岛办公室之前在曼哈顿开个早餐会。 14、前百事可乐CEO Steve Reinemund 现任Wake Forest大学商学院院长，他告诉媒体，他在5:30起床，再读报纸。他会在工作前浏览纽约时报、华尔街日报、金融时报、达拉斯晨报。 15、星巴克CEO Howard Schultz Howard Schultz以晨练开始新的一天，一般是与妻子一同骑车。即便如此，他也会保证自己在6点之前赶到办公室。 16、Aurora Fashions首席执行官Mike Shearwood 作为一家英国时尚领域的先锋公司，Aurora Fashions首席执行官Mike Shearwood忙碌的一天开始于清晨5点。 他从诺丁汉赶到伦敦差不多是7：45了。他对这种长距离的上下班路途乐此不疲：“我会赶复邮件、赶工作，还能与团队通电话。” 17、布鲁克林篮网队首席执行官Brett Yormark 布鲁克林篮网队（Brooklyn Nets）在更名前为新泽西篮网队。Brett Yormark是全美NBA界最年轻的CEO。 他的起床时间也许会让很多人汗颜——3点半，而且他在4：30就会出现在办公室了，然后开始一天的工作，发邮件什么的。 不过，他并非铁人，周末是他放松自己的时间——7点钟才到办公室工作。 18、前氧气媒体公司 （Oxygen Channel）首席执行官Gerry Laybourne 作为二十世纪80年代有线电视界先锋人物，Gerry Laybourne总是在6点起床，半小时以后离家赶赴公司。 如果你起得够早，她可能还会带上你。 她曾对雅虎财经说：“每周一到两次，我都会在中央公园步行，并与一名寻求我的建议的年轻人同行。这是我帮助下一代人的方式。如果有人早起，我认为，他对待生活是认真的。我无法在公司做这些事，但早起让我有空健身，同时，还能和年轻人保持沟通交流。 19、私募股权投资公司Saban Capital首席执行官Haim Saban 这位埃及出生的以色列-美国籍亿万富豪也很勤奋，6：02，他就开始享用清晨咖啡了。他会在75分钟的晨练前先工作一小时。 20、Brooklyn Industries首席执行官Lexy Funk 这位时尚企业联合创始人之一曾对赫芬顿邮报如此形容她的一天：她一般在4点醒来。然后开始纠结，到底是倒头再睡，还是拿起黑莓工作呢？不过，绝大多数情况下，她在忙于回复邮件的同时，会抽空打几个和生意有关的电话。 21、喜达屋酒店（Starwood Hotels）首席执行官Frits Van Paasschen 他在5：50就开始跑步了，你可以想象他的起床时间。6：30，他会准时出现在办公桌前。 22、Cisco 首席执行官Padmasree Warrior 这位印度裔女强人4：30就起来了，发邮件、读新闻、晨练，一样不少。最晚在8：30，她就会进入公司工作了。 也正因其勤奋而卓有成效的工作，Padmasree Warrior早在作为摩托罗拉首席技术官的时候就备受赞誉了。 时间赋予每个人都是24小时，只是有些人把时间用到了极致。 这个世界最可怕事，比你牛逼的人，竟然比你还努力。 有一波人昼夜不停地运转,另一波人醒来后发现世界变了","tags":[{"name":"causerie","slug":"causerie","permalink":"http://www.liuzhidream.com/tags/causerie/"}]},{"title":"Docker","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Docker/Docker/","text":"docker 容器技术学习笔记 Docker 笔记 image 命令docker ps 列出容器列表 docker container ls 管理容器 两个命令都是查看正在运行的容器，加 -a 参数可以查看更多的信息 docker run docker container run 都是运行容器(但是本质还是不同的，可以深入研究下) Ctrl+P+Q 退出容器不关闭 docker start goofy_almeida 启动容器在后台运行 docker attach goofy_almeida 后台容器进入终端 docker network create &lt;name&gt; docker network inspect &lt;name&gt; docker stats 容器ID 查看容器状态 docker logs 把容器运行后产生的输入都打印出来，不要轻易尝试 多个终端访问容器有时候需要开启多个终端来访问容器，通过容器ID，执行命令 docker exec -it 40c330755e61 /bin/bash 就可以了，这个终端的退出不会影响到已经开启的终端 创建容器的参数 -d：后台运行容器，并返回容器ID -i：以交互模式运行容器，通常与 -t 同时使用 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 容器连接容器连接就是把容器接到一起，让它们可以相互通信，如果你使用一个容器运行一个软件的方式，容器连接就是很有必要的，比如你的服务和数据库进行通信，那么你的容器就要连接在一起。使用到的命令有 --link ，不过新的特性推荐使用 network ，network把容器都加到一个网络中，实现之间的互相通信。 相关命令 创建网络，my_network 是网络的名称。创建完网络，把容器加入到网络就行了。1docker network create my_network tip 加入网络示例： docker run -it --name=web_django --network web_network --network-alias django -v /root/py_web_vadmin/:/root/web_work -p 8080:8080 debian:v2 bash docker run -it --name=web_nginx --network web_network --network-alias nginx -v /root/py_web_vadmin/:/root/web_work -p 80:80 nginx bash 把debian和nginx加入到一个已创建的网络中。 查看网络1docker network ls 查看已创建的网络，默认有服务自己创建的网络 效果如下：1234NETWORK ID NAME DRIVER SCOPE9872c9881f6e bridge bridge local6fc119c0ceda host host localc3fdf8d5c56e none null local bridge：默认网络，所有容器默认连接到它 none：没有网络接口 host：连接到主机的网络栈，主机和容器间的网络没有隔离 数据卷数据卷用来做数据持久化，如果你的数据在容器中，比如数据库文件，日志文件等，这些文件是会不断生成的，当你关闭容器，再次启动容器，数据倒是不会丢失，如果你从镜像启动新的容器，数据就没了（出现这种情况是因为：通常使用run命令来启动容器，如果没有定义name，那么每次使用run命令都会从镜像创建新的容器，这样上次容器的操作都没了，应该养成定义容器name的习惯，创建同名的容器是不允许的）。数据要想保持，除非你不断的提交镜像，当然这种做法是不可取的，所以要用到数据卷技术。数据可以让容器和宿主主机共享一个目录，通常把程序，数据库文件等放在宿主机上，通过创建数据卷，让容器可以操作到宿主机文件，并把新的数据写到此。 1docker container run -v /root/data:/root/PythonProjects/GitTest -it -p 8080:8080 debian:v2 bash 上面命令的含意是：本机目录/root/data映射到容器目录/root/PythonProjects/GitTest（在启动容器的时候就得使用-v 命令，容器和主机共用一个目录，关闭容器，在启动容器也得带-v命令）一般会把程序放在宿主机上，更新修改都在这，不过修改了代码后，记得进入容器中去重启项目。 文件操作12从主机复制到容器 sudo docker cp host_path containerID:container_path从容器复制到主机 sudo docker cp containerID:container_path host_path 操作流程：先把容器运行起来，宿主主机执行 docker container 查询正在运行的container 的containerID 然后去执行上面的命令 保存容器修改： pull 了一个新的image后，或操作已有的容器，并对容器做了修改，退出容器后 执行 docker ps -l 得到 容器的ID 执行 docker commit 容器ID 镜像名称 该操作将覆盖现有进行为修改后的容器 docker commit 容器ID 镜像名称:v2 保存修改为tag为v2的镜像 容器容器(container)是docker一个很重要的概念，通过镜像我们就可以创建容器。这里记录一些相关命令。 123456789101112131415161718192021222324252627282930查看docker container ls 等同于 docker ps -a 查看更多的信息删除docker rm container iddocker rmi image id杀死所有正在运行的容器docker kill $(docker ps -a -q)删除所有已经停止的容器(容器不再使用了，可以使用此命令把它们都清空了)docker rm $(docker ps -a -q)删除所有未打 dangling 标签的镜像docker rmi $(docker images -q -f dangling=true)删除所有镜像docker rmi $(docker images -q)强制删除镜像名称中包含“doss-api”的镜像docker rmi --force $(docker images | grep doss-api | awk '&#123;print $3&#125;')删除所有未使用数据docker system prune只删除未使用的volumesdocker volume prunedocker start goofy_almeida 启动容器在后台运行docker attach goofy_almeida 后台容器进入终端 docker ps –选项 Name, shorthand Default Description –all , -a Show all containers (default shows just running) –filter , -f Filter output based on conditions provided –format Pretty-print containers using a Go template –last , -n -1 Show n last created containers (includes all states) –latest , -l Show the latest created container (includes all states) –no-trunc Don’t truncate output –quiet , -q Only display numeric IDs –size , -s Display total file sizes 使用 docker attach 命令进入container（容器）有一个缺点，那就是每次从container中退出到前台时，container也跟着退出了。要想退出container时，让container仍然在后台运行着，可以使用 docker exec -it 命令。每次使用这个命令进入container，当退出container后，container仍然在后台运行，命令使用方法：12345docker exec -it goofy_almeida /bin/bashgoofy_almeida：要启动的container的名称/bin/bash：在container中启动一个bash shell 这样输入“exit”或者按键“Ctrl + C”退出container时，这个container仍然在后台运行。 关于容器的运行，我本人的做法会使用 screen (linux的一个软件)，一般没有做后台运行。 container总结run 命令后从镜像创建container(容器)，此时的容器是新的，如果修改了内容，用exit退出，这个容器被关闭了（进入了Exited状态），如果想留着修改，最好是Ctrl+P+Q 退出容器不关闭 这样docker ps 可以查看容器还在，这样就可以通过start 容器name再次进入容器了。（这里我感觉容器的状态是有用的，具体就要看文档了，因为run新容器后，通过exit命令退出了，再次run，此时ps命令应该是创建了一次，然后关闭，又创建了一次，出现过两个name, 但是第二次run的容器是新的，上次修改的拿不到。 但是修改后，exit退出，通过docker ps -l，可以看到容器id, 这里可以进行提交。所以像保持容器的修改，最好用上面的流程，等理清楚了生命周期，就比较清楚整个流程了）经测试，docker ps -l列不出的容器，通过docker ps -a找到，即使状态不是update也可以去commit。 One of created, restarting, running, removing, paused, exited, or dead 容器导入导出docker save imageID &gt; filename.tar docker load &lt; filename.tar docker export imageID &gt; filename.tar docker import &lt; filename.tar 镜像和容器导出和导入的区别 镜像导入和容器导入的区别： 容器导入 是将当前容器 变成一个新的镜像 镜像导入 是复制的过程 save 和 export区别： save 保存镜像所有的信息-包含历史 export 只导出当前的信息 Dockerfile 使用除了通过拉取官方镜像的方式外，使用Dockerfile可以定制镜像，使其更加灵活。整个Dockerfile文件就是执行的脚本，由特定的命令组成，一个redis镜像Dockerfile文件大概是这样的。 123456789101112131415FROM centos:latestRUN yum -y update; yum clean allRUN yum -y install epel-release; yum clean allRUN yum -y install redis; yum clean all# 设置挂载点VOLUME [\"/data/redis\"]# Define working directory.WORKDIR /dataEXPOSE 6379CMD [\"redis-server\"] 上述Dockerfile文件是基于基础镜像CentOS来制作Redis。 docker build -t centos:v2 . 在文件所在目录下执行构建命令 指令Dockerfile指令就是上述文件中开头的FROM，RUN等。Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像。 FROM scratch 如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 12345678910ADDCOPYENVEXPOSEFROMLABELSTOPSIGNALUSERVOLUMEWORKDIR docker-compose这个工具是用来做容器编排的，简单来说就是可以一次启动多个容器，包括了设置端口映射，数据卷，容器连接等。在使用docker部署项目时，还是应该一个软件对应一个容器，而不是基于一个容器安装多个软件（这样就搞成一个虚拟机了），你要依次启动4，5个容器，设置端口映射，容器连接等会很麻烦，使用docker-compose只需要编写一个 docker-compose.yaml 文件就可以了。 使用了docker-compose，最好再配合一下Dockerfile，这样很快速就可以搭建一个环境。 以Python语言为例，流程应该是编写Dockerfile，在Dockerfile中基于一个基本容器（ubuntu，或者是Python3等容器），设置一些参数，然后安装依赖 RUN pip install -r requirements.txt，这样语言环境就有了，下面就是各个服务，比如MySQL，Redis等，这些不是太复杂的情况，直接在Dockerfile中指定image就行了。 总结： Dockerfile 定义应用的运行环境 docker-compose.yml 定义组成应用的各服务 docker-compose up 启动整个应用 编写yaml文件这个编写很简单，就是把各个容器怎么运行，参数配置组织在一起 来看一个简单的官方例子： 123456789101112131415version: '3'services: web: build: . ports: - \"5000:5000\" volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redisvolumes: logvolume01: &#123;&#125; 官方文档总结： 一份标准配置文件应该包含 version、services、networks 三大部分，其中最关键的就是 services 和 networks 两个部分，官方这里的例子使用links，而没有使用新的networks特性。configs配置在3.3及以上版本使用，用于配置文件的访问权限。 version：用来指定版本，依照官方的例子，现在可以使用3版本了，不同版本对一些配置的支持不同，比如配置参数从字符串到对象的变化，这里不再深入了 services：就是需要运行的容器，容器通过build或image指定，build就是使用Dockerfile文件，image就是使用镜像，本地有的使用本地的，否则下载仓库的。build后面还可以加参数，例如context，args，用来设置上下文，参数等，这属于Dockerfile相关的内容，一般情况，直接在build指定当前目录就行了。ports指定端口映射，volums指定数据卷（使用数据卷，修改代码不用重启容器），在这个官方例子中，在最外层也就是顶级定义了volumes，这是为服务定义的，使用一个单机开发环境在services中定义就行了。标签有两种情况，在服务上（部署集群的时候）deploy: labels: ’标签内容‘，在容器上只需要用labels。看到deploy，它下面的配置都是和部署有关的。depends_on依赖关系，依赖的容器会先启动。command命令，类似python3 manage.py runserver 0.0.0.0:8000。pid: “host” 将PID模式设置为主机PID模式，跟主机系统共享进程命名空间。容器使用这个标签将能够访问和操纵其他容器和宿主机的名称空间。extra_hosts 添加主机名的标签，就是往/etc/hosts文件中添加一些记录，与Docker client的–add-host类似。 命令 Command Description build 构建或重建服务，这会把Dockerfile再执行一次 help 命令帮助 kill 杀掉容器 logs 显示容器的输出内容 port 打印绑定的开放端口 ps 显示容器 pull 拉取服务镜像 restart 重启服务 rm 删除停止的容器 run 运行一个一次性命令，run web bash exec Execute a command in a running container，感觉run差不多 scale 设置服务的容器数目 start 开启服务 stop 停止服务 up 创建并启动容器 version 查看版本，如果你是2版本的，就不要在yaml里面使用3版本的写法了 使用总结： 个人心得，大致浏览了一下官方文档，docker-compose最大的用处应该是集群，它提供了很多功能，不过对于单机来说仍然有它的价值，省去了很多命令，同样作为单机来用，不需要学的很深入，很多配置都是用不到的 启动容器：使用up命令来启动容器，同时也会把build配置生成镜像，在我使用的版本中，给出了警告，对于需要使用Dockerfile构建的镜像，警告说应该先使用 docker-compose up --build，不过这对容器的启动到是没什么影响（不知道这里官方想表达什么）。build命令只会构建镜像，并不会去启动容器，up命令启动容器后，会把容器的输出打印到终端，要想在后台运行，应该 up -d name：使用image的，镜像名称就是指定的，使用build，镜像名称为当前目录加上在services中的配置，在容器中的name也是当前目录加上在services中的配置。使用docker-compose需要在yaml文件目录执行，这样在services中的配置，比如一个叫做web的配置，第一次使用镜像（或用build构建）是Python，生成的容器也是 当前目录_web_1，修改了web配置，image变成Redis，那么上次创建的容器会被删除，创建新的容器，容器的名称是一样的，因为修改的是image，而不是web。使用container_name可以自定义容器name，不过通过ps命令可以看到系统的缺省名称是web_1，如果自定义了，那么在集群上因为名称相同导致错误 exited with code 0：我用自定义的dockerfile启动容器，结果返回这么一个信息容器就停止了，我分析了官方例子做了一些测试后发现，如果你的容器启动后，什么都不做，那就会退出了，一些情况也是会退出的，比如你用 command echo $HOME 终端会打印这个信息，然后退出容器，我写了一个Python循环，用logging打印信息，终端一直在打印信息，没有退出。也就是说启动容器不能什么也不做 使用command，推荐绝对路径 :sunny:docker-compose应该这么来理解，它把多个容器组织在一起，并默认加到一个网络中（如果你没有定义网络或把容器分到不同的网络），通过run命令可以向整个环境发送命令(docker-compose run dev /bin/zsh 进入交互环境)，同时也可以使用docker的命令。体现了一个整体的概念。","tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuzhidream.com/tags/linux/"},{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"docker","slug":"docker","permalink":"http://www.liuzhidream.com/tags/docker/"}]},{"title":"Collect","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Collect/collect/","text":"常用内容收集整理，内容来自网络与个人整理 收藏内容内容来自某位大佬，网络收集与个人整理 注册码IntelliJ IDEA 后端申请Let’s Encrypt永久免费SSL证书(来自简书)Netlify 是一个提供网络托管的综合平台 前端consola 优雅命令行 console vuepress 也使用了 webpackbar webpack 打包进度可视化 jarvis webpack dashboard popmotion 一个函数式声明前端动画库 merge-images 图片合成 direction-reveal 一个根据鼠标进入方向展现 hover 描述的库 micron 通过动画属性绑定动画效果的库 sweetalert2 一个自适应优美自定义性强的弹出框 phaser 这是一个为桌面和移动浏览器开发 HTML5 游戏的快速开源框架。你可以为 iOS、 Android 和不同的本地应用程序创建游戏。 vue-sauce 一个可以展示 vue 源码的指令 tippy.js tooltip/popover library vue-smooth-dnd Vue wrappers components for smooth-dnd text-mask 一个可以让 input 按照规则输入(如电话,email,日期等) codesandbox-client 在线 web 开发容器 astexplorer 一个在线 ast 生成器 dinero.js 一个钱计算的库 crate 一个 react 全栈练习(pc,mobile,rn,api)demo Jasonette一个用 json 来构建 hybrid 的框架 vuegg 一个 vue 可视化拖拽界面生成器 refined-github 优化 github 默认功能的 chrome 插件 lerna 大项目版本控制工具，项目中可以有多个 package.json 文件 git-labelmaker 命令行快速创建 github react-in-patterns 一本开源叫你写 react 的书 picojs js 人脸识别库 img-2 一个提高图片加载性能和体验的库，懒加载使用 web worker 模糊预览 fingerprintjs 是一个快速的浏览器指纹库 ajv 一个 json schema 验证的库 dayjs 一个轻量级类 moment.js API 时间库 live-server 一个建议快速 dev 开发自动刷新的 http server serve快速起本地静态服务 primjs 代码高亮 ReLaXed 一个将 document html 转成 PDF 的工具 fabric.js 基于 canvas 创建交互式的图片编辑界面非常适合用来做图片合成类工作。 tabler 高颜值 ui 模板 matter-js web 物理引擎 rough 基于 Canvas 的手绘风格图形库 wired-elements 基于 rough.js 分装 button input raido 等组件 真正特别之处在于它的底层是 Web components uppy 一个很好看的也很好用的 前端上传库 tui-calendar 功能全面的日程安排日历控件，还支持拖拽。 tabler 基于 Bootstrap 4 的 Dashboard UI Kit 和美观 vee-validate 基于 vue 的验证，能验证的内容比较全 x-chart 我就是觉得颜色挺好看的 vuesax 一个很漂亮的基于 vue 的 ui 框架 vue-virtual-scroller 基于 vue 的虚拟列表无限滚动 particles.js 一个前端画颗粒 粒子的库 pulltorefresh.js 下个下拉刷新插件 lulu 腾讯阅文基于 jQuery，针对 PC 网站 IE8+（peak 主题）的前端 UI 框架 chancejs 生成随机数据的库 spritejs 360 奇舞团出的跨平台绘图对象模型 workbox 让你的网站更方便的变成 pwa tui.image-editor 一个功能齐全的在线图片编辑，基于 canvas hocs react 相关 hoc 收集库 nanoid 前端轻量 unique string ID 生成库 rxdb 一款开源的快速、灵活的客户端数据库，支持各种浏览器以及 NodeJS，Electron、React 等等，是 PouthDB 之上的一个封装库 vue-analytics 基于 vue 的 谷歌统计封装 percollate 命令行工具 能将网页转换成 pdf Nodechokidar node 监听文件变化的库 fs-extra fs-extra 模块是系统 fs 模块的扩展，提供了更多便利的 API，并继承了 fs 模块的 API globby 用于模式匹配目录文件 node-semver node 版本验证库 npm-run-all 一个 CLI 工具可以并行或者串行执行 script live-server 一个简单的 http server 带有 reload 功能 node-portfinder 一个端口嗅探工具 update-notifier Update notifications for your CLI app y18n yargs 基于 i18n 的一个包 signale Hackable console logger execa A better child_process listr Terminal task commander.js 自动的解析命令和参数，合并多选项，处理短参，等等，功能强大，上手简单 Inquirer.js A collection of common interactive command line user interfaces. 命令行询问库 ora Elegant terminal spinner 命令行 loaidng chalk 命令行着色美化库 hygen 快速方便的创建代码 可以命令行创建预设的 template ndb node 调试 got http 请求库 如果你觉得 request 太多的话 这是一个不错的选择 dumper.js 能让你的 node console 更加的规整，方便调试 node-in-debugging node.js 调试指南 nodebestpractices node 最佳实践 fastscan node 敏感词库 GraphQLprisma 让前端也能快速的写出 Apollo GraphQL 是基于 GraphQL 的全栈解决方案集合。从后端到前端提供了对应的 lib 使得开发使用 GraphQL 更加的方便 有趣1the-bread-code 使用程序员的思维制作面包 ，比如制作中使用 A/B test,来比较那种做法更好。 build-your-own-x 教你用各种语言实现 Bot Database Neural Network javascript-algorithms 教你用前端知识认识各种算法 工具high-speed-downloader 百度网盘不限速下载 支持 Windows 和 Mac hyper 前端命令行 yapi 是一个可本地部署的、打通前后端及 QA 的、可视化的接口管理平台 sway 一个微软自己出的在线 ppt 很强大 bigjpg 放大图片的神器 通过神经网络可以放大图片并能降噪 Ascii Art Generator 在线生成 Ascii 图案 Winds 开源 RSS JSUI 一个用来控制管理前端项目的客户端 docz 让你能快速写文档的一个库 hiper 性能统计分析工具 verdaccio 私有 npm git-guide git 入门指南 git-tips git 进阶 bit 实现了项目之间的代码共享 可以自建私有 simpread 简悦 ( SimpRead ) - 让你瞬间进入沉浸式阅读的扩展 mkcert 一键命令 让本地也支持 https termtosvg 录制 命令操作转成 svg 基于 python gh-polls 可以在 github issue 中添加投票 eruda 移动端调试工具 vConsole 也是一个移动端调试工具 腾讯出品 terminalizer 命令行录制工具 基于 node badgen 快速构建和 shields 一样的 svg badge 但速度更快 readability 移除页面非正文部分 基于 jsdom WeChatPlugin-MacOS 一款功能强大的 macOS 版微信小助手 puppeteer-recorder 一个 chrome 插件 能够根据你的操作 自动生成 puppeteer 相关代码 mdx-deck 用 markdown 编写演示文稿 code-surfer 基于 mdx-deck 的一个插件让你更好的在文稿中展示 code Progressive Tooling 前端性能优化工具集合 https://github.com/artf/grapesjs 可视化建站工具 不需要写代码就能写一个页面，前端再次再次要下岗了 image-charts 该服务通过 URL 接受参数，然后生成图表，以图片形式返回 eagle.js 一个用 vue 来制作 PPT 的库 Optimizely A/B Test appadhoc 一个国内的 A/B Test 服务 Macget-plain-text 能清除剪贴板里的格式 很实用 IINA mac 平台感觉免费最好的播放器 强推 Githubgithub 短域名服务 shields Github README 里面的装逼小图标 Emoji 方便平时写查找 emoji emoji.muan 同上 而且更全 git-awards github ranking 没事可以查着玩玩 http://githubrank.com/ github 按照 followers 排名 开发zeplin 前端和设计师神器，有标注、Style Guide、版本管理、简单的团队协作，重点是前端不用写 css 了，复制就可以了。 iconfont 阿里出的图标库，非常实用，支持 svg、font、png 多种格式，基本现在所有图标都在上面找。 cssicon 所有的 icon 都是纯 css 画的 缺点：icon 不够多 智图 腾讯出品 在线图片压缩 支持转成 webP 处理静态图片时候很好用 picdiet 另一个图片压缩网站 CSS triangle generator 帮你快速用 css 做出三角形 cssarrowplease 帮你做对话框三角的 clippy 在线帮你使用 css clip-path 做出各种形状的图形 Regular Expressions 在线正则网站 jex 正则可视化网站，配合上面的 Regular Expressions，写正则方便很多 jsfiddle 在线运行代码网站 很不错，可惜要翻墙 codepan 在线运行代码网站 不用翻墙，可以自己部署 fiddle.md 一个方便的在线共享 markdown 在线笔试题一般都用这个 jsdelivr cdn 服务 unpkg cdn 服务 coderpad 远程面试的神器，可以让面试者远程写代码 不过需要翻墙 icode 有赞团队出品的 coderpad 可以互补，它不需要翻墙 snipper 一个代码协同的网站。你新建一个代码片段，然后把网址分享给其他人，就可以看到他们的实时编辑。 codesandbox 一个可以在线编辑且提供在线 demo 的网站 支持 vue react angular 多种框架 神器 codrops 上面的交互都非常酷炫 bgremover 在线图片去底工具 photopea 一个网页端 Photoshop 很变态 设计uimovement 能从这个网站找到不少动画交互的灵感 awwwards是一个一个专门为设计精美的网站以及富有创意的网站颁奖的网站 dribbble 经常能在上面找到很多有创意好看的 gif 或者图片，基本上我所有的图都是上面招的 Bēhance dribbble 是设计师的微博，Bēhance 是设计师的博客 Logojoy 使用 ai 做 logo 的网站，做出来的 logo 质量还不错。 brandmark 另一个在线制作 logo 网站(这个不打水印，很良心) instant 有一个 logo 制作网站 coolors 帮你在线配色的网站 你能找到不少配色灵感 colorhunt 另一个配色网站 uigradients 渐变色网站 有趣帮你百度一下 可以 点我测试一下 国际版 同帮我百度一下 点我测试一下 wallhaven 壁纸网站 交互微交互 里面收集了市面上很多很好的微交互例子 值得学习 Little Big Details 同上，一个国外微交互汇集网站 cruip 登录页的各种页面设计，可以免费下载模板 Csscss-tricks 一个学习 css 不错的网站 有很多有意思的 demo 教程npx 教你怎么合理的使用 npx 产品产品大牛 什么有很多完整的产品原型可以借鉴 磨刀 快速出 ui 原型","tags":[{"name":"water","slug":"water","permalink":"http://www.liuzhidream.com/tags/water/"}]},{"title":"Python-threading","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python-threading/Python-threading/","text":"python多线程相关笔记 线程使用标准库threading来创建线程。threading 库可以在单独的线程中执行任何的在 Python 中可以调用的对象。你可 以创建一个 Thread 对象并将你要执行的对象以 target 参数的形式提供给该对象。虽然python GIL 的存在，导致多线程同一时刻只能有一个线程获得解释器（在py2中，大概执行1000行字节码后，会释放解释器，当线程被阻塞的时候，会让出解释器，释放GIL） 可以通过time.sleep(3)来阻塞线程 一个简单例子： 12345678910111213141516171819202122232425import threading# 计算密集型任务def func(): a = [i for i in range(1111)] print('hello world')t = threading.Thread(target=func)t.start()print('sleep')# 此时创建列表a占用了解释器，先hello world 再 sleep# 计算密集型任务def func(): a = [i for i in range(11111111111)] print('hello world')t = threading.Thread(target=func)t.start()print('sleep')# 这种情况，先打印sleep再是hello world（执行一定的字节码后，释放了解释器） threading的属性和方法 current_thread() # 返回当前线程对象. main_thread() # 返回主线程对象. active_count() # 当前处于alive状态的线程个数. enumerate() # 返回所有活着的线程的列表，不包括已经终止的线程和未开始的线程. get_ident() # 返回当前线程ID，非0整数. 看一个例子： 1234567891011121314151617import threadingdef func(): # a = [i for i in range(1111)] print('current thread = &#123;&#125;'.format(threading.current_thread())) print('main thread = &#123;&#125;'.format(threading.main_thread()), '\"主线程对象\"') print('active count = &#123;&#125;'.format(threading.active_count()), '\"alive\"') print('hello world')t = threading.Thread(target=func)t.start()print('sleep')print('current thread = &#123;&#125;'.format(threading.current_thread()))print('main thread = &#123;&#125;'.format(threading.main_thread()), '\"主线程对象\"')print('active count = &#123;&#125;'.format(threading.active_count()), '\"alive\"') 运行以上代码，每次的执行结果是不一样的，而且是print是线程不安全的。要解释这个问题，需要再了解一些线程相关的概念。 thread实例的属性和方法 name: 只是一个名称标识，可以重名，getName()、setName()来获取、设置这个名词。 ident: 线程ID，它是非0整数。线程启动后才会有ID，否则为None。线程退出，此ID依旧可以访问。此ID可以重复使用。 is_alive(): 返回线程是否活着。 通过threading.Thread() 我们创建了线程类的实例，像面向对象一样，可以有对应的方法，属性 t = threading.Thread(target=func, name=&#39;my_thread&#39;, args=(&#39;1&#39;, ), kwargs={&#39;a&#39;: 2}) start(): 启动线程。每一个线程必须且只能执行该方法一次。 开始线程活动。 对每一个线程对象来说它只能被调用一次，它安排对象在一个另外的单独线程中调用run()方法（而非当前所处线程）。当该方法在同一个线程对象中被调用超过一次时，会引发RuntimeError(运行时错误)。 run(): 运行线程函数。 代表了线程活动的方法。 你可以在子类中重写此方法。标准run()方法调用了传递给对象的构造函数的可调对象作为目标参数，如果有这样的参数的话，顺序和关键字参数分别从args和kargs取得。 start() 后，还会执行run。如果你重写线程类，在调用start和run的时候，加入打印代码，start执行的线程，会派生出子线程，在子线程中去执行run，配合threading.current_thread()可以看到整个过程。 而run只在当前线程中执行。 多线程情况继承Thread类，使用Extender的形式扩展start和run方法，观察执行情况。我们开启两个线程，然后start他们，利用threading.current_thread()获取当前线程，main_thread()返回主线程对象 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import threadingimport timeimport logginglogging.basicConfig(level=logging.NOTSET)def worker(): count = 0 while True: if count &gt; 5: break time.sleep(1) count += 1 # print(\"worker running\") logging.info(\"&#123;&#125; &#123;&#125; 主线程：&#123;&#125;\".format(threading.current_thread().name, threading.current_thread().ident, threading.main_thread())) # print(threading.current_thread().name, threading.current_thread().ident)class MyThread(threading.Thread): def start(self): print('start~~~~~~~~~~~~~') super().start() def run(self): print('run~~~~~~~~~~~~~~~') super().run()print(threading.main_thread())t = MyThread(name='worker', target=worker)t2 = MyThread(name='not worker', target=worker)t.start()t2.start()t.join()t2.join()# 输出结果# &lt;_MainThread(MainThread, started 4587271616)&gt;# start~~~~~~~~~~~~~# run~~~~~~~~~~~~~~~# start~~~~~~~~~~~~~# run~~~~~~~~~~~~~~~# INFO:root:worker 123145369858048 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:not worker 123145375113216 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:worker 123145369858048 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:not worker 123145375113216 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:worker 123145369858048 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:not worker 123145375113216 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:worker 123145369858048 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:not worker 123145375113216 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:worker 123145369858048 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:not worker 123145375113216 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:worker 123145369858048 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt;# INFO:root:not worker 123145375113216 主线程：&lt;_MainThread(MainThread, started 4587271616)&gt; 可以看到两个线程交替运行，如果使用print，你跑多次这个结果是不一样的。 打印前可以加入threading.main_thread()，这样可以看到俩个线程都是主线程派生出来的子线程。 换成run()方法后，结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import threadingimport timeimport logginglogging.basicConfig(level=logging.NOTSET)def worker(): count = 0 while True: if count &gt; 5: break time.sleep(1) count += 1 # print(\"worker running\") # print(threading.main_thread().name, threading.current_thread().name, threading.current_thread().ident) logging.info(\"&#123;&#125; &#123;&#125; 主线程：&#123;&#125;\".format(threading.current_thread().name, threading.current_thread().ident, threading.main_thread()))class MyThread(threading.Thread): def start(self): print('start~~~~~~~~~~~~~') super().start() def run(self): print('run~~~~~~~~~~~~~~~') super().run()t = MyThread(name='worker', target=worker)t2 = MyThread(name='not worker', target=worker)t.run()t2.run()# run~~~~~~~~~~~~~~~# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# run~~~~~~~~~~~~~~~# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt;# INFO:root:MainThread 4705641920 主线程：&lt;_MainThread(MainThread, started 4705641920)&gt; 可以看到，run就是去调用函数，谁来调用呢？当然是当前线程了，可以看到 print(threading.main_thread().name, threading.current_thread().name, threading.current_thread().ident) 打印出来的都是主线程。 没有开新的线程，这就是普通函数调用，所以执行完t1.run()，然后执行t2.run()，这里就不是多线程。 当使用start方法启动线程后，进程内有多个活动的线程并行的工作，就是多线程。 一个进程中至少有一个线程，并作为程序的入口，这个线程就是主线程。一个进程至少有一个主线程。其他线程称为工作线程。 线程安全使用print来运行上面的两个例子，本应该是一行行打印，但很多字符串打印在了一起，这说明print函数被打断了，被线程切换打断了。 print函数分两步，第一步打印字符串，第二部换行，就在这之间，发生了线程的切换。 说明print函数不是线程安全函数。 print函数还没执行换行符，就被其它线程打断了，在python3中： def print(self, *args, sep=&#39; &#39;, end=&#39;\\n&#39;, file=None) print变成了函数，结尾默认加‘\\n’，你可以去改变这个参数，比如改成’’, 打印结果就是一行的一串字符 线程安全: 线程执行一段代码，不会产生不确定的结果，那这段代码就是线程安全的。在开发中，我们会使用标准库的logging来，打印信息，这个是线程安全的。 线程daemon线程可以被标识为”Daemon线程”，Daemon线程表明整个Python主程序只有在Daemon子线程运行时可以退出。该属性值继承自父线程，可通过setDaemon()函数设定该值。 daemon线程和non-daemon线程(注：这里的daemon不是Linux中的守护进程)： 进程靠线程执行代码，至少有一个主线程，其他线程是工作线程。 主线程是第一个启动的线程。 父线程：如果线程A中启动了一个线程B，A就是B的父线程。 子线程：B就是A的子线程。 python中构造线程的时候可以设置daemon属性，这个属性必须在start方法之前设置好。 daemon属性：表示线程是否是daemon线程，这个值必须在start()之前设置，否则引发RuntimeError异常。 daemon=False 运行发现子线程依然执行，主线程已经执行完，但是主线程会一直等着子线程执行完daemon=True 运行发现主线程执行完程序立即结束了 实例方法： isDaemon()：是否是daemon线程。setDaemon()：设置为daemon线程，必须在start方法之前设置。 总结: 线程具有一个daemon属性，可以显式设置为True或False，也可以不设置，不设置则取默认值None。 如果不设置daemon，就取当前线程的daemon来设置它。子线程继承父线程的daemon值，作用和设置None一样。 主线程是non-daemon线程，即daemon=False。 从主线程创建的所有线程不设置daemon属性，则默认都是daemon=False，也就是non-daemon线程。 python程序在没有活着的non-daemon线程运行时退出，也就是剩下的只能是daemon线程，主线程才能退出，否则主线程就只能等待。 如果有non-daemon线程的时候，主线程退出时，也不会杀掉所有daemon线程，直到所有non-daemon线程全部结束 如果还有daemon线程，主线程需要退出，会结束所有 daemon线程，退出。 线程创建的时候t = threading.Thread(target=func, daemon=False)这个daemon不设置就是False 子线程也是non-daemon，只要有线程是non-daemon，python程序就不会退出，如果还未执行完成的线程是daemon的，主线程执行完，就会退出，并杀掉所有daemon线程。 Daemon线程会被粗鲁的直接结束，它所使用的资源（已打开文件、数据库事务等）无法被合理的释放。 123456789101112131415import timeimport threadingdef foo(n): for i in range(n): print(i) time.sleep(1)t1 = threading.Thread(target=foo, args=(10,), daemon=True)t1.start()# t1.join() # 设置join.print('Main Thread Exiting') 在这个例子中，子线程开始执行，然后主线程执行了打印，由于主线程执行完成了，而剩下的线程是daemon的，所以程序退出。把daemon = False或者不设置，结果就是打印了Main Thread Exiting后，子线程继续，打印1，2，3….. join 使用了join方法后，daemon线程执行完了，主线程才退出。 join(timeout=None)，是线程的标准方法之一。 一个线程中调用另一个线程的join方法，调用者将被阻塞，直到被调用线程终止。 一个线程可以被join多次。 timeout参数指定调用者等待多久，没有设置超时，就一直等待被调用线程结束。 调用谁的join方法，就是join谁，就要等谁。 把上面例子的 t1.join() # 设置join. 放开，print(&#39;Main Thread Exiting&#39;) 要等子线程执行完成才执行。 join ()方法：主线程A中，创建了子线程B，并且在主线程A中调用了B.join()，那么，主线程A会在调用的地方等待，直到子线程B完成操作后，才可以接着往下执行，那么在调用这个线程时可以使用被调用线程的join方法。 总结： 主要理解daemon join，不做处理的多线程，线程是并发的，daemon控制了主线程是否等待子线程执行完成，join控制了线程是否要组赛，主线程被阻塞了，就不会因为还剩daemon线程退出，因为主线程被阻塞了，他还没有执行完，所以这两个概念是互不冲突的（你可以设置超时时间，超时到了，主线程不再阻塞，就会杀掉daemon线程）。 在主线程中创建了3个线程，3个线程执行了join，就是说主线程要等着3个线程完成才执行，3个线程中的A线程创建了线程a，那么a就是A的子线程，a中join A就要等a执行完成，主线程也被阻塞，在等A，即主线程等A，A等a。 原子性python的大部分操作是原子性的，比如你对列表执行反向，排序，它不会被其它线程打断。 12import disdis.dis(foo) 利用标准库的dis可以看python代码的字节码实现，一般操作由一条指令来完成，那么就是原子性，如果一个操作（对应python的一行或几行代码）需要多个指令（入栈，出栈，调用寄存器等），可能在入栈等某个指令的时候被其它线程打断，出现和预期不一样的效果。 队列标准库queue提供了队列支持，在py2中，通过import Queue来使用队列，在py3中，通过from queue import Queue，py3中，除了Queue类，还增加了queue.LifoQueue（LIFO后进先出队列），queue.PriorityQueue（优先级队列） 实例方法q = queue.Queue(3) # 创建队列，队列最大元素3个，默认为0，此时队列长度没有限制 queue.qsize() 返回队列的大小 queue.empty() 如果队列为空，返回True，反之False queue.full() 如果队列满了，返回True，反之False queue.full 与 maxsize 大小对应 queue.get([block[, timeout]])获取队列，timeout等待时间 queue.get_nowait() 相当queue.get(False) queue.put(item) 写入队列，timeout等待时间 queue.put_nowait(item) 相当queue.put(item, False) queue.task_done() 在完成一项工作之后，queue.task_done()函数向任务已经完成的队列发送一个信号 queue.join() 实际上意味着等到队列为空，再执行别的操作 本地线程不同的线程对内容的修改只在线程内发挥作用，线程之间互相不影响，在flask框架中有使用到 12345678910111213141516171819202122232425import threadingmy_data = threading.local()my_data.number = 42print(my_data.number)log = []def f(): my_data.number = 11 log.append(my_data.number) print(id(my_data.number))thread = threading.Thread(target=f)thread.start()thread.join()print(log)print(my_data.number)print(id(my_data.number))# 42# 4559721904# [11]# 42# 4559722896 同步原语控制多线程同时访问资源，包括互斥锁，信号量，条件变量，事件 以房间为例子举例： 有些房间最多只能容纳一个人。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。 一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫互斥锁（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。 还有些房间，可以同时容纳n个人。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。 这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做信号量（Semaphore），用来保证多个线程不会互相冲突。 不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。 信号量使用信号量做为同步机制，使用with进入上下文管理器，省略了acquire和release，信号量通过计数器来管理，这里计数器初始是3，获取acquire操作，计数器减1，release操作，计数器加1，当计数器为0的时候，阻塞其它线程的操作。 通过执行结果可以看到，创建了5个线程，前3个线程 0，1，2 执行了 acquire操作，使得信号量为0，阻塞了其它线程，通过sleep模拟线程阻塞，等到线程 2 release的时候，线程 3 才执行 acquire 操作，4 线程也是等待 3 线程release后才执行 acquire。 通过使用信号量，实现了只能有3个线程并发，而锁其实就是信号量为1的情况。 1234567891011121314151617181920212223242526272829303132333435import timefrom random import randomfrom threading import Thread, Semaphoresema = Semaphore(3) # 创建信号量def foo(tid): with sema: print(f'&#123;tid&#125; acquire sema') time.sleep(random() * 2) print(f'&#123;tid&#125; release sema')threads = []for i in range(5): t = Thread(target=foo, args=(i,)) threads.append(t) t.start()for i in threads: i.join()# 0 acquire sema# 1 acquire sema# 2 acquire sema# 2 release sema# 3 acquire sema# 3 release sema# 4 acquire sema# 1 release sema# 0 release sema# 4 release sema 总结所以线程的执行结果是有很多因素影响的，在你用默认操作的时候，如果进行了IO密集任务或是CPU密集任务，IO密集在等待时会释放GIL，CPU密集也会执行一定数量的字节码后释放一下GIL，由于线程并发的切换是操作系统控制的，所以有这样的编程需求的时候，务必配合join，daemon等控制程序，不然什么时候切换，这是说不准的。 线程何时切换？一个线程无论何时开始睡眠或等待网络 I/O，其他线程总有机会获取 GIL 执行 Python 代码。这是协同式多任务处理。CPython 也还有抢占式多任务处理。如果一个线程不间断地在 Python 2 中运行 1000 字节码指令，或者不间断地在 Python 3 运行15 毫秒，那么它便会放弃 GIL，而其他线程可以运行。把这想象成旧日有多个线程但只有一个 CPU 时的时间片。 协同式多任务处理当一项任务比如网络 I/O启动，而在长的或不确定的时间，没有运行任何 Python 代码的需要，一个线程便会让出GIL，从而其他线程可以获取 GIL 而运行 Python。这种礼貌行为称为协同式多任务处理，它允许并发；多个线程同时等待不同事件。 抢占式多任务处理Python线程可以主动释放 GIL，也可以先发制人抓取 GIL 。 让我们回顾下 Python 是如何运行的。你的程序分两个阶段运行。首先，Python文本被编译成一个名为字节码的简单二进制格式。第二，Python解释器的主回路，一个名叫 pyeval_evalframeex() 的函数，流畅地读取字节码，逐个执行其中的指令。当解释器通过字节码时，它会定期放弃GIL，而不需要经过正在执行代码的线程允许，这样其他线程便能运行。默认情况下，检测间隔是1000 字节码。所有线程都运行相同的代码，并以相同的方式定期从他们的锁中抽出。在 Python 3 GIL 的实施更加复杂，检测间隔不是一个固定数目的字节码，而是15 毫秒。然而，对于你的代码，这些差异并不显著。","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Python-异步与协程","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python-asyncio/README/","text":"异步编程是一个很难的点，不同于同步编程，编程模型将变得复杂。下文引用理查德·史蒂文斯（William Richard (Rich) Stevens，1951年2月5日－1999年9月1日）所编写的《UNIX网络编程》关于I/O Models 部分内容，并结合个人以及网络上的内容做的整理，关于Linux编程遇到的函数，由于没有太多的接触，先做个理解。 概念用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。注：总而言之就是很耗资源，具体的可以参考这篇文章：进程切换。 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存 IO缓存 IO 又被称作标准 IO，大多数文件系统的默认 IO 操作都是缓存 IO。在 Linux 的缓存 IO 机制中，操作系统会将 IO 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 IO 的缺点： 数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 recvfrom() recv()本函数用于从（已连接）套接口上接收数据，并捕获数据发送源的地址。recv也是差不多的功能，不过不能知道对端地址信息（由谁发来的） 同步、异步 概念：消息的通知机制 解释：涉及到IO通知机制；所谓同步，就是发起调用后，被调用者处理消息，必须等处理完才直接返回结果，没处理完之前是不返回的，调用者主动等待结果；所谓异步，就是发起调用后，被调用者直接返回，但是并没有返回结果，等处理完消息后，通过状态、通知或者回调函数来通知调用者，调用者被动接收结果。 反应到编程模型中：同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。要么成功都成功，失败都失败，两个任务的状态可以保持一致。所谓异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。 阻塞、非阻塞 概念：程序等待调用结果时的状态 解释：涉及到CPU线程调度；所谓阻塞，就是调用结果返回之前，该执行线程会被挂起，不释放CPU执行权，线程不能做其它事情，只能等待，只有等到调用结果返回了，才能接着往下执行；所谓非阻塞，就是在没有获取调用结果时，不是一直等待，线程可以往下执行，如果是同步的，通过轮询的方式检查有没有调用结果返回，如果是异步的，会通知回调。 反应到编程模型中：阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。函数只有在得到结果之后才会返回。 有人也许会把阻塞调用和同步调用等同起来，实际上它们是不同的。 对于同步调用来说，很多时候当前线程可能还是激活的，只是从逻辑上当前函数没有返回而已，此时，这个线程可能也会处理其他的消息。还有一点，在这里先扩展下： 如果这个线程在等待当前函数返回时，仍在执行其他消息处理，那这种情况就叫做同步非阻塞； 如果这个线程在等待当前函数返回时，没有执行其他消息处理，而是处于挂起等待状态，那这种情况就叫做同步阻塞； 所以同步的实现方式会有两种：同步阻塞、同步非阻塞；同理，异步也会有两种实现：异步阻塞、异步非阻塞 对于阻塞调用来说，则当前线程就会被挂起等待当前函数返回 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。虽然表面上看非阻塞的方式可以明显的提高CPU的利用率，但是也带了另外一种后果就是系统的线程切换增加。增加的CPU执行时间能不能补偿系统的切换成本需要好好评估。 场景举例： 去银行营业厅办业务员，不论是排队还是使用号码等待通知，如果在这个等待的过程中，等待者除了等待消息通知之外不能做其它的事情，那么该机制就是阻塞的，表现在程序中，也就是该程序一直阻塞在该函数调用处不能继续往下执行。 相反，有的人喜欢在银行办理这些业务的时候一边打打电话发发短信一边等待，这样的状态就是非阻塞的，因为他(等待者)没有阻塞在这个消息通知上，而是一边做自己的事情一边等待。 也就是说，你去排队，要时不时留意有没有排队排到你了，这是同步机制（如果是等叫号就是异步机制），然后你在排队的时候如果不做其它事情，就是阻塞（如果排队的时候玩手机，就是非阻塞），共可以组合出4种情况，也就是对应同步阻塞、同步非阻塞、异步阻塞、异步非阻塞 但是需要注意了，同步非阻塞形式实际上是效率低下的，想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有。如果把打电话和观察排队的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的；而异步非阻塞形式却没有这样的问题，因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。 1. 同步阻塞形式效率是最低的，拿上面的例子来说，就是你专心排队，什么别的事都不做。 2. 异步阻塞形式如果在银行等待办理业务的人采用的是异步的方式去等待消息被触发（通知），也就是领了一张小纸条，假如在这段时间里他不能离开银行做其它的事情，那么很显然，这个人被阻塞在了这个等待的操作上面。 异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞。 比如select 函数，假如传入的最后一个timeout参数为NULL，那么如果所关注的事件没有一个被触发，程序就会一直阻塞在这个select 调用处。 3. 同步非阻塞形式实际上是效率低下的，想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有，如果把打电话和观察排队的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的。 很多人会写阻塞的read/write 操作，但是别忘了可以对fd设置O_NONBLOCK 标志位，这样就可以将同步操作变成非阻塞的了。 4. 异步非阻塞形式效率更高，因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。比如说，这个人突然发觉自己烟瘾犯了，需要出去抽根烟，于是他告诉大堂经理说，排到我这个号码的时候麻烦到外面通知我一下(注册一个回调函数)，那么他就没有被阻塞在这个等待的操作上面，自然这个就是异步+非阻塞的方式了。 如果使用异步非阻塞的情况，比如aio_*组的操作，当发起一个aio_read操作时，函数会马上返回不会被阻塞，当所关注的事件被触发时会调用之前注册的回调函数进行处理。 很多人会把同步和阻塞混淆，我想是因为很多时候同步操作会以阻塞的形式表现出来，比如很多人会写阻塞的read/write操作，但是别忘了可以对fd设置O_NONBLOCK标志位，这样就可以将同步操作变成非阻塞的了。但最根本是因为没有区分这两个概念，比如阻塞的read/write操作中，其实是把消息通知机制和等待消息通知的状态结合在了一起，在这里所关注的消息就是fd是否可读/写，而等待消息通知的状态则是对fd可读/写等待过程中程序（线程）的状态。当我们将这个fd设置为非阻塞的时候，read/write操作就不会在等待消息通知这里阻塞，如果fd不可读/写则操作立即返回。 同样的，很多人也会把异步和非阻塞混淆，因为异步操作一般都不会在真正的IO操作处被阻塞，比如如果用select函数，当select返回可读时再去read一般都不会被阻塞，而是在select函数调用处阻塞。 五种IO模型 blocking IO （阻塞IO） nonblocking IO （非阻塞IO） IO multiplexing （IO多路复用） signal driven IO （信号驱动IO） asynchronous IO （异步IO） 以上五种IO模型不仅在操作系统中存在，也可以引申到编程模型中，有些框架的原理就是其中的一种。 再说一下IO发生时涉及的对象和步骤。 网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)对于socket流而言，第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。第二步：把数据从内核缓冲区复制到应用进程缓冲区。网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。 最后，记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。 blocking IO在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： image 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 non-blocking IOlinux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： image 从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，用户进程其实是需要不断的主动询问kernel数据好了没有。 IO multiplexingIO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图： image 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 IO多路复用是需要特别理解的，因为在很多框架中都有运用，再多啰嗦几句： 网络模型： 由于同步非阻塞方式需要不断主动轮询，轮询占据了很大一部分过程，轮询会消耗大量的CPU时间，而 “后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。如果轮询不是进程的用户态，而是有人帮忙就好了。那么这就是所谓的 “IO 多路复用”。UNIX/Linux 下的 select、poll、epoll 就是干这个的（epoll 比 poll、select 效率高，做的事情是一样的。 IO多路复用有两个特别的系统调用select、poll、epoll函数。select调用是内核级别的，select轮询相对非阻塞的轮询的区别在于—前者可以等待多个socket，能实现同时对多个IO端口进行监听，当其中任何一个socket的数据准好了，就能返回进行可读，然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，当然这个过程是阻塞的。select或poll调用之后，会阻塞进程，与blocking IO阻塞不同在于，此时的select不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理。如何知道有一部分数据到达了呢？监视的事情交给了内核，内核负责数据到达的处理。也可以理解为”非阻塞”吧。 I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。 对于多路复用，也就是轮询多个socket。多路复用既然可以处理多个IO，也就带来了新的问题，多个IO之间的顺序变得不确定了，当然也可以针对不同的编号。 :sunny:总结：blocking IO只处理一个IO，IO multiplexing通过系统调用函数，处理多个IO。no-blocking IO 的轮询是用户态的（由当前进程来执行），多路复用的轮询由系统调用来执行，可以等待多个socket，能实现同时对多个IO端口进行监听。 I/O多路复用的主要应用场景如下： 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字。 服务器需要同时处理多种网络协议的套接字。 了解了前面三种IO模式，在用户进程进行系统调用的时候，他们在等待数据到来的时候，处理的方式不一样，直接等待，轮询，select或poll轮询，两个阶段过程： 第一个阶段有的阻塞，有的不阻塞，有的可以阻塞又可以不阻塞。 第二个阶段都是阻塞的。 从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型(synchronous)。都是进程主动等待且向内核检查状态 高并发的程序一般使用同步非阻塞方式而非多线程 + 同步阻塞方式。要理解这一点，首先要扯到并发和并行的区别。比如去某部门办事需要依次去几个窗口，办事大厅里的人数就是并发数，而窗口个数就是并行度。也就是说并发数是指同时进行的任务数（如同时服务的 HTTP 请求），而并行数是可以同时工作的物理资源数量（如 CPU 核数）。通过合理调度任务的不同阶段，并发数可以远远大于并行度，这就是区区几个 CPU 可以支持上万个用户并发请求的奥秘。在这种高并发的情况下，为每个任务（用户请求）创建一个进程或线程的开销非常大。而同步非阻塞方式可以把多个 IO 请求丢到后台去，这就可以在一个进程里服务大量的并发 IO 请求。 注意：IO多路复用是同步阻塞模型还是异步阻塞模型： 同步是需要主动等待消息通知，而异步则是被动接收消息通知，通过回调、通知、状态等方式来被动获取消息。IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数获取数据就绪状态消息，并且其进程状态为阻塞。所以，把IO多路复用归为同步阻塞模式。 signal-driven IO信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 image Asynchronous I/Olinux下的asynchronous IO其实用得很少。先看一下它的流程： image 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪： 先回答最简单的这个：blocking vs non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： image 经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 最后，再举几个不是很恰当的例子来说明这四个IO Model: 有A，B，C，D四个人在钓鱼： A用的是最老式的鱼竿，所以呢，得一直守着，等到鱼上钩了再拉杆； B的鱼竿有个功能，能够显示是否有鱼上钩，所以呢，B就和旁边的MM聊天，隔会再看看有没有鱼上钩，有的话就迅速拉杆； C用的鱼竿和B差不多，但他想了一个好办法，就是同时放好几根鱼竿，然后守在旁边，一旦有显示说鱼上钩了，它就将对应的鱼竿拉起来； D是个有钱人，干脆雇了一个人帮他钓鱼，一旦那个人把鱼钓上来了，就给D发个短信。 总结同步，异步，阻塞，非阻塞 同步和异步说的是消息通知的机制 同步调用，调用者要一直等待消息返回，编程模型就是由A向B发起了请求，B要把本次请求的任务做完成，然后返回数据给A（通知A任务完成了）。 这里对于任务的调用又会有阻塞和非阻塞，阻塞的编程模型就是在B中，数据还没准备好，但是它不会返回给你，A没有得到返回，要一直等着。如果是非阻塞，编程模型就是在B中，可能会去查数据，没查到（说明内核没有准备好数据），就返回，A收到返回了（假设是一个错误信息，即数据没准备好），A的请求不被B影响，它不需要等待，但是你是同步的，如果A没得到数据，虽然没阻塞A调用，A可以去做其它事情，但是A仍然要再次去请求B，整个调用是同步的，A不去请求B，没人会通知A，所以同步非阻塞是效率低下的编程模型。 异步就是B不需要立即通知A，A可以马上得到返回，B通过回调机制来通知A，这个回调机制就是通知A的手段，可以比喻成发短信，打电话，编程模型就是要准备回调函数，这个回调函数内去通知A。 异步阻塞，A调用B，A不会得到返回，等着回调函数来通知A，A的调用被阻塞了 异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞 异步非阻塞，A调用B，A不会被阻塞，等待回调函数来通知A 同步和阻塞，异步和非阻塞，很容易混淆概念，把同步当成是阻塞的，同样的，很多人也会把异步和非阻塞混淆，因为异步操作一般都不会在真正的IO操作处被阻塞，比如如果用select函数，当select返回可读时再去read一般都不会被阻塞，而是在select函数调用处阻塞。 一般情况，我们不会自己处理这么复杂的编程模型，都是使用现成的模型，linux中的5种IO模型，再比如webserver中，利用gunicorn+django的方式部署项目，理解此时的IO模型是什么样的，gunicorn使用不同的worker模式，IO模型是什么样的。更加细的理解要结合内核态和用户态，操作系统的机制来。理解好概念，当真的需要编写相关代码的时候，理解好整个编程模型，知道什么操作被阻塞，是同步机制还是异步机制。 理解“消息通知机制”和“等待消息通知时的状态（程序等待调用结果时的状态）”这两个概念，这是理解四个概念的关键所在。 关于异步阻塞： 业务逻辑需要的是做完一件事后做另一件事，例如数据库连接初始化后才能开始接受用户的 HTTP 请求。这样的业务逻辑就需要调用者是以阻塞方式来工作。另外一种使用阻塞方式的理由是降低响应延迟。如果采用非阻塞方式，一个任务 A 被提交到后台，就开始做另一件事 B，但 B 还没做完，A 就完成了，这时要想让 A 的完成事件被尽快处理（比如 A 是个紧急事务），要么丢弃做到一半的 B，要么保存 B 的中间状态并切换回 A，任务的切换是需要时间的（不管是从磁盘载入到内存，还是从内存载入到高速缓存），这势必降低 A 的响应速度。因此，对实时系统或者延迟敏感的事务，有时采用阻塞方式比非阻塞方式更好。 协程1234567891011121314151617def consumer(): while True: v = yield print(f'consume: &#123;v&#125;')def producer(c): for i in range(10, 13): c.send(i)c = consumer()c.send(None)producer(c)c.close() 123456789101112131415161718192021def consumer(): r = '' while True: v = yield r print(f'consume: &#123;v&#125;') r = f'Result : &#123;v * 2&#125;'def producer(c): for i in range(10, 13): print(f'Producing... &#123;i&#125;') r = c.send(i) print(f'Consumer return: &#123;r&#125;')c = consumer()c.send(None)producer(c)c.close() 12345678910111213141516171819def framework(logic): try: it = logic() s = next(it) print(f'[FX] logic: &#123;s&#125;') print(f'[FX] do something...') it.send(f'async: &#123;s&#125;') except StopIteration: passdef logic(): s = 'Logic' r = yield s print(r)framework(logic)","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Django","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/Django/","text":"django学习笔记 对文档阅读的大致补充，框架拥有功能的概述，详细内容查阅文档。 在使用前后端分离的项目中，模版相关的内容基本没什么用了，对于Django如果不是快速开发的应用，基本也不用它提供的功能（认证，表单等），使用较多的有中间件，URL到视图响应，ORM，个人认为扩展ORM开发一套自己的框架很有实战意义，你可以做一个自己风格的ORM，实现像只完成模型定义，就拥有对模型进行增加(Create)、读取查询(Retrieve)、更新(Update)和删除(Delete)的能力。 如此，你便迭代出一个非常适合自己的框架，相信大公司都会有自己的一套迭代框架，用于快速开发产品。 Django 相关 image sessionsession是一种常用的web技术，在Django框架中很容易去使用它。 session 概念大多数的应用都是用 Cookie 来实现 Session 跟踪的，第一次创建 Session 的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie里面记录一个 Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie怎么办？一般这种情况下，会使用一种叫做 URL重写 的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。 网站保存登录账号和密码是由本地的Cookie来实现的。 关于缓存：为了实现性能，缓存还是有必要的，不过先做到数据库的实现。session还可以基于文件来实现 工作流程session是要浏览器这边配合Cookie来实现的，所以浏览器不能禁用cookie： 当用户来访问服务端时,服务端生成一个随机字符串； 当用户登录成功后 把 {sessionID :随机字符串} 组织成键值对 加到 cookie里发送给用户； 服务器以发送给客户端 cookie中的随机字符串做键，用户信息做值，保存用户信息； 代码流程（在默认配置下）在代码上，我们直接 request.session[&#39;name&#39;] = &quot;my name&quot; 这一步执行了，就是使用随机字符串，创建了session保存到数据库，然后把 session_id（随机字符串）放在cookie里面给到浏览器，浏览器就设置了cookie，下次浏览器就会在请求里面cookie带上这个id，框架流程上中间件会拿出请求体的cookie查询数据库，并将session对象赋值给 request.session。 session序列化(框架文档有讲解)session的数据会被序列化保存在数据库中，默认是json，一般不需要改，由于是json，所以数据创建的键最好是字符串，数据要能被json编码，你不能直接把一个对象设置在session的键值对当中。 如果想保存更高级的格式，就需要自己实现序列化程序。（从数据库的数据来看，存储的并不是是序列字符串，是一定规则化的字母，猜测是为了压缩数据，s.get_decoded()可以得到解码的结果） 会话对象准则使用普通的Python字符串作为字典键 request.session。这是一个比硬性规定更重要的惯例。以下划线开头的会话字典键由Django保留供内部使用。不要request.session用新对象覆盖，也不要访问或设置其属性。像Python字典一样使用它。 扩展session 就是用来在后端，为了给无状态的HTTP协议提供识别（用户识别），扩展它是很重要的。比如我们不依赖cookie，而是每次都传递一个id，后端用这个id自己创建session，然后前端每次请求都带这个ID，这样后端中间件每次都通过ID查询数据库，赋值request.session 扩展依赖于 SessionStore from django.contrib.sessions.backends.db import SessionStore 如果 SESSION_ENGINE 不是数据库，需要从对应的引擎来引入，可以这样： 123from importlib import import_modulefrom django.conf import settingsSessionStore = import_module(settings.SESSION_ENGINE).SessionStore 安全如果您在cookie中设置了 HttpOnly 性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止 XSS 攻击，具体一点的介绍请google进行搜索 遇到这个问题时： The request&apos;s session was deleted before the request completed. The user may have logged out in a concurrent request, for example. 该地址有讲解，不过这个问题应该是出现在开发阶段的调试中，如果出现了问题可以清除浏览器数据来解决，一劳永逸的方案（还没看，链接在下面）不一定需要。https://stackoverflow.com/questions/42211065/django-memcached-error-the-requests-session-was-deleted-before-the-request-c 密码加密框架提供了密码加密功能，该部分讲解了密码如何存储，密码升级，密码验证，管理密码。 密码存储暂时没看。 密码升级有从下一版本升级到新版本的时候，使用新的算法，和对所有需要升级的一次处理，具体参考文档。 除了框架的自己提供的，还可以使用自己编写的算法进行加密 手动管理密码：包括几个函数，对密码进行加密得到加密的结果，这个用来保存在数据库，验证密码，把明文密码和数据库存储的加密密码进行验证，返回布尔值。 密码验证：控制用户输入的密码，避免太简单，例如用户的密码输入6为，验证规则是9位那么验证不通过。 配置文件： 123456789101112131415# 密码加密使用的算法# 列表的第一个元素 (即settings.PASSWORD_HASHERS[0]) 会用于储存密码，# 所有其它元素都是用于验证的哈希值，它们可以用于检查现有的密码。PASSWORD_HASHERS = [ 'django.contrib.auth.hashers.PBKDF2PasswordHasher', 'django.contrib.auth.hashers.PBKDF2SHA1PasswordHasher', 'django.contrib.auth.hashers.Argon2PasswordHasher', 'django.contrib.auth.hashers.BCryptSHA256PasswordHasher', 'django.contrib.auth.hashers.BCryptPasswordHasher', 'django.contrib.auth.hashers.SHA1PasswordHasher', 'django.contrib.auth.hashers.MD5PasswordHasher', 'django.contrib.auth.hashers.UnsaltedSHA1PasswordHasher', 'django.contrib.auth.hashers.UnsaltedMD5PasswordHasher', 'django.contrib.auth.hashers.CryptPasswordHasher',] 中间件高版本需要继承MiddlewareMixin，低版本不需要。 各种架构中都会用到的技术（有些框架也称为管道，httphandle）。用户发起的请求会依次经过所有的中间件。由于中间件也用来处理django的内部的东西，所以自己添加的中间件一般写在系统中间件后面，除非你对流程很了解，想在框架某个流程时插入某些东西。 模型 每个模型都是django.db.models.Model 的一个Python 子类。模型的每个属性都表示为数据库中的一个字段。 每个字段都被指定成一个类属性，例如Field类。每个属性映射到一个数据库的列。 查阅或看源代码，可以从模型类上获取到很多内容。 字段参数question_text = models.CharField(max_length=200,blank=true,null=true) blank，null 都是该字段可以为空，blank是在admin中可以为空，要在表中可以为空，设置null null = Ture 指定空，blank = Ture 允许填 choices 这个字段参数设置该字段内容是选择列表 primary_key 该参数为Ture 指定其为主键字段，不写，自动添加一个IntegerField字段为主键 db_index 为此字段创建索引 editable 设置为False 这个字段将不会出现在 admin 或者其他 ModelForm.，会跳过模型验证 unique 为Ture，这个字段在表中必须有唯一值，注意当设置 unique 为True 时，你不需要再指定 db_index，因unique 本身就意味着一个索引的创建 verbose_name（字段的自述名） Field.verbose_name 一个字段的可读性更高的名称。如果用户没有设定冗余名称字段，Django会自动将该字段属性名中的下划线转换为空格，并用它来创建冗余名称。可以参照 Verbose field names。 元参数 permissions 是用来这种模型的权限的，default_permissions 是设置默认权限的，比如add，change，即模型是否能添加，改变。 由于Django 查询语法的工作方式，字段名称中连续的下划线不能超过一个。django不允许重写字段。 模型的属性objects 模型最重要的属性是Manager。它是Django 模型进行数据库查询操作的接口，并用于从数据库获取实例。如果没有自定义Manager，则默认的名称为objects。Managers 只能通过模型类访问，而不能通过模型实例访问。 Manager 称为管理器 ，它是一个类，该类下面有多个方法，比如get，all，filter 方法，它们都属于这个管理器，你也可以重写一个新的管理器，实现新的查询方法。通常的 Objects.get()，就是指向该类下的方法。 类的扩展创建一个可公共使用的模型，他的字段将被其他模型包含，这个模型称为：抽象基类。 当你想将一些共有信息放进其它一些model的时候，抽象化类是十分有用的。你编写完基类之后，在 Meta 类中设 abstract=True，这个模型就不会被用来创建任何数据表。取而代之的是，当它被用来作为一个其他model的基类时，它的字段将被加入那些子类中。如果抽象基类和它的子类有相同的字段名，那么将会出现 error（并且Django将抛出一个exception）。 一个例子： 1234567891011from django.db import modelsclass CommonInfo(models.Model): name = models.CharField(max_length=100) age = models.PositiveIntegerField() class Meta: abstract = Trueclass Student(CommonInfo): home_group = models.CharField(max_length=5) Student 模型将有三个项：name，age 和 home_group。CommonInfo 模型无法像一般的Django模型一样使用，因为它是一个抽象基类。它无法生成一张数据表或者拥有一个管理器，并且不能实例化或者直接储存。 许多应用场景下, 这种类型的模型继承恰好是你想要的。它提供一种在 Python 语言层级上提取公共信息的方式，同时在数据库层级上，每个子类各自仍然只创建一个数据库表。 多表继承 这是 Django 支持的第二种继承方式。使用这种继承方式时，每一个层级下的每个 model 都是一个真正意义上完整的 model 。每个 model 都有专属的数据表，都可以查询和创建数据表。继承关系在子 model 和它的每个父类之间都添加一个链接 (通过一个自动创建的 OneToOneField来实现)。 例如： 123456789from django.db import modelsclass Place(models.Model): name = models.CharField(max_length=50) address = models.CharField(max_length=80)class Restaurant(Place): serves_hot_dogs = models.BooleanField(default=False) serves_pizza = models.BooleanField(default=False) Place里面的所有字段在 Restaurant中也是有效的，只不过数据保存在另外一张数据表当中。所以下面两个语句都是可以运行的： 12&gt;&gt;&gt; Place.objects.filter(name=\"Bob's Cafe\")&gt;&gt;&gt; Restaurant.objects.filter(name=\"Bob's Cafe\") 代理继承 使用多表继承时，model 的每个子类都会创建一张新数据表，通常情况下，这正是我们想要的操作。这是因为子类需要一个空间来存储不包含在基类中的字段数据。但有时，你可能只想更改 model 在 Python 层的行为实现。比如：更改默认的 manager ，或是添加一个新方法。 12345678910111213from django.db import modelsclass Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30)class MyPerson(Person): class Meta: proxy = True def do_something(self): # ... pass 它们都操作同一个数据表，设置 proxy = Ture 实现代理，为Person 模型添加了一个方法你可以在代理中重写方法，或者改变某一字段的排序，不会对原始模型产生影响。比如你用原模型查询a字段是无序的，你在代理中对a字段元属性进行了排序，用代理模型去查询就是有序的。 模型对应关系框架实现了大部分字段了，文件，图片都有，关于文件如果用到可以仔细看看，另外有模型API，方便获取对象的信息，这对于开发很有用。 一对一和一对多一对多比较了解了，被to的模型，通常会被多个表to。如果字段是外键，并且这个外键只被这个字段to那么这个时候就可以用一对一了，就是这个被to的模型，一张表只被另一张表to（不知道再被另一张表to的时候会发生什么）。通常用来做详情或扩展，比如用户的扩展，那么扩展内容可以是一个新的模型，因为这些内容是和用户相关的，所以应该一条详情对应一个用户，就可以用一对一。 使用一对一模型，在查询的时候，这个被关联的字段可以互相取到双方的值。 如 user 有 detail 对到模型 detail： 1234567891011u = user.objects.filter().first()u.detail.msg# 反向查询d = detail.objects.filter().first()d.user.name# 一对多，上面的详情变成了classu = user.objects.filter().first()u.class.msg# 反向查询c = class.objects.filter().first()c.user_set.all() # 返回查询集 反向查询如果设置了 related_name，比如 class_user，可以这样 c.class_user，默认用 表名_set。 多对多一般通过外键，新建一个表，把两张表联系起来，实现多对多。或者在其中一个模型里面建立多对多字段。此时进行正向查询，不会像一对多那样得到外键id或对象，应该 .all() 得到查询集（一对多方向才得到查询集），反向查询也是得到查询集，反向查询也是可以用 related_name。 什么时候用多对多对于一对多来说，被to的可以说是独立的，它可以不依赖其它模型，比如学生和班级，班级就是班级，而学生要和班级建立关系就用一对多，班级被to了，才会通过反向查询得到所有的学生。 对于上诉情况也会有特殊情况，上诉情况比较实用于中学，中学就是一个学生属于一个班级，如果在大学，我们进行选课，那么课程会是一个模型，一个学生会选择多个课程，这个时候用多对多就比较合适了，当然也可以通过第三张表将课程和学生建立关系，用一对多来实现。 被用做多对多的字段，创建对象的时候，如何赋值，add, set, remove, clear。 查询与数据库框架ORM查询补充 数据迁移与修改模型迁移功能非常强大，可以让你在开发过程中不断修改你的模型而不用删除数据库或者表然后再重新生成一个新的 —— 它专注于升级你的数据库且不丢失数据。实现模型变更的三个步骤： 修改你的模型（在models.py文件中） 运行python manage.py makemigrations ，为这些修改创建迁移文件 运行python manage.py migrate ，将这些改变更新到数据库中 将生成和应用迁移文件的命令分成几个命令来执行，是因为你可能需要将迁移文件提交到你的版本控制系统中并跟随你的应用一起变化；这样做不仅可以使开发变得更加简单，而且对其他开发者以及上线生产非常有用。 跨关联关系的查询可以像这样，只需使用关联的模型字段的名称，并使用双下划线分隔，直至你想要的字段 dquery = DrawMoneyRecord.objects.filter(drawuser__district__name__icontains=&apos;西山片区&apos;) 发现当关联的字段有null的时候，查询不到结果。比如模型DMR有三张表，三张都有drawuser，到了drawuser外键对应的模型User的时候，有两张User的表，其中一张district字段为null，此时查询失效，需保证有关联的都不能为null。 它还可以反向工作。若要引用一个“反向”的关系，只需要使用该模型的小写的名称。 比如 Order 和 OrderItem ，它们的对应关系为： order = models.ForeignKey(to=Order, verbose_name=_(&apos;订单&apos;), editable=False) 想要从Order来查：Order.objects.filter(orderitem__name__icontains=&#39;小&#39;)，便可以利用orderitem来查出order 反向查询，关系是从右看到左： AgencyOrder.objects.filter(agencyorderitem__orderitem__order_id__in=order_ids) 上面这个order_ids可以得到order，向上得到orderitem… order__bigorder__date SQL 优化prefetch_related select_related 都是针对表有关联的，如果不用，则拿到的只是外键的id，如果使用，则一次就把外键对象拿到。 打印 SQL 语句 确保 django.core.context_processors.debug 在 CONTEXT_PROCESSORS 中 DEBUG = True 代码如下： 1234567from django.db import connection# 这里是查询MyModel.objects.filter(name=\"my name\")print connection.queries# 或者from django.db import connectionprint MyModel.objects.filter(name=\"my name\").query save 方法一般在得到查询集后，只有是去创建的情况才使用 queryset.save()，对于数据的修改，使用 quseryset.save(update_fields=[&#39;fields&#39;])。 查询对象 F，QF用来做运算，加减乘除。Q做复杂查询。 查询集查询集，就是查询结果的集合。 Blog.objects.all() 返回包含数据库中所有 Blog 对象的一个查询集。 filter(**kwargs) 返回一个新的查询集，它包含满足查询参数的对象。 exclude(**kwargs) 返回一个新的查询集，它包含不满足查询参数的对象。 通过 get 获取一个单一的对象 one_entry = Entry.objects.get(pk=1) queryset是查询集，就是传到服务器上的url里面的查询内容。Django会对查询返回的结果集QuerySet进行缓存，这是为了提高查询效率。也就是说，在你创建一个QuerySet对象的时候，Django并不会立即向数据库发出查询命令，只有在你需要用到这个QuerySet的时候才会这样做。 缓存和查询集： 每个查询集都包含一个缓存来最小化对数据库的访问。理解它是如何工作的将让你编写最高效的代码。在一个新创建的查询集中，缓存为空。首次对查询集进行求值 —— 同时发生数据库查询 ——Django 将保存查询的结果到查询集的缓存中并返回明确请求的结果（例如，如果正在迭代查询集，则返回下一个结果）。接下来对该查询集 的求值将重用缓存的结果。请牢记这个缓存行为，因为对查询集使用不当的话，它会坑你的。例如，下面的语句创建两个查询集，对它们求值，然后扔掉它们： 12&gt;&gt;&gt; print([e.headline for e in Entry.objects.all()])&gt;&gt;&gt; print([e.pub_date for e in Entry.objects.all()]) 这意味着相同的数据库查询将执行两次，显然倍增了你的数据库负载。同时，还有可能两个结果列表并不包含相同的数据库记录，因为在两次请求期间有可能有Entry被添加进来或删除掉。为了避免这个问题，只需保存查询集并重新使用它： 123&gt;&gt;&gt; queryset = Entry.objects.all()&gt;&gt;&gt; print([p.headline for p in queryset]) # Evaluate the query set.&gt;&gt;&gt; print([p.pub_date for p in queryset]) # Re-use the cache from the evaluation. 查询集方法 order_by 排序 pk__in 当需要取多个结果的时候，比如id=1,2,3这三条数据，models.object.filter(pk__in = ids)，ids=[1,2,3] select_related()函数 在一对一和外键中使用，目的：减少查询次数 关联查询例子： Person(人)，字段中有一个居住地living，living外键到City，City 中有 province(省)，如何直接得到省的数据？ 12p=Person.object.select_related('living').get(name=\"小明\")p.living.province 如果省是其它的外键，比如 province外键到 Province类，查询集要用 &#39; __ &#39;，p=Person.object.select_related(&#39;living__province&#39;).get(name=&quot;小明&quot;)。 常用方法： Command Description __exact 精确等于 like ‘aaa’ __iexact 精确等于 忽略大小写 ilike ‘aaa’ __contains 包含 like ‘%aaa%’ __icontains 包含 忽略大小写 ilike ‘%aaa%’，但是对于sqlite来说，contains的作用效果等同于icontains。 __gt 大于 __gte 大于等于 __lt 小于 __lte 小于等于 __in 存在于一个list范围内 __startswith 以…开头 __istartswith 以…开头 忽略大小写 __endswith 以…结尾 __iendswith 以…结尾，忽略大小写 __range 在…范围内 __year 日期字段的年份 __month 日期字段的月份 __day 日期字段的日 __isnull=True/False __isnull=True 与 __exact=None的区别 例子：类是 Author 字段 username，password 123Author.objects.filter(username__exact=username) #精准查询k=Author.objects.filter(username__exact=username)obj=Author.objects.get(username__exact=username) #get 取得的是字段为username 匹配的对象：在使用update的时候，需要注意，查询集才有这个方法，查询集实例没有，查询集有5个，update可以一次更新5张表的数据。 分页实现两个参数 page，limit 每次都传这两个参数，决定了数据的截取位置和截取多少。 query[ (page-1)*limit : page*limit ] 其它 对于模型的新创建的实例，直接save()就行了，不能用 save(update_fields=[])，本来就没有字段，所以不能用。如果是QS的元素，考虑使用 save(update_fields=[])，它只更新特定的字段。 对于QS，可以使用QS.update(field=value)，批量跟新。 django queryset 的 values 和 values_list(values_list(&#39;id&#39;, flat=true)) 这两个函数可以得到特定字段的值，有些字段是外键，我们在表示的时候，需要的是外键所对应的对象，利用这个外键id,查到数据后，将查到的对象添加到刚才的列表中去。 去除重复：distinct distinct()可以对查询集进行去重复，比如querset.distinct(), 得到的查询集元素都是唯一的对象。（有些时候，我们用id__in去得到的数据会有好几个，比如一个模型的两张表字段外键都是对到同一个，这个时候id__in 就会得到两个查询集对象，但是这个去重一般是在想处理相同字段的时候使用）当我们想去除字段相同的数据的时候，querset.values(fields).distinct().order_by(&#39;fields&#39;), 这个操作会返回dict, 这里需要排序的原因是如果不排序。在执行distinct的时候，使用默认排序id, 两列数据id是不一样的，只有我们想去重的字段是一样的，所以要以想去重的字段为准，执行一次排序。 在做查询的时候，filter的参数如果是None，就是把模型中该字段为null的查出来 sql：EXISTS用于检查子查询是否至少会返回一行数据，该子查询实际上并不返回任何数据，而是返回值True或False。EXISTS 指定一个子查询，检测 行 的存在。django也可以用这个方法，对于queryset.exists()即可 事务在Django中使用事务：`@transaction.atomic` 该装饰器将装饰内容由事务来处理。 命令项目目录下的 manage.py 接受输入参数，执行对应命令。 python manage.py validate 验证模型的有效性 python manage.py migrate 创建数据库表 python manage.py makemigrations polls 关联应用，激活模型（现在Django知道要包含polls应用。 可以运行这个命令） sqlmigrate 展示迁移的SQL语句 如果在后面的开发中需要更改模型，先在代码中加入新的字段，然后执行 迁移命令，再执行数据库创建命令。 python manage.py makemigrations （根据模型给应用生成迁移脚本） python manage.py migrate python mange.py shell 进入交互式shell 各种修改表后，可能会导致表无法创建（历史原因，可能），执行命令来同步表（遇到场景，提示字段名字重复，创建了字段后，又修改，删除migrations，创建），可以执行以下命令： 1python manage.py migrate myapp --fake 创建管理员首先，我们需要创建一个能够登录管理站点的用户。 运行如下命令： $ python manage.py createsuperuser 键入你想要使用的用户名，然后按下回车键 Username: admin 然后提示你输入想要使用的邮件地址 Email address: admin@example.com 你将被要求输入你的密码两次，第二次输入是确认密码 123Password: **********Password (again): *********Superuser created successfully. 配置配置修改setting.py文件 Django设置TIME_ZONEDjango默认的timezone是 TIME_ZONE = &#39;America/Chicago&#39;，现在要改成我们中国的时区 只需编辑settings.py文件，把time_zone的值改成TIME_ZONE=即可。 模版模版语法可以快速开发页面，不过对于前后端分离的项目，基本没什么用了。 使用模板，实现动态的生成HTML。模板包含所需HTML输出的静态部分，以及一些特殊的语法，描述如何将动态内容插入。 Django 为加载和渲染模板定义了一套标准的API，与具体的后台无关。 加载包括根据给定的标识找到模板然后预处理，通常会将它编译好放在内存中。 渲染表示使用Context 数据对模板插值并返回生成的字符串。 注意在django工程的设置中，模板设置里面，APP_DIRS设置为True，这样就允许查找应用下的模板。这里的应用包括自己创建和系统的，可以查看设置文件看看该项目有哪些应用。只要在该项目下有过Template文件夹，django就可以找到模板。 模板语言： 变量 {{ }}，变量的值来自于context中的输出 句点查找，就是 . 查找，比如 {{ f.b }}，将按照一定顺序的查找规则。字典，属性，方法调用，列表类型索引。 系统使用所找到的第一个有效类型，这是一种短路逻辑它可以嵌套，比如 { { f.a.bv(&nbsp;) }}，按顺序来，如果a没有找到，就去找bv()。 Django 模板中的HTML自动转义当用户输入的信息是一个JS脚本的时候，这个时候浏览器会执行脚本，难免会有漏洞。所以不能进行转义。 可以使用模板过滤器：safe 例子： 1hello &#123;&#123;name|safe&#125;&#125; 自定义标签我们可以创建一个模板库，里面包含我们自己写的标签和过滤器。在应用目录下创建一个templates文件夹，该文件创建一个文件__init__.py，说明它是一个模块，如何就可以写自定义的 .py 标签过滤器。 在模板中 {% load poll_extras %} 便可以将标签载入，load后面的是写的.py。 {% load %} 标签检查 INSTALLED_APPS 中的设置，仅允许加载已安装的Django应用程序中的模板库。这是一个安全特性。它可以让你在一台电脑上部署很多的模板库的代码，而又不用把它们暴露给每一个Django安装。 url 标签123urlpatterns = patterns('', (r'^article$','news_index' ),) 1&lt;a href=\"/article\"&gt;资讯&lt;/a&gt; 通常我们的URL都是硬编码的，在模板里面可能会有多个标签都是一个url，如果你要改变这个url，那么模板里面所有的url都要改变，这时候我们可以使用url标签。 123urlpatterns = patterns('', url(r'^article$','news_index' ，name=\"news_index\"),) 1&lt;a href=\"&#123;%url 'news_index'%&#125;\"&gt;资讯&lt;/a&gt; 增加一个nema，当你改变原来的url时，模板的地址也会随之改变，在view中使用 HttpResponseRedirect(&quot;/article&quot;)。 使用 reverse() 函数 HttpResponseRedirect(reverse(&quot;news_index&quot;))。 带参数的url 1url(r'^(?P&lt;year&gt;\\d&#123;4&#125;)/(?P&lt;month&gt;\\d&#123;1,2&#125;)/$','news_list',name=\"news_archive\" ) 1&lt;a href=\"&#123;%url 'news_archive' 2010 02%&#125;\"&gt;2010年02月&lt;/a&gt; 或者这样: 1&lt;a href=\"&#123;%url 'news_archive' year=2010 month=02%&#125;\"&gt;2010年02月&lt;/a&gt; 模板继承创建一个基本的骨架模板，将里面的部分内容用其它模板来替换。 123456&#123;% block title %&#125; &lt;ul&gt; &lt;li&gt;&lt;a href=\"/\"&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/blog/\"&gt;Blog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&#123;% endblock %&#125; 在这个模板中，使用block标签， block 告诉模版引擎：子模版可能会覆盖掉模版中的这些位置。 只是可能替换，不一定非要替换，如果没被替换，输出是原样： 1234&lt;ul&gt; &lt;li&gt;&lt;a href=\"/\"&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/blog/\"&gt;Blog&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; 在子模板中，同样是block标签。比如 1&#123;% block title %&#125;My amazing blog&#123;% endblock %&#125; 则原模板在使用的时候，它的title包围的块被替换成 My amazing blog，子模板在开头加上extend标签，说明继承关系： 1&#123;% extends \"base.html\" %&#125; 如果需要获得父模板中代码块的内容，可以使用如果只想在上级代码块基础上添加内容，而不是全部重载，该变量就显得非常有用了。 过滤器可以自己定义，记得在设置中添加路径自定义的过滤器添加了才有用，继承中没有添加过的过滤器不能使用 标签Django自带了大约24个内置的模版标签。你可以在内置标签参考手册中阅读全部关于它们的内容。 标签在渲染的过程中提供任意的逻辑。 这个定义是刻意模糊。例如，一个标签可以输出内容，作为控制结构，例如“if”语句或“for”循环从数据库中提取内容，甚至可以访问其他的模板标签。Tags是由 {% %} 来定义的。 过滤器更改变量或标签参数的值 {{ django|title }} 把django变量的内容开头是小写的变成大写 过滤器能够被“串联”。一个过滤器的输出将被应用到下一个。{{ text|escape|linebreaks }} 就是一个常用的过滤器链，它编码文本内容，然后把行打破转成 &lt;p&gt; 标签。 一些过滤器带有参数。过滤器的参数看起来像是这样：{{ bio|truncatewords:30 }}。这将显示 bio 变量的前30个词。过滤器参数包含空格的话，必须被引号包起来；例如，使用逗号和空格去连接一个列表中的元素，你需要使用 {{ list|join:\", \" }}。 Django提供了大约六十个内置的模版过滤器。你可以在 内置过滤器参考手册中阅读全部关于它们的信息。 注释 这样完成类注释，注释的内容不会在模板渲染时输出。 要注意的是，注释不会跨多行比如： 123This is a &#123;# this is not a comment #&#125;test. 这个注释是无效的。 其它ifequal：输出第一个判断为True的值 其它功能 发送信号：在特点操作完成前后都可以发送信息，比如数据save() 聚合内容（RSS ATOM） 静态文件收集：方便部署 验证器：用在模型字段参数里面，对字段的值进行验证froms:表单模型，表单相关，验证器可以在表单模型字段里面使用（表单模型不是我常用的东西） 日志记录模块","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"farmework","slug":"farmework","permalink":"http://www.liuzhidream.com/tags/farmework/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]},{"title":"Python","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/Python/README/","text":"python 学习笔记 基础永远是重中之重，虽然在应用开发中，很少会去使用语言的一些特性，比如一些高级话题，描述符，元类。但是掌握这些可以帮助理解框架源代码，从更深层次理解语言。 callable(object)检查对象object是否可调用。如果返回True，object仍然可能调用失败；但如果返回False，调用对象ojbect绝对不会成功。 注意：类是可调用的，而类的实例实现了call()方法才可调用。 版本：该函数在python2.x版本中都可用。但是在python3.0版本中被移除，而在python3.2以后版本中被重新添加。 dir() 函数dir() 函数不带参数时，返回当前范围内的变量、方法和定义的类型列表；带参数时，返回参数的属性、方法列表。如果参数包含方法 __dir__()，该方法将被调用。如果参数不包含 __dir__()，该方法将最大限度地收集参数信息。 与之对应的属性有 __dict__，也可以查看对象的属性，实例的 __dict__ 仅存储与该实例相关的实例属性，正是因为实例的 __dict__ 属性，每个实例的实例属性才会互不影响。类的dict存储所有实例共享的变量和函数(类属性，方法等)，类的__dict__ 并不包含其父类的属性。所以不能通过 __dict__ 在一个继承关系中，尤其是还动态修改属性后，判断属性是否存在，要获取完整的属性列表，使用dir()。 标准库 inspectinspect 作为Python的标准库，主要有以下作用： 对是否是模块，框架，函数等进行类型检查。 获取源码 获取类或函数的参数的信息 解析堆栈 一般来说，可以得到对象的各种信息，函数的参数，类的文档字符串等。 继承一个类如果已经定义了Person类，需要定义新的Student和Teacher类时，可以直接从Person类继承： 123456class Person(object): def __init__(self, name, gender): self.name = name self.gender = gender 定义Student类时，只需要把额外的属性加上，例如score： 123456class Student(Person): def __init__(self, name, gender, score): super(Student, self).__init__(name, gender) self.score = score 一定要用 super(Student, self).__init__(name, gender) 去初始化父类，否则，继承自 Person 的 Student 将没有 name 和 gender。函数 super(Student, self) 将返回当前类继承的父类，即 Person ，然后调用init()方法，注意self参数已在super()中传入，在init()中将隐式传递，不需要写出（也不能写）。 super(Teacher,self).__init__(name,gender) 和 Person.__init__(self,name,gender) 等价的，二者选一就好。 :::tip在新的py3中，使用super变的简洁了，super().__init__(name, gender)，类的形式Person.__init__(self,name,gender)没变::: 假如一个类C继承了类A和类B，类A和类B有不同的属性，并且类C在创建时要初始化这些属性，此时在类C的构造函数init中使用super(C，self).init调用就无法实现了 123456789101112class A(object): def __init__(self, a): self.a = aclass B(object): def __init__(self, b): self.b = bclass C(A, B): def __init__(self, a, b): super(C, self).__init__(a, b) # &lt;----这样写是错误的 正确的写法: 123456class C(A, B): def __init__(self, a, b): A.__init__(self, a) B.__init__(self, b) 建议养成习惯，不要使用super()这个函数，即便是单继承，也使用上面的方式 反射 &amp; 自省当执行对象的方法，或者对某个字段赋值的时候，你要操作的字段名或者方法名在编码的时候不确定，这时候需要通过某种机制访问未知的属性。 这个机制被称为反射（反过来让对象告诉我们他是什么），或是自省（让对象自己告诉我们他是什么）。 使用反射获取到的函数和方法可以像平常一样加上括号直接调用 获取到类后可以直接构造实例 不过获取到的字段不能直接赋值，因为拿到的其实是另一个指向同一个地方的引用，赋值只能改变当前的这个引用而已 单下划线/双下划线Python 用下划线作为变量前缀和后缀指定特殊变量/方法。 主要存在四种情形： object # public __object__ # special, python system use, user should not define like it __object # private (name mangling during runtime) _object # obey python coding convention, consider it as private; 核心风格：避免用下划线作为变量名的开始。 因为下划线对解释器有特殊的意义，而且是内建标识符所使用的符号，我们建议程序员避免用下划线作为变量名的开始。一般来讲，变量名 _object 被看作是“私有 的”，在模块或类外不可以使用，不能用 &#39;from moduleimport *&#39;(这种情况单双下划线都适用，而且只是用了*号不能导入，导入整个模块，或直接导入下划线开头的模块都是可行的) 导入。当变量是私有的时候，用 _object 来表示变量是很好的习惯。因为变量名 __object__ 对Python来说有特殊含义，对于普通的变量应当避免这种命名风格。 python有关private的描述，python中不存在protected的概念，要么是public要么就是private，但是python中的private不像C++, Java那样，它并不是真正意义上的private，通过name mangling（名称改编(目的就是以防子类意外重写基类的方法或者属性)，即前面加上“单下划线”+类名，eg：instance._Class__object）机制就可以访问private了。 “单下划线”：使用单下划线定义的属性或变量，它表示该方法或者属性是该类型的私有方法或属性。但其实在Python中不存在真正意义上的私有方法或者属性，前面加单下划线_只是表示你不应该去访问这个方法或者属性，因为它不是接口的一部分。 这个意思其实是一种定义，约束，你非要去访问也可以，所以在代码中我们看到单下划线开头的对象，就是让你不要去访问它。举个例子，在Django关于froms的代码中： 12345678910111213class BaseForm(StrAndUnicode): def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None): # ... self._errors = None # Stores the errors after clean() has been called. @property def errors(self): \"\"\"Return an ErrorDict for the data provided for the form.\"\"\" if self._errors is None: self.full_clean() return self._errors 这段代码截取自Django框架，可以看到_errors属性是私有的，它在clean()方法调用后被赋值，如果要查看错误，访问errors属性，而不是（也不应该）访问_errors获取错误信息。所以多看看源代码，学习其编程风格，有些人在命名变量的时候，同名的被使用了，就加个下划线，这是错误的风格。 “双下划线”：双下划线开头的变量也是设计成私有的概念，不过区别于单下划线，它确实不能直接访问，Python中不存在真正意义上的私有变量。对于双下划线开头的方法和属性虽然我们不能直接引用，那是因为Python默认在其前面加了前缀_类名，通过特别的机制（变量轧压）可以访问到。官方设计双下划线的目的，可以在继承中防止方法被覆写。 12345678910111213141516171819202122232425262728293031323334353637383940class A: def __method(self): print('__method in class A') def _method(self): print('_method in class A') def run_method(self): print(hasattr(a, '__method')) # False self.__method() self._method()class B(A): def __method(self): print('__method in class B') def _method(self): print('_method in class B')a = A()a.run_method()# output:# __method in class A# _method in class A# 很正常的输出，没有问题b = B()b.run_method()# output# __method in class A# _method in class B# 在解释器编译代码后，会进行变量轧压，或称为属性扩展，A类的__method变成了_A__method# 所以实例a，b去执行self.__method()都是去访问属性_A__method，print(dir(a))可以看到# _A__method在输出列表中，像hasattr等方法，要用_A__method作为属性名称 变量轧压：Python把以两个或以上下划线字符开头且没有以两个或以上下划线结尾的变量当作私有变量。私有变量会在代码生成之前被转换为长格式（变为公有）。转换机制是这样的：在变量前端插入类名，再在前端加入一个下划线字符。这就是所谓的私有 变量轧压（Private name mangling）。 属性扩张：一个属性命名前加了2个下划线，属性会扩展为_类__属性，属性扩展后，要用扩展后的变量名去获取属性。 注意： 一是因为轧压会使标识符变长，当超过255的时候，Python会切断，要注意因此引起的命名冲突。 二是当类名全部以下划线命名的时候，Python就不再执行轧压。 总结：理解单双下划线，Python私有变量的真正含义，它并不是语法严格限制，而是一种设计或风格，什么是变量轧压，使用了单双下划线后，from moduleimport * 要注意。 特殊方法 name Description __class__ 类对象的类型 __name__ 在模块外和类中代表不同的含义，类中调用返回类名（str），只能类调用，实例调用：self.__class__.__name__ __doc__ 类的文档字符串 __bases__ 类的所有父类组成的元祖，只能类调用，实例需要通过 __class__ __dict__ 得到一个属性字典，类和实例都可以调用，得到它们对应的属性 __module__ 类定义所在的模块（类的全名是 __main__.className，如果类位于一个导入模块mymod中，那么 className.__module__ 等于 mymod） __str__ 实例来调用，打印实例，输出实例都会执行定义的方法 __repr__ 实例调用，输出不变，打印变 __getattribute__ 获取属性，针对所有属性运行 __getattr__ 获取属性，针对未定义的属性运行 __getitem__ 字典相关获取属性 __slots__ 限制实例能绑定的属性 time该模块归属在 gengrice operating system services中，接近操作系统底层。围绕着Unix Timestamp 进行。 需要注意的是在该模块中的大多数函数是调用了所在平台C library的同名函数(比如sleep，其实是调用了平台的C代码)， 所以要特别注意有些函数是平台相关的，可能会在不同的平台有不同的效果。另外一点是，由于是基于Unix Timestamp，所以其所能表述的日期范围被限定在 1970 - 2038 之间，如果你写的代码需要处理在前面所述范围之外的日期，那可能需要考虑使用datetime模块更好。为了解决这个问题，C出里新的标准库代替原来的，这里留个心眼。 重定向在Python中，文件对象sys.stdin、sys.stdout和sys.stderr分别对应解释器的标准输入、标准输出和标准出错流。在程序启动时，这些对象的初值由sys.stdin、sys.stdout和sys.stderr保存，以便用于收尾(finalization)时恢复标准流对象。 print语句默认写入标准输出流，也可重定向至文件或其他可写对象(所有提供write方法的对象)。这样，就可以使用简洁的print语句代替笨拙的object.write(‘hello’+’\\n’)写法。因此，在python中调用 print obj 打印对象时，缺省情况下等效于调用sys.stdout.write(obj+’\\n’). 控制台重定向(&gt;和&gt;&gt;)：Windows命令提示符(cmd.exe)和Linux Shell(bash等)均通过”&gt;”或”&gt;&gt;”将输出重定向。其中，”&gt;”表示覆盖内容，”&gt;&gt;”表示追加内容。类似地，”2&gt;”可重定向标准错误。重定向到”nul”(Windows)或”/dev/null”(Linux)会抑制输出，既不屏显也不存盘。 示例： Linux 下 python print_test.py &gt;&gt;out.txt argv 获取输入参数获取输入参数 123456import sysa = sys.argvprint(a)# 在shell输入python print_test.py 321# 打印：['print_test.py', '321'] 操作Excel xlrd 读取文件，但不能对其进行操作 xlwt 生成Excel文件（可以用来控制生成的格式），但是不能在已有的Excel文件基础上进行修改 xluntils 可以修改文件，该模块需要依赖于xlrd，xlwt 12wb = Workbook()ws = wb.active #激活 worksheet，就是创建一张表，表名默认，worksheet就是该表的对象 xlwt 中 write_merge(5,6,4,7,’hello’) 在第五行，第四列这里输入数据，结果跨1行（5+1），跨3列（4+3） openpyxl：也可以用来操作Excel，由于文件格式的原因，在超过最大行数的时候，xlwt将不能处理，这时候可以使用 openpyxl 内置序列函数 map(func, seq1[, seq2,…])第一个参数接受一个函数名，后面的参数接受一个或多个可迭代的序列，返回的是一个列表。 filter(func, seq1[, seq2,…])用法和map一样，对每个迭代的元素执行func，如果返回结果是真，这个值就留下。 reduce()函数接收的参数和 map()类似，一个函数 f，一个list，但行为和 map()不同，reduce()传入的函数 f 必须接收两个参数，reduce()对list的每个元素反复调用函数f，并返回最终结果值。 调用 reduce(f, [1, 3, 5, 7, 9])时，reduce函数将做如下计算： 先计算头两个元素：f(1, 3)，结果为4； 再把结果和第3个元素计算：f(4, 5)，结果为9； 再把结果和第4个元素计算：f(9, 7)，结果为16； 再把结果和第5个元素计算：f(16, 9)，结果为25； 由于没有更多的元素了，计算结束，返回结果25。 上述计算实际上是对 list 的所有元素求和。虽然Python内置了求和函数sum()，但是，利用reduce()求和也很简单。__iter__，__next__ 这个结合，实现一个迭代器，让对象可以迭代。 zip([iterable, …])zip()是Python的一个内建函数，它接受一系列可迭代的对象作为参数，将对象中对应的元素打包成一个个tuple（元组），然后返回由这些tuples组成的list（列表）。若传入参数的长度不等，则返回list的长度和参数中长度最短的对象相同。利用*号操作符，可以将list unzip（解压）。 123456789&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6]&gt;&gt;&gt; c = [4,5,6,7,8]&gt;&gt;&gt; zipped = zip(a,b)[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; zip(a,c)[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; zip(*zipped)[(1, 2, 3), (4, 5, 6)] 时间模块 utc时区：协调世界时，又称世界统一时间，世界标准时间，国际协调时间，简称UTC 不属于任意时区 中国大陆、中国香港、中国澳门、中国台湾、蒙古国、新加坡、马来西亚、菲律宾、西澳大利亚州的时间与UTC的时差均为+8，也就是UTC+8。 时间模块有调用操作系统底层的函数，所以你直接看源码看不出什么东西来，源码上的函数是对应到底层的，这个函数真正的实现在底层。 一般用time, datetime这两个模块。 time该模块一般用的少 获取时间戳：time.time() 由给定的时间返回时间戳：time.mktime(t)，t是一个时间元组。先设一个时间元组，9个参数，最后3位可为0： 1t = (2016,7,21,22,47,45,0,0,0） 英文显示：time.asctime(t) 格式化结果：time.strftime()，time模块是封装好的一个类，可以理解为直接的time就是时间，但是你不能这么用，得调用类的方法，而strftime方法是将结果格式化的方法 时区转换：time.gmtime() 将时间戳转换成UTC时区，这里的时间戳就是time.time() datetime常用的时间对象处理模块 datetime 模块包含了几个常用的模块来处理时间，如date日期，datetime当前日期加上时间 获取时间：datetime.datetime.now() 1datetime.date.today() 时间计算（如做加减法，返回几天前的日期）：获取的时间 和 datetime.timedelta(days=1)做计算，如果是加法就可以得到当前时间一天后的时间，也可传分钟minutes等其它变量，用他们英文的复数形式。 时间对象格式化，字符串转换时间对象 strftime：这个函数是时间对象的格式化函数，只要你是时间对象就可以用这个格式化，结果是str strptime：这个是上面是反着的，将一个字符串转换成时间对象，字符串要和格式化模式一致。比如 ‘2017-8-12’ 对应的格式化模式是 ‘%Y-%m-%d&#39; 这里的Y如果用小写y，就不对了，小写对应的是 %y time模块可以直接调用上面的函数datetime模块你要先创建一个时间对象才能使用上面的函数。因为datetime格式化是类的方法，你要先创建一个实例（时间对象）才能调用方法，而对于time来说这个两个是模块里面的函数，不是类的方法。直接看源码即可理解。 格式符 说明 %a 星期的英文单词的缩写：如星期一， 则返回 Mon %A 星期的英文单词的全拼：如星期一，返回 Monday %b 月份的英文单词的缩写：如一月， 则返回 Jan %B 月份的引文单词的缩写：如一月， 则返回 January %c 返回datetime的字符串表示，如03/08/15 23:01:26 %d 返回的是当前时间是当前月的第几天 %f 微秒的表示： 范围: [0,999999] %H 以24小时制表示当前小时 %I 以12小时制表示当前小时 %j 返回 当天是当年的第几天 范围[001,366] %m 返回月份 范围[0,12] %M 返回分钟数 范围 [0,59] %P 返回是上午还是下午–AM or PM %S 返回秒数 范围 [0,61]。。。手册说明的 %U 返回当周是当年的第几周 以周日为第一天 %W 返回当周是当年的第几周 以周一为第一天 %w 当天在当周的天数，范围为[0, 6]，6表示星期天 %x 日期的字符串表示 ：03/08/15 %X 时间的字符串表示 ：23:22:08 %y 两个数字表示的年份 15 %Y 四个数字表示的年份 2015 %z 与utc时间的间隔 （如果是本地时间，返回空字符串） %Z 时区名称（如果是本地时间，返回空字符串） 时间戳和时间对象转换 1d = datetime.datetime.fromtimestamp(timeStamp) d.timestapo()，3.0 datetime模块时间对象的方法，如果是2.0，先把时间对象转换成时间元组，利用time模块的time.mktime(t)也可以得到时间戳。 由于time模块的时间对象是 struct_time 元组，并不是很好用，所以推荐获取时间戳用time.time()，其余时间处理都使用datetime，然后利用 datetime.datetime.fromtimestamp(time.time()) 可以由时间戳转换为时间对象。 时间对象处理注意： seconds 是 timedelta 对象的属性，datetime不能调用这个属性，即对时间计算才能使用这个属性。另外利用这个去做时间比较不是很靠谱，如果你的差超过了一天，那么转换的秒数溢出了，会显示0，而且如果是负数（理论值），但是时间是没有负秒数的，所以显示会和实际不符（猜测显示的可能为补码的结果）最好的时间差处理是，利用datetie.timedelte加出时间差和现在时间做比较大小。 :sunny:总结：时间对象，时间戳，时间对象格式化成字符串，字符串转换为时间对象，时间对象计算（可以将结果转换成秒，在比较的时候有作用，只要是时间对象，都可以进行算数运算） 基本数据结构 基本顺序存储结构——列表与元组 切片一般是字符串，不过列表也是可以切片的，从a到b, 这个b可以用负数来做索引。关于倒叙排列 a [ : : -1]，只操作最后一步“步进” isdigit()，字符串才有的方法，判断是不是数字 a[1:20] = [5] 可以对列表某部分切片了进行值修改，属于在原处修改 复制（浅拷贝）s[:] or s.copy() s.extend(t) or s += t 在后面插入一组，相当于 +=，区别于append，append的参数是一个元素，元素可以是list，dict s.insert(i, x) 在i处插入x(可以是任意对象) 清空：del s[:] or s.clear() 删除：s.pop([i]) 默认删除尾部元素，否则删除i处的元素(在删除索引处元素时，相比于del感觉风格要好一点)，s.remove(x) 删除第一个等于x的元素s.reverse() 列表反向 :sunny:上面这几个操作 pop 有返回值，其它都没有，所以你不能把v = list.append(1) v的值为append方法的返回值None range快速生成列表，在3x中，返回的是迭代器(3.x中很多类似函数都返回了迭代器)，如果要步进是小数，需要自己实现，Python不提供这样的函数 基本哈希存储结构——字典 name description len(d) 返回字典元素个数 d[key] 返回key对应的value d[key]=value 为字典元素赋值，如果没有则增加元素 del d[key] 删除字典元素 key ind/key not ind 查看key是否在d中 iter(d) 返回一个迭代器，具有next()方法 clear() 清空 copy() 浅复制 fromkeys(seq[,value]) 以seq作为键，value作为值建立字典，默认value为None get(key[,default]) 安全的get方法，如果不存在返回default，如果不指定default则报错 items() 列出一个键值对的view keys() 列出key的view,通常用于遍历 values() Return a new view of the dictionary’s values. pop(key[,default]) 如果键值key存在与字典中，删除dict[key]，返回dict[key]的value值。key值必须给出。否则，返回default值。如果default值没有过出，就会报出KeyError异常。pop()方法至少接受一个参数，最多接受两个参数。 popitem() 弹出一个键值对，为key的哈希序列中的第一个 setdefault(key[,default]) 安全的添加操作，如果存在就返回value不更改值，如果不存在添加一个key:default的表项，default默认为0 update([other]) 更改操作，other可以是键值对的列表或元组（二级的），也可以是字典，用other中的键值对添加到或替换原有键值对 字符串：s.upper() 小写转大写 sort：修改原列表 sorted：产生一个新的列表 字符串处理，分割用split()，替换用replace() ，strip，lstrip, rstrip分别用于去除首位，左边，右边的指定字符串。替换可以把换行去了，str.replace(‘\\n’, ‘’)，或者去空格。 python是没有null类型的，这个类型其它语言的，如js，sql。所以当前端传过这样的类型来需要注意，sql也是，如果一个没有赋值的字段，他可能是null的，但是判断布尔会出错，你会取得一个‘null’字符串。 python dict函数：一般用法传入关键字，其它方法： dict(zip([‘one’, ‘two’, ‘three’], [1, 2, 3])) # 映射函数方式来构造字典（也是利用了传入可迭代对象的方法） dict([(‘one’, 1), (‘two’, 2), (‘three’, 3)]) # 可迭代对象方式来构造字典 python setdefault（key, default） 不是设置值，而是返回结果，当键不存在的时候，才会去设置值，并返回设置了的值。如果你没写default，而键不存在，则返回None，必须注意返回的值是字典的键对应的值，不是这个字典。 :sunny:切片补充： 总有人面试出一些诡异的问题，在切片中，做了以下的总结： 切片超过索引不会报错 关于步进：步进的值不能是0(0报错)，可以是正数或负数，符号影响切片的方向，正号从左向右切，符号相反，值代表步进多少 start和end，start不能大于end（这里的大于应该从切片的位置来考虑，不能看数值，即开始切片的位置不能在end后面）否则切片结果为空，注意在负步进中，也是从start切到end，不过从右边开始切 start和end可以是负索引，和列表操作一样，当list很长，你不知道最后的索引是多少时，可以用负索引，10为list长度，正索引范围是0到9负索引范围是-1到-11 切片是不会循环的，步进决定切片方向，正负索引要从它的实际位置来做运算，字符串和tuple也可以切片 举例： 1234567891011121314list_data = list(range(0, 10))print(list_data)print(list_data[20:30])# [] # 超范围为空print(list_data[-1:9])# [] 根据第3点，数值满足，但是切的位置不满足，-1相当于是索引9的位置print(list_data[-9:-4])# [1, 2, 3, 4, 5]print(list_data[-9:-4:-1])# [] 一定要注意，步进不是加负号就倒叙print(list_data[9:-8:-2])# [9, 7, 5, 3]，负步进是反向切片，所以用正步进实现不了 any内置函数，any(iterable)，可迭代序列每个元素都是False，返回False，如果其中一个是True，返回True。这可以用在对多个对象判断逻辑，把它们写在元组里面，使用any函数。 all内置函数，all(iterable)，可迭代的每个元素都是True，返回True，否则返回False 浮点数精度以下情况就是精度损失造成的 print(0.1 * 3) # 0.30000000000000004 为什么会有精度损失： Python 中使用双精度浮点数来存储小数。在 Python 使用的 IEEE 754 标准（52M/11E/1S）中，8字节64位存储空间分配了52位来存储浮点数的有效数字，11位存储指数，1位存储正负号，即这是一种二进制版的科学计数法格式。虽然52位有效数字看起来很多，但麻烦之处在于，二进制小数在表示有理数时极易遇到无限循环的问题。 所以在使用float的时候，千万要小心精度，推荐金钱计算使用decimal 精度控制round函数，注意它的四舍五入比较特殊，不是单纯的记一个四舍五入，round() 如果只有一个数作为参数，不指定位数的时候，返回的是一个整数，而且是最靠近的整数（这点上类似四舍五入）。但是当出现.5的时候，两边的距离都一样，round()取靠近的偶数，这就是为什么round(2.5) = 2。当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则，但是碰到.5的这样情况，如果要取舍的位数前的小树是奇数，则直接舍弃，如果偶数这向上取舍。(这个函数的用法非常的扯淡，不如decimal好) :::tipNote The behavior of round() for floats can be surprising: for example, round(2.675, 2) gives 2.67 instead of the expected 2.68. This is not a bug: it’s a result of the fact that most decimal fractions can’t be represented exactly as a float. See Floating Point Arithmetic: Issues and Limitations for more information.根据官方的说法，是看浮点数被省略后，尽量取接近的值::: 不指定小数点位数, 即取整数, 四舍五入: (取到哪一位的后面一位, 若遇到.5 奇进偶不进) 1234round(2.3) 2.0round(2.6) 3.0round(2.5) 2.0round(1.5) 2.0 指定小数点位数, 即有小数位, 四舍五入: (取到哪一位的后面一位, 若遇到.5 偶进奇不进) 12345round(2.635,2) 2.63round(2.645,2) 2.65round(2.655,2) 2.65round(2.665,2) 2.67round(2.675,2) 2.67 / 和 //6.0 / 3.0 = 2.0，6.0，3.0是浮点数，那么结果也是浮点数2.0，更精确的说，只要” / “ 两边有一个数是浮点数，那么结果就是浮点数。 在Python2.2版本以前也是这么规定的，但是，Python的设计者认为这么做不符合Python简单明了的特性，于是乎就在Python2.2以及以后的版本中增加了一个算术运算符” // “来表示整数除法，返回不大于结果的一个最大的整数，而” / “ 则单纯的表示浮点数除法，但是，为了折中，所有2.X版本中，也是为了向后兼容，如果要使用” // “，就必须加上一条语句：from __future__ import division一看到这句，” / “就表示 浮点数除法，返回浮点结果，” // “表示整数除法。 但是，在Python3.0时，就没有这种折中情况了，” / “就一定表示浮点数除法，返回浮点结果，” // “表示整数除法。 slots在类中定义，用来限制类能被绑定的属性。需要注意一些情况： 正常使用，没有继承关系，除了限制的属性其它的不能被绑定 继承情况，分为两种，一是类定义了 __slots__，被其它类继承；二是类继承自其它类，父类没有定义 __slots__，而类自己定义了 __slots__。 第一种情况下，类自己的slots是可以发挥作用的，但是继承这个类的子类就没有属性绑定限制了，但是子类的 __slots__属性是可以访问的（实例和类都可以打印 __slots__ 子类没定义，打印父类的值，子类定义了，打印子类的值），如果想要父类的绑定限制，需要在子类中定义 __slots = () 一个空元组，这样子类的属性绑定就被触发了，能被添加的属性由父类的元组和子类的元组构成，但是子类是空元组，就是需要子类来显示定义 __slots__ 来触发熟悉绑定限制。 第二种情况，一个类定义了属性绑定，但是它有继承，这个时候该类的slots是发挥不了作用的。需要父类定义 __slots = () 一个空元组，子类的slots才发挥作用。 1234567891011class C: # __slots__ = ('a',) __slots__ = () passclass D(C): __slots__ = ('b',) pass 在应用开发中，也是很少使用slots，一般在看源代码的时候会见到 给类添加方法python的 MethodType(方法， 实例（如果是给类添加方法，就用None）， 类) 用来给类或实例绑定方法。例子： 12s = Stuedent() s.set_name = MethodType(set_name, s, Student) 获取项目依赖pip freeze &gt; requirements.txt 获取项目依赖。 pip instal requirements.txt 安装依赖。 eval &amp; exec可以执行动态的代码，比如给一个字符串计算结果。区别：eval返回结果，exec不返回。这就要注意了，exec(&#39;print 1&#39;) 但是用eval就不行，print 不返回结果，你可以做布尔运算，这样是返回结果的。 闭包1234def function(runfun): def fun(runfun): runfun() return fun 记住，当函数function被调用后，就产生一个闭包，闭包是fun，自由变量是runfun。 装饰器：功能函数，原函数，使用装饰器，就是将原函数的引用指向功能函数。由于装饰器是为了给原函数增加功能，所以功能函数实现的时候需要接受一个函数的引用作为参数，这个引用即为原函数。 关于自由变量： 1234def func1(x): def func2(n): print x ** n return func2 当我们 a = func1(5)，内嵌的函数得到了自由变量 5，虽然func1的调用结束了，但是 5 会被记录下来，执行 a(2) 得到 25。通过闭包得到了一个自由变量，这种是运用了嵌套作用域，如果n的值在func1中赋值了，利用的是默认参数来保留嵌套作用域的状态，在低版本中这样用，当时没有引进E的概念，n按照命名空间的原则查找。保持住状态，是闭包的最大运用（js, python 语言亦如此）记住这个保持住状态，你可能会需要这样的特性来设计程序。 这里就涉及到了python作用域查找，LGB，B是内置，新的版本引入了嵌套作用域，LEGB，查找流程是 L→B。 js：Javascript语言特有的”链式作用域”结构（chain scope），子对象会一级一级地向上寻找所有父对象的变量。所以，父对象的所有变量，对子对象都是可见的，反之则不成立。js中用闭包就可以在外部取到函数内部的变量（我会在最外层设置一个全局变量，在这个函数里面去把结果赋值给最外层，这样函数外部可以随时取这个变量，当然有闭包，并且还有这样的需求，最好是用闭包）。 对于作用域，一个函数内变量是处在这个作用域里面的，只有函数嵌套才会涉及到作用域嵌套的问题。 变量作用域，在函数里面大家是通用的，嵌套发生在函数与函数嵌套的时候。但是有一个情况，你通过if语句决定的变量，在条件不满足的时候，就无法取到了，即这个变量的作用域在不满足条件的时候，对于整个函数不是全局的。 命名空间python 命名空间，用字典来记录。局部命名空间（当前函数），全局命名空间（当前模块），内置命名空间（存放内置函数和异常），理解变量查找顺序。 Python 的一个特别之处在于其赋值操作总是在最里层的作用域。赋值不会复制数据——只是将命名绑定到对象。删除也是如此：”del y” 只是从局部作用域的命名空间中删除命名 y 。事实上，所有引入新命名的操作都作用于局部作用域。理解命名空间生命周期。函数的命名空间是属于自己的，递归调用的函数也有自己的命名空间。 模块导入的模块会存储在sys.modules表中，重复导入只要能在表中找到，则从内存中取出，不再去执行导入操作。 在导入这里涉及到了字节码的相关知识：做为顶层文件（被执行的，导入其它模块的文件），我们通常看不到pyc，因为顶层文件的pyc在内部使用后就被丢弃了，而属于被导入的文件会创建pyc，并且保留下来。pyo也是字节码，称为最佳化字节码文件。 不要重复导入一个模块，这样做不到覆盖模块属性，应使用 reload（）。不要做两个模块互相导入，如果处理不好逻辑容易出错。python3 reload 被移到imp中，需要 from imp import reload 才能使用。重载后import的模块对象改变了，会对使用import的有影响，但是重载之前的from不会，因为from是复制。记住对于from，它是复制了模块的变量给了新变量（两个同名），变量已经被复制出来了，reload模块不会影响复制出来的变量。 模块是对象，导入后，模块将拥有属性，可以使用自省获取模块属性。对于使用from的导入，要重载，先重载对应模块，在重新执行from 递归导入：两个模块相互导入对方。逻辑上处理不对，极其容易发生错误，尽量避免这种导入尤其是在其中还使用from 单下划线开头的变量只是不能被from module import * 形式导入，from module import _变量名是可以导入的 程序直接执行和导入也是有区别的，第五部分7题（python学习手册4）（对于这些非常绕的概念，没有必要完全理解，实际开发运用我们是不会这样做的，还是那句话，书上讲的不要和实际混淆，例如模块名字和系统名字重复，导致导入失败，既然你都知道了，就不要取同名，也省的使用非常绕的导入方法，就为了同名，还不如重新取个名字） 理解 from &amp; import sys.path 模块的搜索路径，在程序启动时进行配置，自动将顶级文件的主目录（或者指定当前工作目录的一个空字符串）、任何PYTHONPATH目录、已创建的任何 .pth 文件路径的内容，标准库目录合并。得到一个目录列表。 对于sys.path 修改环境变量是永久影响的，sys.path.append()在程序结束后失效。 import from 是赋值语句 import将整个模块对象赋值给一个变量名， from将一个或多个变量名赋值给另一个模块中同名的对象 理解模块对象。记住from是赋值，import是导入。在使用上仍有些许区别（只需理解from是copy就行了，理解2的意义） 注意：from的第一步也是普通的导入操作。因此，from总是会把整个模块导入到内存中（如果还没导入的话），无论是从这个文件中复制出多少变量名。它不是你想的只加载你需要的部分，如一个函数，虽然导入全部，但是你没指明的模块还是用不了。可能在效率上差了点，但是影响不大。 或者这样理解：from也是导入，先导入，然后将变量复制过来。 变量的含义一定是由源代码中的赋值语句的位置决定的 使用import导入的模块，它的全局作用域一定是其所在的文件 函数绝对无法看见其它函数内的变量名，除非它们从物理上处于这个函数内 模块程序代码绝对无法看见其它模块内的变量名，除非明确的进行了导入 一段程序的作用域完全由程序所处的文件中实际位置决定，作用域绝不会被函数调用或模块导入影响。（这体现了python的静态作用域，有些语言是动态作用域，作用域依赖于运行期间的调用） 命名空间嵌套：a.py b.py c.py b导入了a， c 导入了b， c中通过b.a可以访问到a模块。 包：理解 __all__，__init__.py 跨目录导入的时候就应该用包导入。包文件里面可以赋值和执行代码，会在导入包的时候执行，赋值的变量也会加到命名空间里。这里和执行文件所处的位置有重要关系。 例子：dir1是一个文件夹，下面有包dir2。代码在dir1下执行，可以导入dir2包，import dir2 不要这样写 import dir1.dir2。若dir1也是一个包，代码在它的上层目录执行，就应该是 import dir1.dir2。这样两个包的包文件的代码会被执行，变量也可以取到。 该部分也许用到的较少，实际结合下书607页（python学习手册第四版）内容。主要是： 代码的执行位置 包文件（只有被导入的包，包文件才被执行，变量才能加到命名空间，如果代码本身处在一个包下，那么这个包的包文件因为你不导入所以不被执行） 跨文件：有些时候想从另一个文件中拿一个模块来，此时代码所处的是文件或者包亦无所谓，你跨的目录就得是包，一级一级得包结构下去，而且这个包的上一级目录必须在sys.path 中，注意这句话，这个包的上级目录必须在 sys.path中，只能到上级目录，把自身（包）加进去就找不到了。A下有 a，b，b想拿a，sys.path 的路径就要到A，到A/a不可以。若路径只到A的上一级，应该是 import A.b Ab都要是包。 注意：sys.path 路径在搜索的时候，是在这个列表上从左到右来进行的。 包相对导入和绝对导入： 绝对就是完整路径，从sys.path路径开始搜索。p2.6默认是相对，p3默认是绝对。这样带来问题，import module，p3默认使用绝对路径，如果是系统模块，则同目录下的包导入失败。 模块导入顶层语句直接被执行，定义的函数将被创建，函数的引用写入内存，变量被创建命名空间，python会检查代码并填充局部命名空间。在python运行那行代码之前，就发现了对变量的赋值，并把它添加到局部命名空间中。 在函数中做这样的语句 i = i +1，它的本质为：python 是静态作用域，程序在编译的时候就已经知道了变量作用范围。（在代码中给一个变量赋值的地方决定了这个变量将存在于哪个命名空间，也就是它可见的范围）比如定义函数：12def func2(): i = i +1 这是一个函数，它被定义了，函数所处的模块被导入，或者自身被执行的时候，就要引入这个函数到内存，并且创建它的命名空间，所以说它是静态作用域，等到做func2()，即执行函数的时候，解释器会知道i是静态作用域。这里 i = i + 1，是对 i 进行赋值，记住 i 是被赋值的，所以不是查找变量，i 被加入函数自己的局部作用域，后面的 i + 1 是执行语句，函数在创建命名空间时，只管创建，还不执行，等到执行的时候，计算 i + 1，因为i 是局部的，该函数没有i 的值，所有会报错。记住命名空间先创建，执行的时候去找变量。123456789101112i = 1def func2(): a = i +1``` 这样是对的, 执行的时候，`i` 在局部没找到，去找全局但是如果是这样：```pyi = 1 def func2() a = i +1 i = a i 会被当成局部变量，导致执行 a = i+1 时出错。 i 必须要声明才能用，要在函数里面取得外部的i, 可以在开始指定 global i。 动态类型与对象引用变量类型的概念只存在对象中。例如 a = 3。创建一个对象来表示 3，这个对象由值3和头信息组成，头信息是一个指向 int 的对象的指针。它的步骤应该是这样的： 创建一个变量a，如果它还没创建的话。 进行引用，a变量的引用是对象3。 深刻理解 变量，对象，引用 变量：变量是一个系统表的元素，拥有指向对象的链接空间 对象：对象是分配的一块内存，有足够的空间去表示它们所代表的值 引用：是自动形成的从变量到对象的指针 引用计数器：对象拥有引用计数器 理解共享引用，两个对象都指向同一个对象 对于赋值，每次都是创建新的引用，但是列表支持在原处修改（修改某个元素，不会创建新的对象，把变量赋值为3，则原来指向列表对象，想再指向整形对象，此时创建的新对象），原处修改的，如果想不改变原来的值，可以进行对象拷贝。 加深：a=3, b=a也是实现了共享引用，和列表一样，但是它不支持在原处修改。 多态python 依赖于类型的行为称为多态。为对象来编写接口，而不是为数据类型来编写接口，注意多态的弊端，如果你的接口某个运算只能使用整形，传字符串就出错了，但是多态的灵活性是一种实实在在的好处，是否需要判断类型，可做权衡。一般说python是动态类型语言。 作用域每次对函数调用都会创建一个新的本地作用域。 理解 LEGB 作用域，E中闭包的运用（2.2中加入的功能），这是一种高级的技术，是函数式编程的运用。为了取得函数内部的参数，实现一个闭包，在外部来调用，js中的讲解。 嵌套作用域的变量在嵌套的函数被调用的时候才进行查找，在循环中，会以最后循环的值为准。使用默认参数，避开嵌套作用域查找。 分析一个函数的时候，先分析变量的赋值，看其所处的作用域。即先看这个变量会处于什么作用域，再去分析代码。 1234567891011121314151617def func1(parm1): parm1 = parm1 def func2(s): print parm1, s return func2# 这样是正确的def func1(parm1): parm1 = parm1 def func2(s): print parm1, s parm1 = parm1 + 1 return func2# 这样就出错了，以为函数第一，先创建，第二对赋值的变量创建作用域（静态作用域），# print 语句等函数执行的时候才去执行，次数需要的参数parm1是局部的（因为下一句赋值的# 关系），所以程序出错。 python3 nonlocal ： 在python2 中只有 global 被声明的变量会将作用域变成全局。nonlocal 的作用：如果在嵌套函数中赋值，该变量会被判定为局部作用域，如果不先赋值就会出错，如果外层有同名变量，在不改变内层变量名的情况下（内层变量名和外层一样），想引用外层的变量，只有声明变量是 nonlocal。其实改个变量名也可以解决事情。 12345678def func1(parm1): parm1 = parm1 def func2(s): parm2 = parm1 parm2 = parm2 + 'ss' print parm2 return func2 若要 parm1 = parm1 ,要先 nonlocal param1。局部作用域里的代码可以读外部作用域（包括全局作用域）里的变量，但不能更改它。一旦进行更改，就会将其当成是局部变量。而如果在更改前又进行了读取操作，则会抛出异常。这里的改变，即赋值，给想变的变量赋值（是不行的，只能使用关键字，如果外部有个x，将x进行 parm = x，是读取了x的值，后面用parm，不属于改变） 如果上面的例子不好理解nonlocal，可以这样理解： 12345def mufunc(): a = 123 def func(): a = a(标记1)+1 在这个函数里面，对于 func a 根据上面所学，应该知道这里a是声明，那么a的作用域被确定，当然因为没有赋值变量就引用，是要报错的。为了让a（标记1）可以拿到上层函数的a，就可以使用关键字： 1234567def mufunc(): a = 123 def func(): nonlocal a a = a(标记1)+1 # a = 123+1 函数的参数 理解位置参数和关键字参数，针对调用 * 和 ** 接收参数时的使用（编写函数） 调用的时候，传递参数也可以用 * 和 **，python 将进行参数解包 function（1，2，a，b=2），* 得到 1，2，a，** 得到 b=2 keyword-only(python3)在函数定义的时候，跟在 *args，或直接用 *，后面的参数在调用时，必须用关键字的形式。123def dog(name, host, *, age): print(name, host, age)func(1,2,b=2) 理解函数参数是通过赋值传递到函数中，赋值的方式是通过对象引用。 链式编程链式编程 是将多个操作（多行代码）通过点号”.”链接在一起成为一句代码。 例如：a.v.fun( ) 函数注释 Function Annotationspython3 新增加的特性，可以对函数增加变量注释，以及返回值注释，然后可以通过 __annotations__ 获取到注释信息的字典。 注意：使用该特性并不会对参数以及返回值做限制，lambda不支持函数注释 例子： 123456def func(a: 'x', b: 5 + 6, c: list, *args: 'xx', **kwargs: float) -&gt; max(2, 9): passprint(func.__annotations__)# &#123;'a': 'x', 'b': 11, 'c': &lt;class 'list'&gt;, 'args': 'xx', 'kwargs': &lt;class 'float'&gt;, 'return': 9&#125; lambda也称为匿名函数（因为没有函数名） 特性：是一个表达式，而不是一个语句；主体是一个单个的表达式，而不是一个代码块，只能编写简单的函数，不能用像if这样的语句（但可以写if关联的表达式）。由于是表达式，可以出现在列表中，def不能。一个表达式，得到的是函数的引用。 文件流与二进制流stringIO BytesIO，文本流的文件（txt,world,excel）才用StringIO，二进制流（视频，图片）用BytesIO 动态载入模块可能会有需求根据需要载入不同的模块，利用多态的特性进行程序设计 exec()函数 12modelname = 'string'exec('import'+modelname) 或者利用 __import__ （推荐） 12modelname = 'string'string = __import__(modelname) 处理jsonjson是按照一定格式的字符串，json模块有 loads，dumps，load，dump 后两个是文件相关的，前两个是直接转换成字符串的。 dumps将基本类型转换成json格式字符串，转换后的类型是str，需要注意的是，dumps的参数里面如果包含对象，就不是基本类型，无法进行转换，转换的对象必须是serializable(可序列化)的，不然会报类型错误。这时候需要设置参数 json.dumps(mydata, default=changefun) 接受一个函数的引用，这个函数用来处理不能直接转换的类型。函数示例：123def changefun(obj): if hasattr(obj, 'display'): return obj.display 面向对象面向对象相关内容 委托委托的概念，就是你想访问A类的时候，通过B类来访问，一般实现在B类中创建一个私有属性，指向A的实例。 class ：class语句是对象的创建者并且是一个隐含的赋值运算—执行时，它会产生类对象，并把其引用值存储在前面所使用的变量名。就是说，只有代码跑到这里，或者是导入class语句才发挥作用。 注意：一个对象的属性查找顺序遵循首先查找实例对象自己，然后是类，接着是类的父类。如果有一个类变量叫“data”, 实例也有一个变量同名，那么通过self.data去找到的只是实例的，当实例没有这个变量，才会找到类变量。一般类变量访问通过类名来获取。 加深：类本身拥有自己的类变量（保存在内存），当一个TestClass类的对象被构造时，会将当前类变量拷贝一份给这个对象，当前类变量的值是多少，这个对象拷贝得到的类变量的值就是多少；而且，通过对象来修改类变量，并不会影响其他对象的类变量的值，因为大家都有各自的副本，更不会影响类本身所拥有的那个类变量的值；只有类自己才能改变类本身拥有的类变量的值。这也是python的特别，不同于C++的静态变量。 类变量是不是共享？当我们创建的实例，类变量会被复制一份给实例，各个实例用的是自己的，要修改类变量，只能用类去访问，不能用实例去访问，实例访问的是自己的类变量（由类复制一份给它的）。所以实例操作类变量，是操作自己的类变量，影响不了其它实例，要真正修改类变量，还用用类本身去访问。 理解隐式调用：方法第一个参数总是接收方法调用的隐性主体，也就是实例对象。python会自动把实例方法的调用对应到类方法函数：instance.method(args…) class.method(instance, args…) 对于类来说，写在def语句外的都是类变量，想在方法中引用这个变量，需要加上类名。如果变量在class之外，像函数查找变量一样来操作。 类的构造函数可以有多个，但是只会使用最后一个 在python中，当对对象进行点号运算时，就会发生继承，而且涉及了搜索属性定义树（一个或多个命名空间） 类接口技术常用的技巧：超类，继承，重写，扩展，提供（提供者模式） name description Super 定义一个method函数以及在子类中期待一个动作delegate Inheritor 没有提供任何新的变量名，因此会获得Super中定义的一切内容 Replacer 用自己的模版覆盖Super的method Extender 覆盖并回调默认method，从而定制Super的method Provider 实现Super的delegate方法预期的action方法 研究这些子类来了解它们定制的共同的超类的不同的途径，下面就是这个文件： 12345678910111213141516171819202122232425262728class Super: def method(self): print('in Super.method') # Defaulr behavior def delegate(self): self.action() # Expected to be defindeclass Inheritor(Super): # Inherit method verbatim passclass Replacer(Super): # Replace method completely def method(self): print('in Replacer.method')class Extender(Super): def method(self): print('staring Extender.method') Super.method(self) print('ending Extender.method')class Provider(Super): # Fill in a required method def action(self): print('in Provider.action') 关于抽象超类：超类Super中定义了一个函数test。调用了自身的action函数。但是Super中并没有定义action函数。这个超类也会称为抽象超类。意思是说，类的部分行为由子类来提供。 委托，拦截了对实例属性的访问。即在当前类里面，访问委托类的属性，都会被拦截。1234567class Wrapper(object): def __init__(self, object): self.wrapper = object def __getattr__(self, attname): print 'do some thing' return getattr(self.wrapper, attname) 属性名称：对象命名空间 点号的属性名指的是特定对象定属性，并且遵循模块和类定规则。就类和实例对象而言，引用规则增加了继承搜索这个流程。 赋值语句（object.X = value） 在进行点号运算的对象的命名空间内创建或修改属性名X，并没有其他作用。继承树的搜索只发生只属性引用时，而不是属性的赋值运算时。 引用（object.X） 就基于类的对象而言，会在对象内搜索属性名X，然后是其上所有可读取的类（使用继承搜索流程） 对于目前类来说，结合着函数部分的内容，理解作用域是关键，赋值和引用也是关键，看到一条语句要知道它是赋值还是引用，将大大加深你对程序的理解。 加深：作用域总是由赋值语句的位置决定。这里引申一下python3 关键字 nolocal 可以让变量查找作用域到达外层，这样就可以取函数外层的变量了，但不是将其设置为全局（global）。一定要理解赋值和引用。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859def A(): x = 'a' def B(): x += 1``` 在这个例子里面，内层的x还没赋值就参与了运算，是不对的，一般像 y = x + 1是把外层的x拿来，是不能改变x的，要改变，是对变量操作，所以变量要先赋值。所以要用global ，或者nolocal 。还是那句话，这些例子和概念是为了理解LEGB，实际开发我们没必要设置一样的变量名。命名空间字典：模块和类一样，它们的命名空间是以字典的形式来实现的。属性点号的运算其实内部是字典的索引运算，而属性继承其实就是搜索链接的字典。内省的方法对函数也适用模块和类：模块是数据or逻辑包，通过编写python or C 实现，通过导入来使用。类，由class语句创建，通过调用来使用，总是位于一个模块中。抽象超类：抽象类是会调用方法的类，但没有继承或定义该方法，而是期待该方法由子类填补。当行为无法预测，非得等到更为具体的子类编写时才知道，通常可以用这种方式把类通用化。OOP软件框架也使用这种方式作为客户端定义，可定制的运算的实现方法。通过在子类中重新定义方法，然后再调用超类的方法，可以给这个方法增加功能，而不是完全覆盖。python 方法的绑定和未绑定：一般情况，我们都是直接调用方法的。方法是对象，可以获取方法对象而不调用。实例去获取的时候，方法被绑定到实例，得到新对象加上括号就可以调用了。而用类去获取，得到的就是无绑定方法对象，要执行需要把实例作为第一个参数传入。注意，在python3中，无绑定方法将变成函数，它不再是方法对象。显示类型测试程序可能受到影响，如果你打印一个非实例的类方法，它在Python2.6中显示“无绑定方法（unbound method）”，在Python3.0中显示“函数”（function）python 扩展内置类型：一般情况，通过继承内置类型，重载运算符，但是最后还是要调用超类的方法。最好有这种需要的时候多查阅下资料。### 继承搜索机制只在新式类中，继承搜索是从左到右，广度优先。py2继承object的才是新式类，py3写不写object都是新式类经典类py2中：```python class P1: def foo(self): print('p1-foo') class P2: def foo(self): print('p2-foo') def bar(self): print('p2-bar') class C1(P1, P2): pass class C2(P1, P2): def bar(self): print('C2-bar') class D(C1, C2): pass 新式类： 12345678910111213141516171819202122232425class P1: def foo(self): print('p1-foo')class P2: def foo(self): print('p2-foo') def bar(self): print('p2-bar')class C1(P1, P2): passclass C2(P1, P2): def bar(self): print('C2-bar')class D(C1, C2): pass 经典类123d = D()d.foo() # 输出 p1-foo d.bar() # 输出 p2-bar 实例d调用foo()时，搜索顺序是 D =&gt; C1 =&gt; P1 实例d调用bar()时，搜索顺序是 D =&gt; C1 =&gt; P1 =&gt; P2换句话说，经典类的搜索方式是按照“从左至右，深度优先”的方式去查找属性。d先查找自身是否有foo方法，没有则查找最近的父类C1里是否有该方法，如果没有则继续向上查找，直到在P1中找到该方法，查找结束。 新式类123d=D() d.foo() # 输出 p1-foo d.bar() # 输出 c2-bar 实例d调用foo()时，搜索顺序是 D =&gt; C1 =&gt; C2 =&gt; P1 实例d调用bar()时，搜索顺序是 D =&gt; C1 =&gt; C2可以看出，新式类的搜索方式是采用“广度优先”的方式去查找属性。 现在是新式类，使用钻石查找规则，在一个父类里面，如果执行了self.method()，这时将从头开始查找一遍。新类是广度优先，A继承了B，C。找了B，然后找C，再找B的父类。如果是旧类，是深度优先，A继承了B，C，B里面找不到就去找B的父类，一直向上，找不到才来C里面找。 描述符Python支付属性描述符的概念—带有 __get__ 和 __set__ 方法的类，分配给类属性并且由实例继承，这拦截了对特定属性的读取和写入访问。描述符在某种意义上是特性的一种更加通用的形式。实际上，特性是定义特定类型描述符的一种简化方式，该描述符运行关于访问的函数。描述符还用来实现slots特性 注意区分描述符状态和实例状态，描述符自身也是一个类，它有自己的实例，已经调用描述符的实例，所以有两个实例，要注意区分。 描述符结合 __slots__ 使用 装饰器装饰器是利用语法糖@把原来繁琐的方法简化了，装饰器可以分为以下几种： 普通装饰器 被装饰对象带参数 装饰器带参数（被装饰对象同时也可以带参数） 基于类的装饰器 带参数的类装饰器 对类作用装饰器 装饰器之上的装饰器 对于1，2，3种情况，都是在前面的基础上进行扩展，是比较常见的情况，为了适应函数不确定的参数，推荐使用可变参数来设计装饰器： 12345678910111213141516171819202122232425262728def get_run_time(show_time=False): def ff(f): def _func(*args, **kwargs): import time import datetime if show_time: print(datetime.datetime.now()) a = time.time() f(*args, **kwargs) b = time.time() print((b - a), type(a)) return _func return ff@get_run_time(True)def func(*args, **kwargs): print('hello') print(args, kwargs)# func = get_run_time(True)(func) # 不使用语法糖的情况# func(a=12, b=15)func(a=1, b=2) 装饰器也可以是类，由于装饰函数要能callable(因为函数就是能call的，所以类要考虑这个问题)，不然会报错 object is not callable 此时类需要实现 __call__，实例如下（混合了装饰器之上的装饰器，就是把上个装饰器后的结果（一个对象的引用）作为装饰函数的参数传入）： def get_run_time(debug): &quot;&quot;&quot; 获取运行时间 &quot;&quot;&quot; flag = &apos;able&apos; if debug else &apos;disable&apos; print(flag) def f(func): def _func(*args, **kwargs): import time start = time.time() func(*args, **kwargs) end = time.time() run_time = end - start print(run_time) return _func return f class Logging: &quot;&quot;&quot; 类装饰器 &quot;&quot;&quot; def __init__(self, func): self.func = func def __call__(self, *args, **kwargs): print(&apos;logging call&apos;) self.func() @Logging @get_run_time(debug=False) def my_func(): _list = [i for i in range(30 * 300)] print(&apos;this is my_func&apos;) # my_func = Logging(get_run_time(False)(my_func)) # 不使用语法糖的情况 my_func() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051下面来看带参数的类装饰器：```python def get_run_time(debug): &quot;&quot;&quot; 获取运行时间 &quot;&quot;&quot; flag = &apos;able&apos; if debug else &apos;disable&apos; print(flag) def f(func): def _func(*args, **kwargs): import time start = time.time() func(*args, **kwargs) end = time.time() run_time = end - start print(&apos;run_time: &#123;&#125;&apos;.format(run_time)) return _func return f class LoggingConfig: &quot;&quot;&quot; 带参数的类装饰器 &quot;&quot;&quot; def __init__(self, level=&apos;info&apos;): self.level = level def __call__(self, func): def wrapper(*args, **kwargs): print(self.level) func(*args, **kwargs) return wrapper @LoggingConfig(&apos;waring&apos;) @get_run_time(debug=False) def my_func(): _list = [i for i in range(30 * 300)] print(&apos;this is my_func&apos;) # my_func = LoggingConfig()(get_run_time(False)(my_func)) # 不使用语法糖的情况 my_func() 带参数的类装饰器情况还是比较特别的，之所以要这么写，理解 LoggingConfig()(get_run_time(False)(my_func)) 就很明了了，类的参数要在类实例化的时候传入，所以把参数写在类 __init__ 方法内，然后类需要实现__call__ 方法，这个时候就是类的 __call__ 要接收一个函数的引用，就是被装饰函数对象的引用。需要注意@LoggingConfig() 的括号不能去掉，不然 __init__ 方法出错。 来看最后一种情况，对类作用装饰器，这个时候可以把类也当成一个对象的引用，类似函数对象的引用，特别注意类要实例化，所以设计装饰器的时候，最后的返回很重要，大致会有两种情况： 返回类对象的引用，这种情况下，一般是利用装饰器对类进行类属性的操作，比如利用 hasattr判断类是否有特定属性，然后执行一些逻辑，最后返回类对象的引用： 123456789101112131415161718192021222324def as_view(need_login=False): def _auth(view_clz): if need_login: setattr(view_clz, 'need_login', True) return view_clz return _auth@as_view() # 即使不传参数也不能省去括号，否则as_view(need_login=False) 的need_login就指向Aclass A(object): a = 1 def __init__(self, x=0): self.x = x if hasattr(A, 'need_login'): print('need_login is &#123;&#125;'.format(getattr(A, 'need_login'))) else: print('A not has need_login')a = A(2)print(a.x) 返回类实例，这种情况，最内侧是返回一个函数对象的引用，这个函数对象的引用现在指向类，当我们实例化类的时候，就会调用这个函数对象的内容，而这个内容就是返回一个类的实例： 1234567891011121314151617181920212223242526272829303132333435363738394041def as_view(login=False): print('as_view is &#123;&#125;'.format(login)) def _wrapper(cls): print('cls is &#123;&#125;'.format(cls)) def _instance(*args, **kwargs): # setattr(cls, 'need_login', True) # 如果打开这一句，你会发现A仍然没有属性need_login print('param is &#123;&#125;--&#123;&#125;'.format(args, kwargs)) return cls(*args, **kwargs) # return cls 不能在这里返回类对象的引用，因为上一层返回的是_instance，是一个对象的引用 return _instance return _wrapper@as_view()class A(object): a = 1 def __init__(self, x=0): self.x = x if hasattr(A, 'need_login'): print('need_login is &#123;&#125;'.format(getattr(A, 'need_login'))) else: print('A not has need_login')print(A.__name__) # 此时A已经指向_instance，即使你在上面添加了属性need_login，这个属性也不是A的，这是装饰器需要注意的地方，这对于情况一是不存在的，情况一是把对象的引用进行属性添加，返回的也是这个对象的引用，所以情况1 A.__name__ 仍然是 A。a = A(2)print(a.x)# 结果：# as_view is False# cls is &lt;class '__main__.A'&gt;# _instance# param is (2,)--&#123;&#125;# A not has need_login# 2 一般在应用开发中，会使用情况一对类做一些属性限制，非常好用。 函数装饰器，类装饰器：@staticmethod 类似这样的形式，其中staticmethod 也称为元函数，运用于类的称为类装饰器。装饰器在编写的时候，我们只要知道，装饰器是接受被装饰对象为参数，并将其重新赋值给装饰对象，依照此基础就可以来写装饰器。相对于类装饰器，更像是对类进行扩展，把类在装饰函数里面执行操作后（一般是添加属性等），然后返回本身。 装饰器的理念是对原函数、对象的加强，相当于重新封装，所以一般装饰器函数都被命名为wrapper()，意义在于包装。函数只有在被调用时才会发挥其作用。比如@logging装饰器可以在函数执行时额外输出日志，@cache装饰过的函数可以缓存计算结果等等。 而注解和特性则是对目标函数或对象添加一些属性，相当于将其分类。这些属性可以通过反射拿到，在程序运行时对不同的特性函数或对象加以干预。比如带有Setup的函数就当成准备步骤执行，或者找到所有带有TestMethod的函数依次执行等等。 :green_apple:装饰器陷阱： 使用装饰器需要注意两个地方，最好不要在装饰函数之外添加逻辑功能；使用了装饰器，函数签名会被改变。 第一种情况，如下实例代码： 123456789101112131415161718192021222324252627def html_tags(tag_name): print('begin outer function.') def wrapper_(func): print(\"begin of inner wrapper function.\") def wrapper(*args, **kwargs): content = func(*args, **kwargs) print(\"&lt;&#123;tag&#125;&gt;&#123;content&#125;&lt;/&#123;tag&#125;&gt;\".format(tag=tag_name, content=content)) print('end of inner wrapper function.') return wrapper print('end of outer function') return wrapper_# @html_tags('b')def hello(name='Toby'): return 'Hello &#123;&#125;!'.format(name)hello = html_tags('b')(hello)hello(name='Toby')hello(name='Toby') 上述代码结果： begin outer function. end of outer function begin of inner wrapper function. end of inner wrapper function. &lt;b&gt;Hello Toby!&lt;/b&gt; &lt;b&gt;Hello Toby!&lt;/b&gt; 因为装饰器在定义后就会执行了，因为Python的代码在定义的时候就会确定作用域，变量等，所以 &#39;end of inner wrapper function.&#39; 之上的代码在对hello使用装饰器后就会打印了。调用hello两次，只会执行装饰器函数里面的代码。 即：&#39;print(&quot;&lt;{tag}&gt;{content}&lt;/{tag}&gt;&quot;.format(tag=tag_name, content=content))&#39; 所以代码结果是这样的。 所以最好不要在装饰器函数之外添加逻辑功能，这里的逻辑功能是print，如果是一些复杂的逻辑，它只会在定义的时候执行一次。 获取被装饰函数的函数签名，文档字符串等返回的将是闭包的函数信息。 1234567891011121314151617181920212223242526272829303132333435363738def html_tags(tag_name): print('begin outer function.') def wrapper_(func): print(\"begin of inner wrapper function.\") def wrapper(*args, **kwargs): \"\"\" doc string \"\"\" content = func(*args, **kwargs) print(\"&lt;&#123;tag&#125;&gt;&#123;content&#125;&lt;/&#123;tag&#125;&gt;\".format(tag=tag_name, content=content)) print('end of inner wrapper function.') return wrapper print('end of outer function') return wrapper_# @html_tags('b')def hello(name='Toby'): \"\"\" hello doc string \"\"\" return 'Hello &#123;&#125;!'.format(name)hello = html_tags('b')(hello)hello(name='Toby')hello(name='Toby')import inspectdoc = inspect.getdoc(hello)print(hello.__name__, doc) # wrapper doc string 原因就是因为使用@语法糖，原函数的引用被修改了：hello = html_tags(&#39;b&#39;)(hello)，那么新的hello的函数信息指向 wrapper。这是最容易发生问题的地方，尤其是使用多次装饰器，如果你需要这样的复杂逻辑，一定要小心对象的引用早已改变，如果还使用原对象名称进行操作，无疑是出BUG。 如果需要原函数的信息，可以使用标准库 functool.wrapt，对闭包的函数进行装饰： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import functoolsdef html_tags(tag_name): print('begin outer function.') def wrapper_(func): print(\"begin of inner wrapper function.\") @functools.wraps(func) # 在此运用装饰器 def wrapper(*args, **kwargs): \"\"\" doc string \"\"\" content = func(*args, **kwargs) print(\"&lt;&#123;tag&#125;&gt;&#123;content&#125;&lt;/&#123;tag&#125;&gt;\".format(tag=tag_name, content=content)) print('end of inner wrapper function.') return wrapper print('end of outer function') return wrapper_# @html_tags('b')def hello(name='Toby'): \"\"\" hello doc string \"\"\" return 'Hello &#123;&#125;!'.format(name)hello = html_tags('b')(hello)hello(name='Toby')hello(name='Toby')import inspectdoc = inspect.getdoc(hello)print(hello.__name__, doc)print(inspect.signature(hello)) # py3之前的版本仍然获取到闭包函数信息print(inspect.getsource(hello)) # py3之前的版本仍然获取到闭包函数信息 输出如下： begin outer function. end of outer function begin of inner wrapper function. end of inner wrapper function. &lt;b&gt;Hello Toby!&lt;/b&gt; &lt;b&gt;Hello Toby!&lt;/b&gt; hello hello doc string (name=&apos;Toby&apos;) def hello(name=&apos;Toby&apos;): &quot;&quot;&quot; hello doc string &quot;&quot;&quot; return &apos;Hello {}!&apos;.format(name) 除了functool.wrapt模块，还可以使用第三方模块wrapt，如果使用该模块，要按照给定的规则来重新包装函数，和functool.wrapt直接使用装饰器相比需要改动代码，另外Python3.x之前functool.wrapt模块并不能得到函数签名和函数源码等，在3.x之后变得可行了。 利用 dict 做缓存实例方法可以利用装饰器变成属性，其实质是，方法本身也是类的一个属性，通过装饰器，让访问这个属性的时候传回方法计算后期待的值，实现了将方法变成属性。 实例和类都有 __dict__ 属性，写一个装饰器，让方法变成属性可以直接访问，同时将方法作为属性添加到实例的 __dict__ 中去，这样下次再访问这个属性方法的时候，根据属性查找规则，会先去实例里面找，因为实例已经添加了方法的属性键值对，所以直接取到了，不会再去类里面调用方法来计算属性了，从而实现了缓存（在运用的时候，代码运行起来，就每次都是去取缓存了，必须要停下来才去重新计算，所以如果你想要用一些动态技术来生成属性的值，记得把 __dict__ 里面的原属性删除，这样你的方法才会被再次调用，重新做缓存） 以下的例子中，hello只会被执行一次，因为下次从实例里面取，不再调用类的方法了。 12345678910111213141516171819202122232425262728from cached_property import cached_propertyclass A(object): acs = '11' patt = property() def __init__(self, z): self.z = z self.info = None @cached_property def exinfo(self): print('hello') if type(self.info) == dict: res = self.info else: res = &#123;&#125; self.info = res return res def mydata(self): return 'zxc'a = A('ss')print(a.__dict__, A.__dict__)print(a.exinfo, a.__dict__, A.__dict__)print(a.exinfo, a.__dict__, A.__dict__) 避免循环递归123def __getattribute__(self, item): return object.__getattribute__(self, 'other') 利用超类，传递的实例是本对象的。理解方法调用的时候传递的self很重要，你可以改实例，不使用隐式传参。 对于赋值和删除也需要考虑这个问题，用超类来避免循环。或者用 self.__dict__[&#39;other&#39;] = other，这个对于取属性不能用，因为取属性就要循环了。总结：取属性要特别注意，获取和删除不能直接对实例的属性进行赋值，要用超类的setattr方法或者实例的 __dict__ 来赋值。 逻辑表达式和一般语言返回布尔值不同，python更加灵活： 在Python中，空字符串为假，非空字符串为真。非零的数为真。 数字和字符串之间、字符串之间的逻辑操作规律是： 对于and操作符：只要左边的表达式为真，整个表达式返回的值是右边表达式的值，否则，返回左边表达式的值 对于or操作符：只要两边的表达式为真，整个表达式的结果是左边表达式的值。 如果是一真一假，返回真值表达式的值 如果两个都是假，比如空值和0，返回的是右边的值。（空值或0） !/usr/bin/env python脚本语言的第一行，目的就是指出，你想要你的这个文件中的代码用什么可执行程序去运行它，就这么简单。 #!/usr/bin/python是告诉操作系统执行这个脚本的时候，调用/usr/bin下的python解释器 #!/usr/bin/env python这种用法是为了防止操作系统用户没有将python装在默认的/usr/bin路径里。当系统看到这一行的时候，首先会到env设置里查找python的安装路径，再调用对应路径下的解释器程序完成操作 #!/usr/bin/python相当于写死了python路径 #!/usr/bin/env python会去环境设置寻找python目录,推荐这种写法 env是Linux命令，可以启动python。env命令用于显示系统中已存在的环境变量，以及在定义的环境中执行指令。 断言类似C的概念。assert group is None, &quot;msg&quot; 其中group是一个变量，如果断言表达式正确，则代码继续，错误则除非断言异常，AssertionError 会把信息打印出来。 对象拷贝浅拷贝和深拷贝的加深理解：因为没有这样的需要，所以一直没有注意。再来看看两个点的概念 浅拷贝(copy)：拷贝父对象，不会拷贝对象的内部的子对象。 深拷贝(deepcopy)： copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象。 要完全获得一个对象的复制，用深拷贝（深拷贝比较费时间，可能会影响效率），浅拷贝不会拷贝对象内部的子对象，这句话很重要，如果你要拷贝的对象是一个列表，并且列表每一个元素都是一个不可变的，那么浅拷贝效果和深拷贝一样。但是如果你的元素是一个可变对象，比如一个列表，那么原值和新值的这个列表对象都是指向同一个引用的，改其中一个另一个结果也会影响，但是如果是不可变对象，改变其中一个不影响另一个，因为这个不可变对象的拷贝已经是新的引用。 解析 b = a: 赋值引用，a 和 b 都指向同一个对象。 image b = a.copy(): 浅拷贝, a 和 b 是一个独立的对象，但他们的子对象还是指向统一对象（是引用）。 image b = copy.deepcopy(a): 深度拷贝, a 和 b 完全拷贝了父对象及其子对象，两者是完全独立的。 image 垃圾回收除了利用引用计数回收外，还有一个垃圾回收机制，gc(garbage collection)。gc这种机制很多语言都会用，但是python兼顾二者，引用计数回收能在对象计数为0的时候就马上回收。但是引用计数会出现循环引用的情况，只有容器类型对象会出现循环引用，不可变对象不会。例如：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111def myfunc(): l = [] l.append(l)``` 这个操作会循环引用对象I，对于循环引用的情况，利用引用计数来回收就不行了，所以出现了gc机制。这个机制是自动的，可以认为触发。垃圾回收机制会根据内存的分配和释放情况的而被调用，比如分配内存的次数减去释放内存的次数大于某一个阈值的时候。## Python 常见文件格式Python源代码遵循 GPL (GNU General Public License) 协议，由 Guido van Rossum 于 1989 年底发明，第一个公开发行版发行于 1991 年。Python 常被称为胶水语言，能把用其他语言编写的各模块 (尤其是 C/C++) 轻松地联结在一起。常见情形是，用 Python 快速生成程序原型 (有时甚至是程序最终界面)，然后对其中有特别要求的部分，用更合适的语言改写；譬如：3D 游戏中的图形渲染模块，性能要求特别高，就可用 C/C++ 重写，而后封装为 Python 可调用的扩展类库。需要注意的是，在您使用扩展类库时可能需要考虑平台问题，某些扩展类库可能不提供跨平台实现。一般认为，Python 是一种解释性语言，Python 在执行时，会先将 .py 文件中的源代码编译成 byte code (字节码)，然后再由 Python Virtual Machine 来执行这些编译 byte code。这种机制的基本思想跟 Java、.NET 一致；但 Python Virtual Machine 与 Java 或 .NET 的 Virtual Machine 不同的是：Python 的 Virtual Machine 是一种更高级的 Virtual Machine。这里的高级并不是通常意义上的高级，不是说 Python 的 Virtual Machine 比 Java 或 .NET 的功能更强大，更拽，而是说和 Java 或 .NET 相比，Python 的 Virtual Machine 距真实机器的距离更远。或者可以这么说，Python 的 Virtual Machine 是一种抽象层次更高的 Virtual Machine。Python 提供了一种中间编译结果保存机制，即 byte code，或更准确地说，保存 PyCodeObject。事实上，Python 确实提供了这样一种机制 —— .pyc 文件。在执行一个 .py 文件的源代码之后，Python 并不会自动生成与该 .py 文件对应的 .pyc 文件。Python 会根据需要自动触发、创建 .pyc 文件，原理很简单，就是利用 Python 的 import 机制。在 Python 运行过程中如碰到 import abc 这样的语句，Python 将会在设定好的 path 中寻找 abc.pyc 或 abc.dll 文件。若没有这样的文件，而只是发现了 abc.py 文件，那么，Python 会首先将 abc.py 编译成相应的 PyCodeObject 中间结果，然后再创建 abc.pyc 文件，并将中间结果写入该文件。接下来，Python 才会对 abc.pyc 文件进行一个 import 动作，实际上也就是将 abc.pyc 文件中的 PyCodeObject 重新在内存中复制出来，加以运行。由于 Python .pyc 文件的此种运行机制，所以，可随时删除所有中间过程 .pyc 文件，当 Python 再次运行时，还会重生成这些 .pyc 文件，对您所编辑程序的运行并无任何影响。当然，得有源代码才行。视窗用 python.exe 运行 .py ，用 pythonw.exe 运行 .pyw。因为安装视窗版 Python 时，扩展名 .py 自动被登记为用 python.exe 运行， 而 .pyw 则被登记为用 pythonw.exe 运行。 - `.py 文件`以 .py 作扩展名的文件是 Python 源代码文件，由 python.exe 解释，可在控制台下运行。当然，也可用文本编辑器或其它专用 Python IDE (集成开发环境) 工具进行修改。- `.pyc 文件`以 .pyc 作扩展名的文件是 python 编译文件。.pyc 文件是不能直接用文本编辑器进行编辑，其优点是 .pyc 文件的执行速度要远快于 .py 文件。至于为什么要有 .pyc 文件，因为 .py 文件是可直接看到源码的。若是软件开发商，不可能把源码泄漏出去？所以，就需编译成 .pyc 后再发布。但 .pyc 文件只是经简单编译，并未加密，因此，有些工具还能反编译它得出源代码。- `.pyw 文件`.pyc 文件执行时，桌面会出现类似 CMD 命令的黑色 shell 窗口，十分难看，于是 .pyw 文件就应运而生了。.pyw 文件与 .pyc 文件的执行，本质上并没什么区别，只是 .pyw 文件执行的时候不会出现类似 CMD 命令的黑色 shell 窗口。.pyw 文件格式主要是设计用来运行 Python 纯 GUI (图形用户界面) 程序的。纯 GUI (图形用户界面) 程序的用户不需要看到类似 CMD 命令的黑色 shell 控制台窗口。当 .pyw 文件运行时，所有 stdout、stderr 输出无效，所有原 stdin 的读取只会得到 EOF。值得一提的是，开发纯 GUI (图形用户界面) 程序时，可暂时把 .pyw 改成 .py，以便运行时调出控制台窗口，看到所有错误信息，方便修改、调试。注意：采用 PyQt、PySide 等 GUI (图形用户界面) 开发框架开发的程序，源文件仍可采用 .py，无需单独使用 .pyw。- `.pyo 文件`\"python -O 源文件\" 即可将 Python 源程序编译成 .pyo 文件，但有时仍得采用 .pyc 作后缀，才能正常运行。.pyo 文件是相对 .pyc 而言的，优化编译后的 Python 文件。 同样，.pyo 文件也不能直接用文本编辑器进行编辑。- `.pyd 文件`.pyd 文件是非 Python，由其它编程语言 \"编写-编译\" 生成的 Python 扩展模块。Python 要导入 .pyd 文件，实际上是在 .pyd 文件中封装了一个 module。在 python 中使用时，把它当成 module 来用就可以了，即：\"import 路径名.modulename\" 即可，路径名为 .pyd 文件所在的路径。基于 Qt/C++ 的 PyQt、PySide GUI (图形用户界面) 开发框架绑定，会为每个 Qt/C++ 库 .dll 文件生成一个中间 .pyd 文件。PyWin32 项目分发包中，也存在很多 MicroSoft Windows OS 相应 .dll 文件的中间 .pyd 文件。Cython 可将个人基于 Python 语言编写的 Python 模块编译成具有 C 语言特性的 .pyd 文件。.pyd 文件有时也是用 D 语言按照一定格式编写，编译生成的二进制文件。那么什么是 \"D 语言\" 呢？它是 C/C++ 的综合进化版，不仅具有二者的全部优点，且整体性能更佳，但其抽象程度高。D 语言最初由 Digital Mars 公司就职的 Walter Bright 于 2001 年发布，意图改进 C++ 语言。目前最新 D 语言被简称为 D2。最主要的 D 语言实现是 DMD。D 语言源自 C/C++，借鉴了众多编程语言的特色和现代编译器技术，融会贯通了设计者丰富的实践经验，使之具备了非凡的威力 ── 既有 C/C++ 语言的强大威力，又有 Python 和 Ruby 的开发效率。它集众多系统级编程所需的功能于一身，例如垃圾回收、手工内存操作、契约式设计、高级模板技术、内嵌汇编、内置单元测试、Mixin 风格多继承、类 Java 包管理机制、内置同步机制、内建基本运行时信息。## 文本与二进制在 Python 2 中，文本类型（也就是 unicode）和二进制类型（也就是 str）的边界非常模糊。很多函数的参数既可以是文本，也可以是二进制。但是在 Python 3 中，文本类型和二进制类型的字符串被完全的区分开了。Python 3对文本和二进制数据作了更为清晰的区分。文本总是Unicode，由str类型表示，二进制数据则由bytes类型表示。不能拼接字符串和字节包，也无法在字节包里搜索字符串（反之亦然），也不能将字符串传入参数为字节包的函数（反之亦然）。## 位运算a = 0011 1100b = 0000 1101| name | Description | Example| --- | :---------: | :------| &amp; | 按位与运算符 | 参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0 (a&amp;b)输出结果12，二进制解释：00001100 | \\| | 按位或运算符 | 只要对应的二个二进位有一个为1时，结果位就为1。 (a|b)输出结果61，二进制解释：00111101 | ^ | 按位异或运算符 | 当两对应的二进位相异时，结果为1 (a^b)输出结果49，二进制解释：00110001 | ~ | 按位取反运算符 | 对数据的每个二进制位取反,即把1变为0,把0变为1。~x类似于-x-1 (~a)输出结果-61，二进制解释：11000011，在一个有符号二进制数的补码形式。 | &lt;&lt; | 左移动运算符 | 运算数的各二进位全部左移若干位，由\"&lt;&lt;\"右边的数指定移动的位数，高位丢弃，低位补0。 a&lt;&lt;2输出结果240，二进制解释：11110000 | &gt;&gt; | 右移动运算符 | 把\"&gt;&gt;\"左边的运算数的各二进位全部右移若干位，\"&gt;&gt;\"右边的数指定移动的位数 a&gt;&gt;2输出结果15，二进制解释：00001111 关于异或：异或是一种基于二进制的位运算，用符号XOR或者 ^ 表示，其运算法则是对运算符两侧数的每一个二进制位，同值取0，异值取1。它与布尔运算的区别在于，当运算符两侧均为1时，布尔运算的结果为1，异或运算的结果为0。简单理解就是不进位加法，如1+1=0，,0+0=0,1+0=1。性质1、交换律 可任意交换运算因子的位置，结果不变2、结合律（即(a^b)^c == a^(b^c)）3、对于任何数x，都有x^x=0，x^0=x，同自己求异或为0，同0求异或为自己4、自反性 A ^ B ^ B = A ^ 0 = A ，连续和同一个因子做异或运算，最终结果为自己异或运算，只看运算方法，会觉得很奇怪，但是由方法引申出一些性质，再把这些性质作为公式或口诀熟记，异或才能真正去解决问题。比如：1. 两个变量交换 a = a^b b = a^b a = a^b12345678910111213141516171819202122232425262728293031323334352. 判断奇偶数更简单高效的做法奇数二进制的最低位一定是1，偶数二进制的最低位一定是0，所以拿一个数和1作异或就可以判断奇偶性3. 可以去除一些数组中重复的数，利用4个特性## ASCII`ord()` 函数接受一个字符，转换成ASII码。`chr()` 接受一个整型ASII变量，转换成字符## logging 模块logging模块很灵活，是项目必备的模块，日志级别 `CRITICAL &gt; ERROR &gt; WARNING &gt; INFO &gt; DEBUG`，默认logger的level是logging.WARNING，低于该级别的就不输出了。在导入模块后，通过logging.basicConfig(level=logging.NOTSET)来配置日志级别，这里设置为NOTSET，所有级别都会被输出（貌似和设置DEBUG级别是一样的效果，感觉作用在于重写类对象，新增加级别的时候设置NOTSET可以不受控制）## mappingproxy（不可变映射类型）python3.3开始,types模块中引入了一个封装类名叫MappingProxyType，如果给这个类一个映射,它会返回一个只对映射视图。虽然是个只读的视图,但是它是动态的,这意味着如果对原映射做出了改动，我们可以通过这个视图观察到,但是无法通过这个视图对原映射做出修改。```python #示例 from types import MappingProxyType #创建一个集合 index_a = &#123;&apos;a&apos; : &apos;b&apos;&#125; #创建index_a的映射视图 a_proxy = MappingProxyType(index_a) print(a_proxy) a_proxy[&apos;a&apos;] # #不能对a_proxy视图进行修改 # a_proxy[&apos;b&apos;] = &apos;bb&apos; #但是可以对原映射进行修改 index_a[&apos;b&apos;] = &apos;bb&apos; print(a_proxy) 另外值得注意的是，类的 __dict__ 属性也是mappingproxy的，之所以这么做是为了保证类级别的属性和方法只能是字符串，也帮助解释器更快的查找类级别的属性（因为它是字符串的）。类的属性是实例共享的，这也保证了类的统一性。所以你不应该设计这样的程序：通过class.__dict__.update(dict()STATUS=0)去修改类的属性，可以做的是修改实例的属性，记住创建实例会把类的属性复制一份给实例。 利用偏函数设计程序偏函数是将所要承载的函数作为partial()函数的第一个参数，原函数的各个参数依次作为partial()函数后续的参数，除非使用关键字参数。 12345678910from functools import partialdef mod( n, m ): return n % mmod_by_100 = partial( mod, 100 ) print mod( 100, 7 ) # 2print mod_by_100( 7 ) # 2 mod(100, 7) 原函数的各个参数依次作为partial()函数后续的参数 进制转换 12345678910from functools import partialbin2dec = partial( int, base=2 )print bin2dec( '0b10001' ) # 17print bin2dec( '10001' ) # 17hex2dec = partial( int, base=16 )print hex2dec( '0x67' ) # 103print hex2dec( '67' ) # 103","tags":[{"name":"note","slug":"note","permalink":"http://www.liuzhidream.com/tags/note/"},{"name":"python","slug":"python","permalink":"http://www.liuzhidream.com/tags/python/"}]}]